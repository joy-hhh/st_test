import streamlit as st
import pandas as pd
import io
from pathlib import Path
from openpyxl.styles import Font, PatternFill, Alignment
from openpyxl.worksheet.datavalidation import DataValidation
from openpyxl.utils import get_column_letter
from contextlib import redirect_stdout

st.set_page_config(
    page_title="ConsolLab", page_icon="ConsolLab_logo.png", layout="wide"
)

# --- App Title ---
col1, col2 = st.columns([1, 5])
with col1:
    st.image("ConsolLab_logo.png", width=130)
with col2:
    st.title("ConsolLab")
    st.caption("ì—°ê²°ë´‡ ConsolLab : ì—°ê²° ì¬ë¬´ì œí‘œ ìë™í™” ìƒì„±ê¸°")

# --- Session State ì´ˆê¸°í™” ---
if "files" not in st.session_state:
    st.session_state.files = {
        "coa": None,
        "parent": None,
        "subsidiaries": [],
        "adjustment": None,
        "footnotes": [],
    }
if "results" not in st.session_state:
    st.session_state.results = {
        "consolidation_wp_bs": None,
        "consolidation_wp_pl": None,
        "consolidation_wp_cf": None,
        "combined_footnotes": None,
        "validation_log": [],
        "caje_bspl_df": None,
        "caje_cf_df": None,
    }
if "caje_generated" not in st.session_state:
    st.session_state.caje_generated = False
if "fcfs_results" not in st.session_state:
    st.session_state.fcfs_results = {
        "translated_df": None,
        "summary_df": None,
        "log": [],
    }


# =================================================================================================
# --- Helper Functions ---
# =================================================================================================
@st.cache_data
def to_excel(df_dict):
    """
    ì—¬ëŸ¬ ë°ì´í„°í”„ë ˆì„ì„ í•˜ë‚˜ì˜ Excel íŒŒì¼ ë²„í¼ì— ì‹œíŠ¸ë¡œ ì €ì¥í•˜ê³ , ìŠ¤íƒ€ì¼ì„ ì ìš©í•©ë‹ˆë‹¤.
    df_dict: {'sheet_name': DataFrame} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
    """
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine="openpyxl") as writer:
        for sheet_name, df in df_dict.items():
            if df is None:  # df.empty ì¡°ê±´ ì œê±°í•˜ì—¬ ë¹ˆ ì‹œíŠ¸ë„ ìƒì„±
                continue

            # ì†Œê³„ í–‰ ì •ë³´ ì¶”ì¶œ í›„, 'is_subtotal' ì—´ì€ ì—‘ì…€ì—ì„œ ì œì™¸
            is_subtotal_col = df["is_subtotal"] if "is_subtotal" in df.columns else None
            df_to_write = (
                df.drop(columns=["is_subtotal"]) if is_subtotal_col is not None else df
            )
            df_to_write.to_excel(writer, sheet_name=sheet_name, index=False)

            ws = writer.sheets[sheet_name]

            # í—¤ë” ìŠ¤íƒ€ì¼ ì •ì˜
            header_font = Font(bold=True, color="FFFFFF")
            header_fill = PatternFill(
                start_color="4F81BD", end_color="4F81BD", fill_type="solid"
            )
            header_alignment = Alignment(
                horizontal="center", vertical="center", wrap_text=True
            )

            # í—¤ë” ìŠ¤íƒ€ì¼ ì ìš©
            for cell in ws[1]:
                cell.font = header_font
                cell.fill = header_fill
                cell.alignment = header_alignment

            # ì†Œê³„ í–‰ì— ë³¼ë“œì²´ ì ìš©
            if is_subtotal_col is not None:
                bold_font = Font(bold=True)
                for row_idx, is_sub in enumerate(is_subtotal_col):
                    if is_sub:
                        # openpyxl í–‰ì€ 1-based, í—¤ë”ê°€ ìˆìœ¼ë¯€ë¡œ +2
                        for cell in ws[row_idx + 2]:
                            cell.font = bold_font

            # ì—´ ë„ˆë¹„ ë° ìˆ«ì ì„œì‹ ì ìš©
            for i, column_name in enumerate(
                df_to_write.columns, 1
            ):  # openpyxlì€ 1-based index
                column_letter = get_column_letter(i)
                ws.column_dimensions[column_letter].width = 17

                if pd.api.types.is_numeric_dtype(
                    df_to_write[df_to_write.columns[i - 1]]
                ):
                    for cell in ws[column_letter][1:]:
                        if isinstance(cell.value, (int, float)):
                            cell.number_format = "#,##0"
                            cell.alignment = Alignment(
                                horizontal="right", vertical="center"
                            )

    return output.getvalue()


def log_validation(message):
    """ê²€ì¦ ê²°ê³¼ë¥¼ ì„¸ì…˜ ìƒíƒœì— ê¸°ë¡í•©ë‹ˆë‹¤."""
    st.session_state.results["validation_log"].append(message)


# =================================================================================================
# --- ì™¸í™”FSí™˜ì‚°ìš© í•¨ìˆ˜ ë° ì„¤ì • (from fcfs_translate.py) ---
# =================================================================================================
AMOUNT_COL_CANDIDATES = ("ì™¸í™”ê¸ˆì•¡", "FC_Amount", "Amount")
EQUITY_CARRY_COL = "ì´ì›”ê¸ˆì•¡"
NAME_COL_CANDIDATES = ("ê³„ì •ëª…", "Account", "Name")
EPS_BS = 1e-6


def _first_numeric_in_row(row):
    s = pd.to_numeric(row, errors="coerce").dropna()
    return None if s.empty else float(s.iloc[0])


def _find_col(df, candidates):
    for c in candidates:
        if c in df.columns:
            return c
    return None


def read_rates_and_table(xlsx_path):
    all_df = pd.read_excel(xlsx_path, header=0)
    closing_rate = _first_numeric_in_row(all_df.iloc[0])
    average_rate = _first_numeric_in_row(all_df.iloc[1])
    if closing_rate is None or average_rate is None:
        raise ValueError("ê¸°ë§/í‰ê· í™˜ìœ¨ì„ 2~3í–‰(ë°ì´í„° ì²« 2í–‰)ì—ì„œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    df = all_df.drop(index=[0, 1]).reset_index(drop=True)
    if "FS_Element" not in df.columns:
        raise ValueError("íŒŒì¼ì— FS_Element ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. (A/L/E/RE/R/X/PI)")
    return closing_rate, average_rate, df


def precheck_foreign_currency(df, eps=EPS_BS):
    df = df.copy()
    amount_col = _find_col(df, AMOUNT_COL_CANDIDATES)
    if amount_col is None:
        raise ValueError(
            f"ì™¸í™”ê¸ˆì•¡ ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í›„ë³´={AMOUNT_COL_CANDIDATES}"
        )
    df[amount_col] = pd.to_numeric(df[amount_col], errors="coerce").fillna(0.0)
    is_A = df["FS_Element"].eq("A")
    is_L = df["FS_Element"].eq("L")
    is_E = df["FS_Element"].eq("E")
    is_RE = df["FS_Element"].eq("RE")
    is_R = df["FS_Element"].eq("R")
    is_X = df["FS_Element"].eq("X")
    a_fc = df.loc[is_A, amount_col].sum()
    l_fc = df.loc[is_L, amount_col].sum()
    e_fc = df.loc[is_E | is_RE, amount_col].sum()
    ni_fc = df.loc[is_R, amount_col].sum() - df.loc[is_X, amount_col].sum()
    bs_gap_fc = a_fc - l_fc - e_fc
    print(
        f"[PRECHECK] (ì™¸í™”) A-L-(E+RE) = {bs_gap_fc}",
        "->",
        "OK" if abs(bs_gap_fc) < eps else "NG",
    )
    print(f"[PRECHECK] (ì™¸í™”) NI_FC = {ni_fc}")
    return {
        "A_FC": a_fc,
        "L_FC": l_fc,
        "E_plus_RE_FC": e_fc,
        "NI_FC": ni_fc,
        "BS_GAP_FC": bs_gap_fc,
        "BS_OK_FC": abs(bs_gap_fc) < eps,
    }


def translate_fcfs(df, closing_rate, average_rate, eps=EPS_BS):
    df = df.copy()
    amount_col = _find_col(df, AMOUNT_COL_CANDIDATES)
    if amount_col is None:
        raise ValueError(
            f"ì™¸í™”ê¸ˆì•¡ ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í›„ë³´={AMOUNT_COL_CANDIDATES}"
        )
    name_col = _find_col(df, NAME_COL_CANDIDATES)
    df[amount_col] = pd.to_numeric(df[amount_col], errors="coerce").fillna(0.0)
    if EQUITY_CARRY_COL in df.columns:
        df[EQUITY_CARRY_COL] = pd.to_numeric(
            df[EQUITY_CARRY_COL], errors="coerce"
        ).fillna(0.0)
    out_col = "ê¸ˆì•¡"
    if out_col not in df.columns:
        df[out_col] = 0.0
    is_A = df["FS_Element"].eq("A")
    is_L = df["FS_Element"].eq("L")
    is_E = df["FS_Element"].eq("E")
    is_RE = df["FS_Element"].eq("RE")
    is_R = df["FS_Element"].eq("R")
    is_X = df["FS_Element"].eq("X")
    is_PI = df["FS_Element"].eq("PI")
    df.loc[is_A | is_L, out_col] = df.loc[is_A | is_L, amount_col] * closing_rate
    df.loc[is_E | is_RE, out_col] = (
        df[EQUITY_CARRY_COL] if EQUITY_CARRY_COL in df.columns else 0.0
    )
    df.loc[is_R, out_col] = df.loc[is_R, amount_col] * average_rate
    df.loc[is_X, out_col] = df.loc[is_X, amount_col] * average_rate
    ni_krw = df.loc[is_R, out_col].sum() - df.loc[is_X, out_col].sum()
    if is_RE.any():
        re_idxs = df.index[is_RE]
        df.loc[re_idxs[0], out_col] = df.loc[re_idxs[0], out_col] + ni_krw
    else:
        new_row = {col: None for col in df.columns}
        new_row["FS_Element"] = "RE"
        new_row[out_col] = ni_krw
        new_row[amount_col] = 0.0
        if EQUITY_CARRY_COL in df.columns:
            new_row[EQUITY_CARRY_COL] = 0.0
        df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)
        is_RE = df["FS_Element"].eq("RE")
    assets_sum = df.loc[df["FS_Element"].eq("A"), out_col].sum()
    liabs_sum = df.loc[df["FS_Element"].eq("L"), out_col].sum()
    equity_sum = df.loc[df["FS_Element"].isin(["E", "RE"]), out_col].sum()
    diff = assets_sum - liabs_sum - equity_sum
    if is_PI.any():
        pi_idxs = df.index[is_PI]
        df.loc[pi_idxs, out_col] = 0.0
        df.loc[pi_idxs[0], out_col] = diff
    else:
        new_row = {col: None for col in df.columns}
        new_row["FS_Element"] = "PI"
        new_row[out_col] = diff
        new_row[amount_col] = 0.0
        if EQUITY_CARRY_COL in df.columns:
            new_row[EQUITY_CARRY_COL] = 0.0
        if name_col is not None:
            new_row[name_col] = "í•´ì™¸ì‚¬ì—…í™˜ì‚°ì†ìµ(PI)"
        df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)
    pi_krw = diff
    e_total_with_pi = df.loc[df["FS_Element"].isin(["E", "RE", "PI"]), out_col].sum()
    bs_gap_after = assets_sum - liabs_sum - e_total_with_pi
    print(
        f"[POSTCHECK] (í™˜ì‚° í›„) A-L-(E+RE+PI) = {bs_gap_after:.4f}",
        "  -> ",
        "OK" if abs(bs_gap_after) < eps else "NG",
    )
    print(
        f"[POSTCHECK] A={assets_sum:.2f}, L={liabs_sum:.2f}, (E+RE+PI)={e_total_with_pi:.2f}, NI(from R&X)={ni_krw:.2f}, PI={pi_krw:.2f}"
    )
    totals = {
        "A(KRW)": assets_sum,
        "L(KRW)": liabs_sum,
        "E_plus_RE_plus_PI(KRW)": e_total_with_pi,
        "NI(KRW from R&X)": ni_krw,
        "PI(KRW)": pi_krw,
        "A-L-(E+RE+PI) (after)": bs_gap_after,
    }
    cols_to_check = [amount_col, out_col]
    if EQUITY_CARRY_COL in df.columns:
        cols_to_check.append(EQUITY_CARRY_COL)
    is_zero_row = (df[cols_to_check].fillna(0) == 0).all(axis=1)
    df = df[~is_zero_row].reset_index(drop=True)
    return df, totals


# --- ì‚¬ì´ë“œë°” íŒŒì¼ ì—…ë¡œë“œ ---
with st.sidebar:
    st.header("ğŸ“ íŒŒì¼ ì—…ë¡œë“œ")
    st.info("íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ì„¸ì…˜ì— ì €ì¥ë©ë‹ˆë‹¤. ì„¸ì…˜ ì¢…ë£Œì‹œ ë©”ëª¨ë¦¬ì—ì„œ ì‚­ì œë©ë‹ˆë‹¤.")
    st.session_state.files["coa"] = st.file_uploader(
        "1. CoA (ê³„ì • ì²´ê³„)", type="xlsx", key="coa_uploader"
    )
    st.session_state.files["parent"] = st.file_uploader(
        "2. ëª¨íšŒì‚¬ ì¬ë¬´ì œí‘œ (BSPL, CF ì‹œíŠ¸ í¬í•¨)", type="xlsx", key="parent_uploader"
    )
    st.session_state.files["subsidiaries"] = st.file_uploader(
        "3. ìíšŒì‚¬ ì¬ë¬´ì œí‘œ (ë‹¤ì¤‘ ì„ íƒ ê°€ëŠ¥)",
        type="xlsx",
        accept_multiple_files=True,
        key="subs_uploader",
    )
    st.session_state.files["adjustment"] = st.file_uploader(
        "4. ì—°ê²° ì¡°ì • ë¶„ê°œ (CAJE ì—…ë¡œë“œ)", type="xlsx", key="adj_uploader"
    )

# --- íƒ­ êµ¬ì„± ---
tab1, tab2, tab3, tab4 = st.tabs(
    ["ğŸ“ˆ ì—°ê²° ì¬ë¬´ì œí‘œ", "ğŸ“ ì£¼ì„ ëŒ€ì‚¬", "ğŸ” ì—°ê²°ì¡°ì •", "ğŸŒ ì™¸í™”FSí™˜ì‚°"]
)

# =================================================================================================
# --- ì—°ê²° ì¬ë¬´ì œí‘œ íƒ­ ---
# =================================================================================================
with tab1:
    st.header("1. ì—°ê²° ì¬ë¬´ì œí‘œ ìƒì„±")
    st.write(
        "CoA, ëª¨íšŒì‚¬, ìíšŒì‚¬ ì¬ë¬´ì œí‘œì™€ ì—°ê²° ì¡°ì • ë°ì´í„°ë¥¼ í†µí•©í•˜ì—¬ ì—°ê²° ì¬ë¬´ìƒíƒœí‘œ, ì†ìµê³„ì‚°ì„œ, í˜„ê¸ˆíë¦„í‘œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
    )

    if st.button(
        "ğŸš€ ì—°ê²° ì¬ë¬´ì œí‘œ ìƒì„± ì‹¤í–‰",
        key="run_consolidation",
        disabled=not (
            st.session_state.files["coa"] and st.session_state.files["parent"]
        ),
    ):
        with st.spinner("ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ê³  ìˆìŠµë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."):
            # Reset previous results
            st.session_state.results["validation_log"] = []
            st.session_state.results["consolidation_wp_bs"] = None
            st.session_state.results["consolidation_wp_pl"] = None
            st.session_state.results["consolidation_wp_cf"] = None

            # íŒŒì¼ëª…ì—ì„œ íšŒì‚¬ ì´ë¦„ ì¶”ì¶œ
            parent_name = st.session_state.files["parent"].name.split("_")[0]
            subs_names = [
                f.name.split("_")[0] for f in st.session_state.files["subsidiaries"]
            ]

            try:
                # ----------------------------------------------------------------
                # 1. ë°ì´í„° ì¤€ë¹„ (íŒŒì¼ ì½ê¸° ë° ì „ì²˜ë¦¬)
                # ----------------------------------------------------------------
                @st.cache_data
                def load_and_clean_data(
                    coa_file, parent_file, parent_name, subs_files, subs_names, adj_file
                ):
                    def clean_df(df, key_col="ê³„ì •ì½”ë“œ"):
                        if key_col in df.columns:
                            df[key_col] = (
                                df[key_col]
                                .astype(str)
                                .str.strip()
                                .str.split(".")
                                .str[0]
                            )
                            df = df.dropna(subset=[key_col])
                        return df

                    def read_fs_sheets(file, file_name=""):
                        try:
                            xls = pd.ExcelFile(file)
                            bspl_df = (
                                pd.read_excel(
                                    xls, sheet_name="BSPL", dtype={"ê³„ì •ì½”ë“œ": str}
                                )
                                if "BSPL" in xls.sheet_names
                                else pd.DataFrame()
                            )
                            cf_df = (
                                pd.read_excel(
                                    xls,
                                    sheet_name="CF",
                                    dtype={"ê³„ì •ì½”ë“œ": str, "CF_code": str},
                                )
                                if "CF" in xls.sheet_names
                                else pd.DataFrame()
                            )

                            bspl_df = clean_df(bspl_df, "ê³„ì •ì½”ë“œ")
                            if "CF_code" in cf_df.columns:
                                cf_df = clean_df(cf_df, "CF_code")
                            elif "ê³„ì •ì½”ë“œ" in cf_df.columns:
                                cf_df = clean_df(cf_df, "ê³„ì •ì½”ë“œ").rename(
                                    columns={"ê³„ì •ì½”ë“œ": "CF_code"}
                                )

                            for df in [bspl_df, cf_df]:
                                if "ê¸ˆì•¡" in df.columns:
                                    df["ê¸ˆì•¡"] = pd.to_numeric(
                                        df["ê¸ˆì•¡"], errors="coerce"
                                    ).fillna(0)

                            return bspl_df, cf_df
                        except Exception as e:
                            st.error(f"'{file_name}' íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                            return pd.DataFrame(), pd.DataFrame()

                    coa_df = clean_df(
                        pd.read_excel(coa_file, sheet_name="CoA", dtype=str), "ê³„ì •ì½”ë“œ"
                    )
                    xls_coa = pd.ExcelFile(coa_file)
                    cf_coa_df = pd.DataFrame()
                    if "CF" in xls_coa.sheet_names:
                        cf_coa_df = pd.read_excel(xls_coa, sheet_name="CF", dtype=str)
                        if "CF_code" in cf_coa_df.columns:
                            cf_coa_df = clean_df(cf_coa_df, "CF_code")
                    else:
                        log_validation(
                            "ê²½ê³ : CoA íŒŒì¼ì— 'CF' ì‹œíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. í˜„ê¸ˆíë¦„í‘œ ì§‘ê³„ê°€ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                        )

                    aje_code = pd.read_excel(coa_file, sheet_name="AJE", dtype=str)

                    parent_bspl_df, parent_cf_df = read_fs_sheets(
                        parent_file, parent_name
                    )
                    parent_bspl_df = parent_bspl_df.rename(
                        columns={"ê¸ˆì•¡": parent_name}
                    )
                    parent_cf_df = parent_cf_df.rename(columns={"ê¸ˆì•¡": parent_name})

                    subs_bspl_dfs, subs_cf_dfs = [], []
                    for f, sub_name in zip(subs_files, subs_names):
                        bspl, cf = read_fs_sheets(f, sub_name)
                        subs_bspl_dfs.append(bspl.rename(columns={"ê¸ˆì•¡": sub_name}))
                        subs_cf_dfs.append(cf.rename(columns={"ê¸ˆì•¡": sub_name}))

                    caje_bspl_df, caje_cf_df, re_code = (
                        pd.DataFrame(),
                        pd.DataFrame(),
                        None,
                    )
                    if adj_file:
                        try:
                            xls_adj = pd.ExcelFile(adj_file)
                            if "CAJE_BSPL" in xls_adj.sheet_names:
                                caje_bspl_df = pd.read_excel(
                                    xls_adj,
                                    sheet_name="CAJE_BSPL",
                                    dtype={"ê³„ì •ì½”ë“œ": str},
                                )
                                caje_bspl_df = clean_df(caje_bspl_df, "ê³„ì •ì½”ë“œ")
                                if "ê¸ˆì•¡" in caje_bspl_df.columns:
                                    caje_bspl_df["ê¸ˆì•¡"] = pd.to_numeric(
                                        caje_bspl_df["ê¸ˆì•¡"], errors="coerce"
                                    ).fillna(0)

                            if "CAJE_CF" in xls_adj.sheet_names:
                                caje_cf_df = pd.read_excel(
                                    xls_adj,
                                    sheet_name="CAJE_CF",
                                    dtype={"ê³„ì •ì½”ë“œ": str},
                                )
                                caje_cf_df = clean_df(caje_cf_df, "ê³„ì •ì½”ë“œ")
                                if "ì¡°ì •ê¸ˆì•¡" in caje_cf_df.columns:
                                    caje_cf_df["ì¡°ì •ê¸ˆì•¡"] = pd.to_numeric(
                                        caje_cf_df["ì¡°ì •ê¸ˆì•¡"], errors="coerce"
                                    ).fillna(0)

                            if "Code" in xls_adj.sheet_names:
                                code_df = pd.read_excel(
                                    xls_adj, sheet_name="Code", dtype=str
                                )
                                re_row = code_df[code_df["FS_Element"] == "E"]
                                if not re_row.empty:
                                    re_code = re_row.iloc[0]["ê³„ì •ì½”ë“œ"]

                        except Exception as e:
                            log_validation(
                                f"ğŸš¨ ì˜¤ë¥˜: ì¡°ì •ë¶„ê°œ íŒŒì¼({adj_file.name}) ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
                            )

                    return (
                        coa_df,
                        cf_coa_df,
                        parent_bspl_df,
                        parent_cf_df,
                        subs_bspl_dfs,
                        subs_cf_dfs,
                        caje_bspl_df,
                        caje_cf_df,
                        re_code,
                        aje_code,
                    )

                (
                    coa_df,
                    cf_coa_df,
                    parent_bspl_df,
                    parent_cf_df,
                    subs_bspl_dfs,
                    subs_cf_dfs,
                    caje_bspl_df,
                    caje_cf_df_from_file,
                    re_code,
                ) = load_and_clean_data(
                    st.session_state.files["coa"],
                    st.session_state.files["parent"],
                    parent_name,
                    st.session_state.files["subsidiaries"],
                    tuple(subs_names),  # ë¦¬ìŠ¤íŠ¸ëŠ” í•´ì‹œ ë¶ˆê°€ëŠ¥í•˜ë¯€ë¡œ íŠœí”Œë¡œ ë³€í™˜
                    st.session_state.files["adjustment"],
                )

                # ----------------------------------------------------------------
                # 2. ë°ì´í„° ê²€ì¦
                # ----------------------------------------------------------------
                def check_duplicates(df, name):
                    if "ê³„ì •ì½”ë“œ" in df.columns:
                        dups = df["ê³„ì •ì½”ë“œ"].value_counts().loc[lambda x: x > 1]
                        if not dups.empty:
                            log_validation(
                                f"âš ï¸ **[{name}]** ì¤‘ë³µ ê³„ì •ì½”ë“œ ë°œê²¬: {', '.join(dups.index)}"
                            )

                def check_missing_in_coa(df, coa_codes, name):
                    if "ê³„ì •ì½”ë“œ" in df.columns:
                        missing = set(df["ê³„ì •ì½”ë“œ"]) - coa_codes
                        if missing:
                            log_validation(
                                f"ğŸš¨ **[{name}]** CoAì— ì—†ëŠ” ê³„ì •ì½”ë“œ ë°œê²¬: {', '.join(sorted(list(missing)))}"
                            )

                # ----------------------------------------------------------------
                # 2. ë°ì´í„° ê²€ì¦
                # ----------------------------------------------------------------
                def check_duplicates(df, name):
                    if "ê³„ì •ì½”ë“œ" in df.columns:
                        dups = df["ê³„ì •ì½”ë“œ"].value_counts().loc[lambda x: x > 1]
                        if not dups.empty:
                            log_validation(
                                f"âš ï¸ **[{name}]** ì¤‘ë³µ ê³„ì •ì½”ë“œ ë°œê²¬: {', '.join(dups.index)}"
                            )

                def check_missing_in_coa(df, coa_codes, name):
                    if "ê³„ì •ì½”ë“œ" in df.columns:
                        missing = set(df["ê³„ì •ì½”ë“œ"]) - coa_codes
                        if missing:
                            log_validation(
                                f"ğŸš¨ **[{name}]** CoAì— ì—†ëŠ” ê³„ì •ì½”ë“œ ë°œê²¬: {', '.join(sorted(list(missing)))}"
                            )

                def check_balance_sheet_equation(df, coa_df, column_name):
                    """ì¬ë¬´ìƒíƒœí‘œ ì°¨ëŒ€ ê²€ì¦ (ìì‚° = ë¶€ì±„ + ìë³¸)"""
                    if "ê³„ì •ì½”ë“œ" in df.columns and column_name in df.columns:
                        if "FS_Element" in df.columns:
                            merged = df
                        elif "FS_Element" in coa_df.columns:
                            merged = df.merge(
                                coa_df[["ê³„ì •ì½”ë“œ", "FS_Element"]],
                                on="ê³„ì •ì½”ë“œ",
                                how="left",
                            )
                        else:
                            return  # Cannot perform check

                        total_assets = pd.to_numeric(
                            merged[merged["FS_Element"].isin(["A", "CA"])][column_name],
                            errors="coerce",
                        ).sum()
                        total_liabilities = pd.to_numeric(
                            merged[merged["FS_Element"] == "L"][column_name],
                            errors="coerce",
                        ).sum()
                        total_equity = pd.to_numeric(
                            merged[merged["FS_Element"].isin(["E", "CE"])][column_name],
                            errors="coerce",
                        ).sum()
                        difference = total_assets - (total_liabilities + total_equity)

                        if abs(difference) > 1:  # ì‚¬ì†Œí•œ ë°˜ì˜¬ë¦¼ ì˜¤ë¥˜ëŠ” ë¬´ì‹œ
                            log_validation(
                                f"âŒ **[{column_name}]** ì¬ë¬´ìƒíƒœí‘œ ì°¨ëŒ€ ë¶ˆì¼ì¹˜: {difference:,.0f}"
                            )
                        else:
                            log_validation(
                                f"âœ… **[{column_name}]** ì¬ë¬´ìƒíƒœí‘œ ì°¨ëŒ€ ì¼ì¹˜"
                            )

                check_duplicates(parent_bspl_df, parent_name)
                for name, df in zip(subs_names, subs_bspl_dfs):
                    check_duplicates(df, name)

                coa_codes = set(coa_df["ê³„ì •ì½”ë“œ"])
                check_missing_in_coa(parent_bspl_df, coa_codes, parent_name)
                for name, df in zip(subs_names, subs_bspl_dfs):
                    check_missing_in_coa(df, coa_codes, name)

                # ----------------------------------------------------------------
                # 2. BS/PL ë°ì´í„° í†µí•© ë° ê³„ì‚°
                # ----------------------------------------------------------------
                # BS/PL ë°ì´í„° ë³‘í•© (sort=Falseë¥¼ ì¶”ê°€í•˜ì—¬ CoA ìˆœì„œ ìœ ì§€)
                merged_bspl_df = coa_df.merge(
                    parent_bspl_df[["ê³„ì •ì½”ë“œ", parent_name]],
                    on="ê³„ì •ì½”ë“œ",
                    how="left",
                    sort=False,
                )
                for name, df in zip(subs_names, subs_bspl_dfs):
                    merged_bspl_df = merged_bspl_df.merge(
                        df[["ê³„ì •ì½”ë“œ", name]], on="ê³„ì •ì½”ë“œ", how="left", sort=False
                    )

                # ìˆ«ì ì»¬ëŸ¼ ì •ì˜ ë° NaN ê°’ ì²˜ë¦¬
                bspl_val_cols = [parent_name] + subs_names
                merged_bspl_df[bspl_val_cols] = merged_bspl_df[bspl_val_cols].fillna(0)

                # ë‹¨ìˆœí•©ê³„ ê³„ì‚°
                merged_bspl_df["ë‹¨ìˆœí•©ê³„"] = merged_bspl_df[bspl_val_cols].sum(axis=1)

                # --- ì¶”ê°€ëœ ì°¨ëŒ€ ê²€ì¦ ì‹¤í–‰ ---
                check_balance_sheet_equation(merged_bspl_df, coa_df, parent_name)
                for name in subs_names:
                    check_balance_sheet_equation(merged_bspl_df, coa_df, name)
                check_balance_sheet_equation(merged_bspl_df, coa_df, "ë‹¨ìˆœí•©ê³„")
                # ------------------------------

                # ì¡°ì •ë¶„ê°œ ë³‘í•© (sort=Falseë¥¼ ì¶”ê°€í•˜ì—¬ CoA ìˆœì„œ ìœ ì§€)
                if not caje_bspl_df.empty and "ê³„ì •ì½”ë“œ" in caje_bspl_df.columns:
                    adj_bspl_grouped = (
                        caje_bspl_df.groupby("ê³„ì •ì½”ë“œ")["ê¸ˆì•¡"].sum().reset_index()
                    )

                    # ì‚¬ìš©ì ìš”ì²­: L, E, R ê³„ì •ì˜ ì¡°ì •ë¶„ê°œì—ë§Œ -1ì„ ê³±í•˜ì—¬ ë¶€í˜¸ë¥¼ ë³€í™˜
                    adj_with_fs = adj_bspl_grouped.merge(
                        coa_df[["ê³„ì •ì½”ë“œ", "FS_Element"]], on="ê³„ì •ì½”ë“œ", how="left"
                    )
                    is_ler = adj_with_fs["FS_Element"].isin(["L", "E", "R", "CE"])
                    adj_with_fs.loc[is_ler, "ê¸ˆì•¡"] = (
                        adj_with_fs.loc[is_ler, "ê¸ˆì•¡"] * -1
                    )

                    merged_bspl_df = merged_bspl_df.merge(
                        adj_with_fs[["ê³„ì •ì½”ë“œ", "ê¸ˆì•¡"]].rename(
                            columns={"ê¸ˆì•¡": "ì—°ê²°ì¡°ì •"}
                        ),
                        on="ê³„ì •ì½”ë“œ",
                        how="left",
                        sort=False,
                    )
                    merged_bspl_df["ì—°ê²°ì¡°ì •"] = merged_bspl_df["ì—°ê²°ì¡°ì •"].fillna(0)
                else:
                    merged_bspl_df["ì—°ê²°ì¡°ì •"] = 0

                # P/L ì¡°ì • í•©ê³„ë¥¼ BS(ì´ìµì‰ì—¬ê¸ˆ)ì— ë°˜ì˜
                r_adj_sum = merged_bspl_df.loc[
                    merged_bspl_df["FS_Element"] == "R", "ì—°ê²°ì¡°ì •"
                ].sum()
                x_adj_sum = merged_bspl_df.loc[
                    merged_bspl_df["FS_Element"] == "X", "ì—°ê²°ì¡°ì •"
                ].sum()
                pl_adj_sum = r_adj_sum - x_adj_sum

                if re_code:
                    target_row_mask = merged_bspl_df["ê³„ì •ì½”ë“œ"] == re_code
                    if target_row_mask.any():
                        merged_bspl_df.loc[target_row_mask, "ì—°ê²°ì¡°ì •"] += pl_adj_sum
                    else:
                        log_validation(
                            f"ğŸš¨ **[P/L to BS ì´ì „ ì˜¤ë¥˜]** Code ì‹œíŠ¸ì˜ ì´ìµì‰ì—¬ê¸ˆ ê³„ì •({re_code})ì„ CoAì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                        )
                else:
                    log_validation(
                        "ğŸš¨ **[P/L to BS ì´ì „ ì˜¤ë¥˜]** ì¡°ì •ë¶„ê°œ íŒŒì¼ì˜ Code ì‹œíŠ¸ì—ì„œ ì´ìµì‰ì—¬ê¸ˆ(E) ê³„ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                    )

                # ì—°ê²°ê¸ˆì•¡ ìµœì¢… ê³„ì‚°
                merged_bspl_df["ì—°ê²°ê¸ˆì•¡"] = (
                    merged_bspl_df["ë‹¨ìˆœí•©ê³„"] + merged_bspl_df["ì—°ê²°ì¡°ì •"]
                )

                # 3. ì—°ê²°ê¸ˆì•¡ ê¸°ì¤€ BS ì°¨ëŒ€ ê²€ì¦
                log_validation("--- ì—°ê²°ê¸ˆì•¡ ê¸°ì¤€ ì°¨ëŒ€ ê²€ì¦ ---")
                check_balance_sheet_equation(merged_bspl_df, coa_df, "ì—°ê²°ê¸ˆì•¡")

                check_duplicates(parent_bspl_df, parent_name)
                for name, df in zip(subs_names, subs_bspl_dfs):
                    check_duplicates(df, name)

                coa_codes = set(coa_df["ê³„ì •ì½”ë“œ"])
                check_missing_in_coa(parent_bspl_df, coa_codes, parent_name)
                for name, df in zip(subs_names, subs_bspl_dfs):
                    check_missing_in_coa(df, coa_codes, name)

                # ----------------------------------------------------------------
                # 2. BS/PL ë°ì´í„° í†µí•© ë° ê³„ì‚°
                # ----------------------------------------------------------------
                # BS/PL ë°ì´í„° ë³‘í•© (sort=Falseë¥¼ ì¶”ê°€í•˜ì—¬ CoA ìˆœì„œ ìœ ì§€)
                merged_bspl_df = coa_df.merge(
                    parent_bspl_df[["ê³„ì •ì½”ë“œ", parent_name]],
                    on="ê³„ì •ì½”ë“œ",
                    how="left",
                    sort=False,
                )
                for name, df in zip(subs_names, subs_bspl_dfs):
                    merged_bspl_df = merged_bspl_df.merge(
                        df[["ê³„ì •ì½”ë“œ", name]], on="ê³„ì •ì½”ë“œ", how="left", sort=False
                    )

                # ìˆ«ì ì»¬ëŸ¼ ì •ì˜ ë° NaN ê°’ ì²˜ë¦¬
                bspl_val_cols = [parent_name] + subs_names
                merged_bspl_df[bspl_val_cols] = merged_bspl_df[bspl_val_cols].fillna(0)

                # ë‹¨ìˆœí•©ê³„ ê³„ì‚°
                merged_bspl_df["ë‹¨ìˆœí•©ê³„"] = merged_bspl_df[bspl_val_cols].sum(axis=1)

                # --- ì¶”ê°€ëœ ì°¨ëŒ€ ê²€ì¦ ì‹¤í–‰ ---
                check_balance_sheet_equation(merged_bspl_df, coa_df, parent_name)
                for name in subs_names:
                    check_balance_sheet_equation(merged_bspl_df, coa_df, name)
                check_balance_sheet_equation(merged_bspl_df, coa_df, "ë‹¨ìˆœí•©ê³„")
                # ------------------------------

                # ì¡°ì •ë¶„ê°œ ë³‘í•© (sort=Falseë¥¼ ì¶”ê°€í•˜ì—¬ CoA ìˆœì„œ ìœ ì§€)
                if not caje_bspl_df.empty and "ê³„ì •ì½”ë“œ" in caje_bspl_df.columns:
                    adj_bspl_grouped = (
                        caje_bspl_df.groupby("ê³„ì •ì½”ë“œ")["ê¸ˆì•¡"].sum().reset_index()
                    )

                    # ì‚¬ìš©ì ìš”ì²­: L, E, R ê³„ì •ì˜ ì¡°ì •ë¶„ê°œì—ë§Œ -1ì„ ê³±í•˜ì—¬ ë¶€í˜¸ë¥¼ ë³€í™˜
                    adj_with_fs = adj_bspl_grouped.merge(
                        coa_df[["ê³„ì •ì½”ë“œ", "FS_Element"]], on="ê³„ì •ì½”ë“œ", how="left"
                    )
                    is_ler = adj_with_fs["FS_Element"].isin(["L", "E", "R", "CE"])
                    adj_with_fs.loc[is_ler, "ê¸ˆì•¡"] = (
                        adj_with_fs.loc[is_ler, "ê¸ˆì•¡"] * -1
                    )

                    merged_bspl_df = merged_bspl_df.merge(
                        adj_with_fs[["ê³„ì •ì½”ë“œ", "ê¸ˆì•¡"]].rename(
                            columns={"ê¸ˆì•¡": "ì—°ê²°ì¡°ì •"}
                        ),
                        on="ê³„ì •ì½”ë“œ",
                        how="left",
                        sort=False,
                    )
                    merged_bspl_df["ì—°ê²°ì¡°ì •"] = merged_bspl_df["ì—°ê²°ì¡°ì •"].fillna(0)
                else:
                    merged_bspl_df["ì—°ê²°ì¡°ì •"] = 0

                # ì—°ê²°ê¸ˆì•¡ ê³„ì‚°
                merged_bspl_df["ì—°ê²°ê¸ˆì•¡"] = (
                    merged_bspl_df["ë‹¨ìˆœí•©ê³„"] + merged_bspl_df["ì—°ê²°ì¡°ì •"]
                )

                # --- P/L ì¡°ì • í•©ê³„ë¥¼ BS(CE)ë¡œ ì´ì „ ë° ì°¨ëŒ€ê²€ì¦ ---
                # P/L ì¡°ì • í•©ê³„ë¥¼ BS(ì´ìµì‰ì—¬ê¸ˆ)ì— ë°˜ì˜

                r_adj_sum = merged_bspl_df.loc[
                    merged_bspl_df["FS_Element"] == "R", "ì—°ê²°ì¡°ì •"
                ].sum()
                x_adj_sum = merged_bspl_df.loc[
                    merged_bspl_df["FS_Element"] == "X", "ì—°ê²°ì¡°ì •"
                ].sum()
                pl_adj_sum = r_adj_sum - x_adj_sum

                if re_code:
                    target_row_mask = merged_bspl_df["ê³„ì •ì½”ë“œ"] == re_code
                    if target_row_mask.any():
                        merged_bspl_df.loc[target_row_mask, "ì—°ê²°ì¡°ì •"] += pl_adj_sum
                    else:
                        log_validation(
                            f"ğŸš¨ **[P/L to BS ì´ì „ ì˜¤ë¥˜]** Code ì‹œíŠ¸ì˜ ì´ìµì‰ì—¬ê¸ˆ ê³„ì •({re_code})ì„ CoAì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                        )
                else:
                    log_validation(
                        "ğŸš¨ **[P/L to BS ì´ì „ ì˜¤ë¥˜]** ì¡°ì •ë¶„ê°œ íŒŒì¼ì˜ Code ì‹œíŠ¸ì—ì„œ ì´ìµì‰ì—¬ê¸ˆ(E) ê³„ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                    )
                # ì—°ê²°ê¸ˆì•¡ ìµœì¢… ê³„ì‚°
                merged_bspl_df["ì—°ê²°ê¸ˆì•¡"] = (
                    merged_bspl_df["ë‹¨ìˆœí•©ê³„"] + merged_bspl_df["ì—°ê²°ì¡°ì •"]
                )

                # 3. ì—°ê²°ê¸ˆì•¡ ê¸°ì¤€ BS ì°¨ëŒ€ ê²€ì¦
                log_validation("--- ì—°ê²°ê¸ˆì•¡ ê¸°ì¤€ ì°¨ëŒ€ ê²€ì¦ ---")
                check_balance_sheet_equation(merged_bspl_df, coa_df, "ì—°ê²°ê¸ˆì•¡")
                # ------------------------------------------

                # ----------------------------------------------------------------
                # 3. CF ë°ì´í„° í†µí•© ë° ê³„ì‚°
                # ----------------------------------------------------------------
                CF_KEY = "CF_code"
                merged_cf_df = pd.DataFrame()
                if not cf_coa_df.empty and CF_KEY in cf_coa_df.columns:
                    # sort=Falseë¥¼ ì¶”ê°€í•˜ì—¬ CoA ìˆœì„œ ìœ ì§€
                    merged_cf_df = cf_coa_df.merge(
                        parent_cf_df[[CF_KEY, parent_name]],
                        on=CF_KEY,
                        how="left",
                        sort=False,
                    )
                    for name, df in zip(subs_names, subs_cf_dfs):
                        if CF_KEY in df.columns:
                            merged_cf_df = merged_cf_df.merge(
                                df[[CF_KEY, name]], on=CF_KEY, how="left", sort=False
                            )

                    cf_val_cols = [parent_name] + subs_names
                    merged_cf_df[cf_val_cols] = merged_cf_df[cf_val_cols].fillna(0)
                    merged_cf_df["ë‹¨ìˆœí•©ê³„"] = merged_cf_df[cf_val_cols].sum(axis=1)

                    # CF ì¡°ì •ë¶„ê°œ ì²˜ë¦¬ (ì—…ë¡œë“œëœ íŒŒì¼ë§Œ ì‚¬ìš©)
                    caje_cf_df = caje_cf_df_from_file

                    # ì‚¬ìš©ìì˜ ìš”ì²­ì— ë”°ë¼, 'ê³„ì •ì½”ë“œ'ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì¡°ì •ë¶„ê°œë¥¼ ë³‘í•©
                    if (
                        not caje_cf_df.empty
                        and "ê³„ì •ì½”ë“œ" in caje_cf_df.columns
                        and "ì¡°ì •ê¸ˆì•¡" in caje_cf_df.columns
                    ):
                        adj_cf_grouped = (
                            caje_cf_df.groupby("ê³„ì •ì½”ë“œ")["ì¡°ì •ê¸ˆì•¡"]
                            .sum()
                            .reset_index()
                        )

                        merged_cf_df = merged_cf_df.merge(
                            adj_cf_grouped.rename(columns={"ì¡°ì •ê¸ˆì•¡": "ì—°ê²°ì¡°ì •"}),
                            on="ê³„ì •ì½”ë“œ",
                            how="left",
                        )
                    else:
                        merged_cf_df["ì—°ê²°ì¡°ì •"] = 0

                    merged_cf_df["ì—°ê²°ì¡°ì •"] = merged_cf_df["ì—°ê²°ì¡°ì •"].fillna(0)
                    merged_cf_df["ì—°ê²°ê¸ˆì•¡"] = (
                        merged_cf_df["ë‹¨ìˆœí•©ê³„"] + merged_cf_df["ì—°ê²°ì¡°ì •"]
                    )

                # ----------------------------------------------------------------
                # 4. ì†Œê³„ ë° ìµœì¢… FS ìƒì„±
                # ----------------------------------------------------------------
                def generate_fs_with_subtotals(
                    df,
                    name_cols,
                    amount_cols,
                    name_code_map,
                    desc_col="ê³„ì •ëª…",
                    code_col="ê³„ì •ì½”ë“œ",
                ):
                    df = df.copy()

                    # Sign ë¡œì§ ì ìš©
                    apply_sign_logic = "sign" in df.columns
                    if apply_sign_logic:
                        df["sign"] = pd.to_numeric(df["sign"], errors="coerce").fillna(
                            1
                        )
                        for col in amount_cols:
                            if col in df.columns:
                                df[col] = df[col] * df["sign"]

                    # ì†Œê³„ ê³„ì‚°ì„ ìœ„í•œ ì¬ê·€ í•¨ìˆ˜
                    def recursive_subtotal(data, current_name_cols, level=0):
                        if not current_name_cols or data.empty:
                            return data

                        current_col, remaining_cols = (
                            current_name_cols[0],
                            current_name_cols[1:],
                        )
                        all_sub_dfs = []

                        # ë ˆë²¨ ì •ë³´ê°€ ìˆëŠ” ê·¸ë£¹ ë¨¼ì € ì²˜ë¦¬
                        for key, group in data.dropna(subset=[current_col]).groupby(
                            current_col, sort=False
                        ):
                            sub_df = recursive_subtotal(
                                group, remaining_cols, level + 1
                            )

                            # í•©ê³„ í–‰ ìƒì„±
                            sum_data = {col: "" for col in data.columns}
                            sum_data.update(group[amount_cols].sum())
                            sum_data[desc_col] = f"{'' * level}{key}"  # ë“¤ì—¬ì“°ê¸°
                            sum_data[code_col] = name_code_map.get(key, "")

                            # FS_Element, sign ë“± ë©”íƒ€ë°ì´í„° ë³µì‚¬
                            if not group.empty:
                                for col in ["FS_Element", "sign"]:
                                    if col in group.columns:
                                        sum_data[col] = group.iloc[0][col]

                            sum_row = pd.DataFrame([sum_data])
                            all_sub_dfs.append(
                                pd.concat([sub_df, sum_row], ignore_index=True)
                            )

                        # ë ˆë²¨ ì •ë³´ê°€ ì—†ëŠ”(NaN) ê·¸ë£¹ì„ ë‚˜ì¤‘ì— ì²˜ë¦¬í•˜ì—¬ ì•„ë˜ë¡œ ë³´ëƒ„
                        nan_group = data[data[current_col].isna()]
                        if not nan_group.empty:
                            all_sub_dfs.append(
                                recursive_subtotal(nan_group, remaining_cols, level + 1)
                            )

                        # all_sub_dfsê°€ ë¹„ì–´ìˆëŠ” ê²½ìš° ì—ëŸ¬ ë°©ì§€
                        if not all_sub_dfs:
                            return pd.DataFrame(columns=data.columns)

                        return pd.concat(all_sub_dfs, ignore_index=True)

                    final_df = recursive_subtotal(df, name_cols)

                    # Sign ì›ë³µ
                    if apply_sign_logic and not final_df.empty:
                        final_df["sign"] = (
                            pd.to_numeric(final_df["sign"], errors="coerce")
                            .fillna(1)
                            .replace(0, 1)
                        )
                        final_df[amount_cols] = final_df[amount_cols].divide(
                            final_df["sign"], axis=0
                        )

                    return final_df

                # BS, PL, CF ë°ì´í„° ë¶„ë¦¬ ë° ì†Œê³„ ìƒì„±
                df_bs = merged_bspl_df[
                    merged_bspl_df["FS_Element"].isin(["A", "L", "E", "CA", "CE"])
                ].copy()
                df_bs["sign"] = (
                    df_bs["FS_Element"]
                    .map({"A": -1, "CA": -1, "L": 1, "E": 1, "CE": 1})
                    .fillna(1)
                )

                df_pl = merged_bspl_df[
                    merged_bspl_df["FS_Element"].isin(["R", "X"])
                ].copy()
                df_pl["sign"] = df_pl["FS_Element"].map({"R": 1, "X": -1}).fillna(1)

                df_cf = merged_cf_df.copy()
                if "FS_Element" in df_cf.columns:  # CFì˜ FS_ElementëŠ” ë¶€í˜¸ë¡œ ì‚¬ìš©
                    df_cf["sign"] = pd.to_numeric(
                        df_cf["FS_Element"], errors="coerce"
                    ).fillna(1)

                # ì†Œê³„ ìƒì„±ì„ ìœ„í•œ ì„¤ì •
                con_amtcols = (
                    [parent_name] + subs_names + ["ë‹¨ìˆœí•©ê³„", "ì—°ê²°ì¡°ì •", "ì—°ê²°ê¸ˆì•¡"]
                )
                bspl_name_cols = [
                    c
                    for c in coa_df.columns
                    if c.startswith("L") and not c.endswith("code")
                ]
                cf_name_cols = [
                    c
                    for c in cf_coa_df.columns
                    if c.startswith("L") and not c.endswith("code")
                ]

                # ì´ë¦„-ì½”ë“œ ë§¤í•‘ ìƒì„±
                bspl_name_code_map = {
                    row[name]: row[code]
                    for code, name in zip(
                        [
                            c
                            for c in coa_df.columns
                            if c.startswith("L") and c.endswith("code")
                        ],
                        bspl_name_cols,
                    )
                    for _, row in coa_df.iterrows()
                    if pd.notna(row.get(name))
                }
                cf_name_code_map = {
                    row[name]: row[code]
                    for code, name in zip(
                        [
                            c
                            for c in cf_coa_df.columns
                            if c.startswith("L") and c.endswith("code")
                        ],
                        cf_name_cols,
                    )
                    for _, row in cf_coa_df.iterrows()
                    if pd.notna(row.get(name))
                }

                # ìµœì¢… FS ìƒì„±
                bs_final = generate_fs_with_subtotals(
                    df_bs, bspl_name_cols, con_amtcols, bspl_name_code_map
                )
                pl_final = generate_fs_with_subtotals(
                    df_pl, bspl_name_cols, con_amtcols, bspl_name_code_map
                )
                cf_final = generate_fs_with_subtotals(
                    df_cf,
                    cf_name_cols,
                    con_amtcols,
                    cf_name_code_map,
                    desc_col="í˜„ê¸ˆíë¦„í‘œ",
                    code_col="CF_code",
                )

                # ë¶ˆí•„ìš”í•œ ë ˆë²¨ ì»¬ëŸ¼ ì œê±° ë° ìµœì¢… ì •ë¦¬
                level_cols = [c for c in coa_df.columns if c.startswith("L")] + [
                    c for c in cf_coa_df.columns if c.startswith("L")
                ]
                l_cols_to_drop = list(set(level_cols + ["sign"]))
                bs_final.drop(
                    columns=[c for c in l_cols_to_drop if c in bs_final.columns],
                    inplace=True,
                )
                pl_final.drop(
                    columns=[c for c in l_cols_to_drop if c in pl_final.columns],
                    inplace=True,
                )
                cf_final.drop(
                    columns=[c for c in l_cols_to_drop if c in cf_final.columns],
                    inplace=True,
                )

                # ì†Œê³„ í–‰ ì‹ë³„ ë° 'is_subtotal' ì»¬ëŸ¼ ì¶”ê°€
                bspl_name_cols = [
                    c
                    for c in coa_df.columns
                    if c.startswith("L") and not c.endswith("code")
                ]
                if bspl_name_cols:
                    bspl_subtotal_names = set(coa_df[bspl_name_cols].stack().unique())
                    if not bs_final.empty:
                        bs_final["is_subtotal"] = bs_final["ê³„ì •ëª…"].isin(
                            bspl_subtotal_names
                        )
                    if not pl_final.empty:
                        pl_final["is_subtotal"] = pl_final["ê³„ì •ëª…"].isin(
                            bspl_subtotal_names
                        )

                cf_name_cols = [
                    c
                    for c in cf_coa_df.columns
                    if c.startswith("L") and not c.endswith("code")
                ]
                if not cf_coa_df.empty and cf_name_cols:
                    cf_subtotal_names = set(cf_coa_df[cf_name_cols].stack().unique())
                    if not cf_final.empty:
                        cf_final["is_subtotal"] = cf_final["í˜„ê¸ˆíë¦„í‘œ"].isin(
                            cf_subtotal_names
                        )

                # 0ì— ê°€ê¹Œìš´ ê°’ ì •ë¦¬ ë° ì •ìˆ˜ ë³€í™˜
                processed_dfs = []
                for df in [bs_final, pl_final, cf_final]:
                    if not df.empty:
                        df = df.copy()
                        amt_cols_in_df = [c for c in con_amtcols if c in df.columns]

                        if amt_cols_in_df:
                            df.loc[
                                (df[amt_cols_in_df].abs().sum(axis=1)) < 0.01,
                                amt_cols_in_df,
                            ] = 0
                            df[amt_cols_in_df] = (
                                df[amt_cols_in_df].fillna(0).round().astype("int64")
                            )

                            # ê¸ˆì•¡ì´ ëª¨ë‘ 0ì´ë©´ì„œ ì†Œê³„ê°€ ì•„ë‹Œ í–‰ì„ ì œê±°
                            if "is_subtotal" in df.columns:
                                all_zeros = (df[amt_cols_in_df] == 0).all(axis=1)
                                is_not_subtotal = df["is_subtotal"] == False
                                rows_to_remove = all_zeros & is_not_subtotal
                                df = df[~rows_to_remove]
                            else:
                                log_validation(
                                    "âš ï¸ ê²½ê³ : 'is_subtotal' ì»¬ëŸ¼ì´ ì—†ì–´ ì¼ë¶€ 0ì› í–‰ì´ ì œê±°ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                                )
                    processed_dfs.append(df)
                bs_final, pl_final, cf_final = processed_dfs

                # --- CF ê²€ì¦ ë¡œì§ ì¶”ê°€ (ì—°ê²°ì¡°ì • í•©ê³„) ---
                if (
                    not df_cf.empty
                    and "ì—°ê²°ì¡°ì •" in df_cf.columns
                    and "sign" in df_cf.columns
                ):
                    # Signì„ ë°˜ì˜í•œ ì—°ê²°ì¡°ì • ê¸ˆì•¡ì˜ í•©ê³„ê°€ 0ì¸ì§€ ê²€ì¦
                    total_cf_adjustment = (df_cf["ì—°ê²°ì¡°ì •"] * df_cf["sign"]).sum()
                    if abs(total_cf_adjustment) > 1:  # ì‚¬ì†Œí•œ ë°˜ì˜¬ë¦¼ ì˜¤ë¥˜ëŠ” ë¬´ì‹œ
                        log_validation(
                            f"âŒ **[í˜„ê¸ˆíë¦„í‘œ ê²€ì¦]** ì—°ê²°ì¡°ì •ì˜ í•©ê³„(ë¶€í˜¸ ë°˜ì˜)ê°€ 0ì´ ì•„ë‹™ë‹ˆë‹¤: {total_cf_adjustment:,.0f}"
                        )
                    else:
                        log_validation(
                            f"âœ… **[í˜„ê¸ˆíë¦„í‘œ ê²€ì¦]** ì—°ê²°ì¡°ì •ì˜ í•©ê³„(ë¶€í˜¸ ë°˜ì˜)ê°€ 0ìœ¼ë¡œ ì¼ì¹˜í•©ë‹ˆë‹¤."
                        )
                # -----------------------------------------

                # ì„¸ì…˜ ìƒíƒœì— ê²°ê³¼ ì €ì¥
                st.session_state.results["consolidation_wp_bs"] = bs_final
                st.session_state.results["consolidation_wp_pl"] = pl_final
                st.session_state.results["consolidation_wp_cf"] = cf_final

                st.success("ğŸ‰ ì—°ê²° ì¬ë¬´ì œí‘œ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

            except Exception as e:
                st.error(f"ì—°ê²° ì¬ë¬´ì œí‘œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                st.exception(e)  # ê°œë°œ/ë””ë²„ê¹… ì‹œ tracebackì„ ë³´ê¸° ìœ„í•´ ì¶”ê°€

    # --- ê²°ê³¼ í‘œì‹œ ---
    if st.session_state.results["validation_log"]:
        with st.expander("ğŸ” ë°ì´í„° ê²€ì¦ ë¡œê·¸ ë³´ê¸°", expanded=True):
            for log in st.session_state.results["validation_log"]:
                st.markdown(log, unsafe_allow_html=True)

    if (
        st.session_state.results.get("consolidation_wp_bs") is not None
        and not st.session_state.results["consolidation_wp_bs"].empty
    ):
        st.subheader("ğŸ“„ ì—°ê²° ì¬ë¬´ìƒíƒœí‘œ")
        st.dataframe(
            st.session_state.results["consolidation_wp_bs"].style.format(
                precision=0, thousands=","
            )
        )

        st.subheader("ğŸ“„ ì—°ê²° ì†ìµê³„ì‚°ì„œ")
        st.dataframe(
            st.session_state.results["consolidation_wp_pl"].style.format(
                precision=0, thousands=","
            )
        )

        st.subheader("ğŸ“„ ì—°ê²° í˜„ê¸ˆíë¦„í‘œ")
        st.dataframe(
            st.session_state.results["consolidation_wp_cf"].style.format(
                precision=0, thousands=","
            )
        )

        # --- ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ---
        excel_data = to_excel(
            {
                "Consol_BS": st.session_state.results["consolidation_wp_bs"],
                "Consol_PL": st.session_state.results["consolidation_wp_pl"],
                "Consol_CF": st.session_state.results["consolidation_wp_cf"],
            }
        )
        st.download_button(
            label="ğŸ“¥ ì „ì²´ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (Excel)",
            data=excel_data,
            file_name="consolidated_fs_results.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        )
    elif not (st.session_state.files["coa"] and st.session_state.files["parent"]):
        st.info(
            "ì‚¬ì´ë“œë°”ì—ì„œ CoAì™€ ëª¨íšŒì‚¬ íŒŒì¼ì„ ì—…ë¡œë“œí•œ í›„ 'ìƒì„± ì‹¤í–‰' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”."
        )

with tab2:
    st.header("2. ì£¼ì„ ëŒ€ì‚¬ (Reconciliation)")
    st.write(
        "ëª¨íšŒì‚¬ ì£¼ì„ì„ ê¸°ì¤€ìœ¼ë¡œ ìíšŒì‚¬ ì£¼ì„ë“¤ì˜ ìˆ«ì ë°ì´í„°ë¥¼ ìœ„ì¹˜ ê¸°ë°˜ìœ¼ë¡œ í•©ì‚°í•˜ê³ , ì—°ê²°ì •ì‚°í‘œì™€ ëŒ€ì‚¬í•©ë‹ˆë‹¤."
    )
    footnote_parent_file = st.file_uploader("1. ëª¨íšŒì‚¬ ì£¼ì„ íŒŒì¼", type="xlsx")
    footnote_subs_files = st.file_uploader(
        "2. ìíšŒì‚¬ ì£¼ì„ íŒŒì¼ (ë‹¤ì¤‘ ì„ íƒ ê°€ëŠ¥)", type="xlsx", accept_multiple_files=True
    )
    if st.button("ğŸ”„ ì£¼ì„ ëŒ€ì‚¬ ì‹¤í–‰", disabled=not footnote_parent_file):
        if (
            st.session_state.results.get("consolidation_wp_bs") is None
            and footnote_subs_files
        ):
            st.warning(
                "ëŒ€ì‚¬ë¥¼ ìœ„í•´ì„œëŠ” ë¨¼ì € 'ì—°ê²° ì¬ë¬´ì œí‘œ' íƒ­ì—ì„œ 'ìƒì„± ì‹¤í–‰'ì„ ì™„ë£Œí•´ì•¼ í•©ë‹ˆë‹¤."
            )
            st.stop()
        with st.spinner("ì£¼ì„ íŒŒì¼ì„ ì·¨í•©í•˜ê³  ëŒ€ì‚¬í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            try:
                st.session_state.results["combined_footnotes"] = {}
                parent_sheets = pd.read_excel(
                    footnote_parent_file, sheet_name=None, dtype=str
                )
                subs_files_data = [
                    (Path(f.name).stem, pd.read_excel(f, sheet_name=None, dtype=str))
                    for f in footnote_subs_files
                ]

                conso_wp_df = pd.concat(
                    [
                        st.session_state.results.get(
                            "consolidation_wp_bs", pd.DataFrame()
                        ),
                        st.session_state.results.get(
                            "consolidation_wp_pl", pd.DataFrame()
                        ),
                    ]
                )
                conso_map = (
                    conso_wp_df.set_index("ê³„ì •ì½”ë“œ")["ì—°ê²°ê¸ˆì•¡"].to_dict()
                    if not conso_wp_df.empty
                    else {}
                )

                for sheet_name, parent_df in parent_sheets.items():
                    if "ì£¼ì„" not in sheet_name:
                        continue
                    all_dfs_for_sheet = []
                    parent_df_copy = parent_df.copy()
                    parent_df_copy["ì†ŒìŠ¤íŒŒì¼"] = Path(footnote_parent_file.name).stem
                    all_dfs_for_sheet.append(parent_df_copy)
                    for name, sheets in subs_files_data:
                        if sheet_name in sheets:
                            sub_df_copy = sheets[sheet_name].copy()
                            sub_df_copy["ì†ŒìŠ¤íŒŒì¼"] = name
                            all_dfs_for_sheet.append(sub_df_copy)
                    should_concat = any(
                        pd.to_numeric(df[col], errors="coerce").isna().any()
                        for df in all_dfs_for_sheet
                        for col in df.columns[2:-1]
                        if len(df.columns) > 3
                    )
                    if should_concat:
                        final_df = pd.concat(all_dfs_for_sheet, ignore_index=True)
                    else:
                        final_df = all_dfs_for_sheet[0].copy()
                        value_cols = final_df.columns[2:-1]
                        final_df[value_cols] = (
                            final_df[value_cols]
                            .apply(pd.to_numeric, errors="coerce")
                            .fillna(0)
                        )
                        for next_df in all_dfs_for_sheet[1:]:
                            next_value_cols = next_df.columns[2:-1]
                            next_df[next_value_cols] = (
                                next_df[next_value_cols]
                                .apply(pd.to_numeric, errors="coerce")
                                .fillna(0)
                            )
                            final_df[value_cols] = final_df[value_cols].add(
                                next_df[next_value_cols].values, fill_value=0
                            )
                        if footnote_subs_files:
                            final_df["ì†ŒìŠ¤íŒŒì¼"] = "combined"
                        if "ê³„ì •ì½”ë“œ" in final_df.columns and not conso_wp_df.empty:
                            numeric_cols = final_df.select_dtypes(
                                include="number"
                            ).columns
                            if not numeric_cols.empty:
                                last_numeric_col = numeric_cols[-1]
                                if "ì—°ê²°ì¡°ì •" in conso_wp_df.columns:
                                    adj_map = conso_wp_df.set_index("ê³„ì •ì½”ë“œ")[
                                        "ì—°ê²°ì¡°ì •"
                                    ].to_dict()
                                    final_df["ê³„ì •ì½”ë“œ_str"] = (
                                        final_df["ê³„ì •ì½”ë“œ"].astype(str).str.strip()
                                    )
                                    adj_values = (
                                        final_df["ê³„ì •ì½”ë“œ_str"].map(adj_map).fillna(0)
                                    )
                                    final_df[last_numeric_col] += adj_values
                                    final_df = final_df.drop(columns=["ê³„ì •ì½”ë“œ_str"])
                        if "ê³„ì •ì½”ë“œ" in final_df.columns and conso_map:
                            last_numeric_col = final_df.select_dtypes(
                                include="number"
                            ).columns[-1]

                            def check_value_match(row):
                                code = str(row["ê³„ì •ì½”ë“œ"]).strip()
                                if not code:
                                    return ""
                                footnote_value = row[last_numeric_col]
                                conso_value = conso_map.get(code)
                                if conso_value is None:
                                    return "ë¶ˆì¼ì¹˜ (ì •ì‚°í‘œì— ì½”ë“œ ì—†ìŒ)"
                                if abs(footnote_value - conso_value) < 1:
                                    return "ì¼ì¹˜"
                                else:
                                    return f"ë¶ˆì¼ì¹˜ (ì°¨ì´: {footnote_value - conso_value:,.0f})"

                            final_df["ëŒ€ì‚¬ê²°ê³¼"] = final_df.apply(
                                check_value_match, axis=1
                            )
                    st.session_state.results["combined_footnotes"][
                        sheet_name
                    ] = final_df
                st.success("ğŸ‰ ì£¼ì„ ì·¨í•© ë° ëŒ€ì‚¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            except Exception as e:
                st.error(f"ì£¼ì„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

    if st.session_state.results.get("combined_footnotes"):
        st.subheader("ğŸ“’ ì·¨í•©ëœ ì£¼ì„ ë°ì´í„°")
        for sheet_name, df in st.session_state.results["combined_footnotes"].items():
            with st.expander(f"ì‹œíŠ¸: {sheet_name}", expanded=False):
                st.dataframe(df)
        footnote_excel_data = to_excel(st.session_state.results["combined_footnotes"])
        st.download_button(
            label="ğŸ“¥ ì·¨í•©ëœ ì£¼ì„ ë‹¤ìš´ë¡œë“œ (Excel)",
            data=footnote_excel_data,
            file_name="combined_footnotes.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        )

with tab3:
    st.header("3. ì—°ê²° ì¡°ì • ë¶„ê°œ ìƒì„±")
    st.write(
        "ê¸°ë³¸ ì¡°ì •ë¶„ê°œ ì…ë ¥ í›„, ë²•ì¸ì„¸/ë¹„ì§€ë°°ì§€ë¶„(NCI) ì¡°ì •ì„ ìë™ ê³„ì‚°í•˜ê³ , ìµœì¢… ê²€í†  í›„ ì „ì²´ ì¡°ì •ë¶„ê°œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
    )

    # --- Session State for Tab 3 ---
    if "adj_workflow" not in st.session_state:
        st.session_state.adj_workflow = {
            "initial_file": None,
            "intermediate_data": None,
            "final_file": None,
        }

    @st.cache_data
    def create_adjustment_template():
        adjustment_types = [
            "CAJE00_íˆ¬ììë³¸ìƒê³„",
            "CAJE01_ì±„ê¶Œì±„ë¬´ì œê±°",
            "CAJE02_ì œí’ˆë¯¸ì‹¤í˜„ì´ìµì œê±°",
            "CAJE03_ìƒê°ìì‚°ë¯¸ì‹¤í˜„ì´ìµì œê±°",
            "CAJE04_ë°°ë‹¹ì¡°ì •",
            "CAJE05_ê¸°íƒ€ì†ìµì¡°ì •",
            "CAJE96_ì·¨ë“ì¼ì°¨ì´ì¡°ì •",
            "CAJE97_ë²•ì¸ì„¸ì¡°ì •",
            "CAJE98_ë¹„ì§€ë°°ì§€ë¶„ì¡°ì •",
            "CAJE99_ê¸°íƒ€ì¡°ì •",
        ]
        columns = ["íšŒì‚¬ëª…", "ê³„ì •ì½”ë“œ", "ê³„ì •ëª…", "ë‹¹ê¸°ì „ê¸°", "ê¸ˆì•¡", "ì„¤ëª…"]
        output = io.BytesIO()

        with pd.ExcelWriter(output, engine="openpyxl") as writer:
            # 'Info' ì‹œíŠ¸ ìƒì„±
            info_data = {
                "ë‹¹ê¸°ì„¸ìœ¨": [0.2, 0.18, 0.16],
                "ì „ê¸°ì„¸ìœ¨": [0.22, 0.20, 0.18],
                "ë‹¹ê¸°ì§€ë¶„ìœ¨": [1, 0.60, 0.80],
                "ì „ê¸°ì§€ë¶„ìœ¨": [1, 0.60, 0.80],
            }
            info_index_labels = ["ëª¨íšŒì‚¬", "ìíšŒì‚¬A", "ìíšŒì‚¬B"]
            info_df = pd.DataFrame(info_data, index=info_index_labels)
            info_df.index.name = "íšŒì‚¬ëª…"
            info_df.to_excel(writer, sheet_name="Info")

            # 'Info' ì‹œíŠ¸ ìŠ¤íƒ€ì¼ ì ìš©
            ws_info = writer.sheets["Info"]
            header_font = Font(bold=True, color="FFFFFF")
            header_fill = PatternFill(
                start_color="4F81BD", end_color="4F81BD", fill_type="solid"
            )
            header_alignment = Alignment(
                horizontal="center", vertical="center", wrap_text=True
            )
            for cell in ws_info[1]:
                cell.font = header_font
                cell.fill = header_fill
                cell.alignment = header_alignment
            ws_info.column_dimensions[get_column_letter(1)].width = 20
            for i, col_name in enumerate(info_df.columns, 2):
                ws_info.column_dimensions[get_column_letter(i)].width = 20

            for sheet_name in adjustment_types:
                if sheet_name == "CAJE00_íˆ¬ììë³¸ìƒê³„":
                    example_data = [
                        {
                            "íšŒì‚¬ëª…": "ëª¨íšŒì‚¬",
                            "ê³„ì •ì½”ë“œ": "19200",
                            "ê³„ì •ëª…": "ì¢…ì†ê¸°ì—…íˆ¬ì",
                            "ë‹¹ê¸°ì „ê¸°": "ì·¨ë“ì¼",
                            "ê¸ˆì•¡": 3400000,
                            "ì„¤ëª…": "ìíšŒì‚¬A íˆ¬ìê¸ˆì•¡ ì œê±°",
                        },
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "33100",
                            "ê³„ì •ëª…": "ìë³¸ê¸ˆ",
                            "ë‹¹ê¸°ì „ê¸°": "ì·¨ë“ì¼",
                            "ê¸ˆì•¡": 3000000,
                            "ì„¤ëª…": "ìíšŒì‚¬A ìë³¸ê¸ˆ ì œê±°",
                        },
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "37500",
                            "ê³„ì •ëª…": "ì´ìµì‰ì—¬ê¸ˆ",
                            "ë‹¹ê¸°ì „ê¸°": "ì·¨ë“ì¼",
                            "ê¸ˆì•¡": 1000000,
                            "ì„¤ëª…": "ìíšŒì‚¬A ì´ìµì‰ì—¬ê¸ˆ(ì·¨ë“ì‹œì ) ì œê±°",
                        },
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "20600",
                            "ê³„ì •ëª…": "ê¸°ê³„ì¥ì¹˜",
                            "ë‹¹ê¸°ì „ê¸°": "ì·¨ë“ì¼",
                            "ê¸ˆì•¡": -800000,
                            "ì„¤ëª…": "ìíšŒì‚¬A ê³µì •ê°€ì¹˜ì°¨ì´ ê³„ìƒ",
                        },
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "101000",
                            "ê³„ì •ëª…": "ì˜ì—…ê¶Œ",
                            "ë‹¹ê¸°ì „ê¸°": "ì·¨ë“ì¼",
                            "ê¸ˆì•¡": -200000,
                            "ì„¤ëª…": "ìíšŒì‚¬A ì˜ì—…ê¶Œ ê³„ìƒ",
                        },
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "201200",
                            "ê³„ì •ëª…": "ë¹„ì§€ë°°ì§€ë¶„",
                            "ë‹¹ê¸°ì „ê¸°": "ì·¨ë“ì¼",
                            "ê¸ˆì•¡": -1600000,
                            "ì„¤ëª…": "ìíšŒì‚¬A ë¹„ì§€ë°°ì§€ë¶„ ê³„ìƒ",
                        },
                    ]
                    df = pd.DataFrame(example_data)
                elif sheet_name == "CAJE01_ì±„ê¶Œì±„ë¬´ì œê±°":
                    example_data = [
                        {
                            "íšŒì‚¬ëª…": "ëª¨íšŒì‚¬",
                            "ê³„ì •ì½”ë“œ": "10800",
                            "ê³„ì •ëª…": "ë§¤ì¶œì±„ê¶Œ",
                            "ë‹¹ê¸°ì „ê¸°": "ì „ê¸°",
                            "ê¸ˆì•¡": 20000000,
                            "ì„¤ëª…": "ìíšŒì‚¬Aì— ëŒ€í•œ ë§¤ì¶œì±„ê¶Œ ì œê±°",
                        },
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "25100",
                            "ê³„ì •ëª…": "ë§¤ì…ì±„ë¬´",
                            "ë‹¹ê¸°ì „ê¸°": "ì „ê¸°",
                            "ê¸ˆì•¡": 20000000,
                            "ì„¤ëª…": "ëª¨íšŒì‚¬ì— ëŒ€í•œ ë§¤ì…ì±„ë¬´ ì œê±°",
                        },
                        {
                            "íšŒì‚¬ëª…": "ëª¨íšŒì‚¬",
                            "ê³„ì •ì½”ë“œ": "10800",
                            "ê³„ì •ëª…": "ë§¤ì¶œì±„ê¶Œ",
                            "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°",
                            "ê¸ˆì•¡": 10000000,
                            "ì„¤ëª…": "ìíšŒì‚¬Aì— ëŒ€í•œ ë§¤ì¶œì±„ê¶Œ ì œê±°",
                        },
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "25100",
                            "ê³„ì •ëª…": "ë§¤ì…ì±„ë¬´",
                            "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°",
                            "ê¸ˆì•¡": 10000000,
                            "ì„¤ëª…": "ëª¨íšŒì‚¬ì— ëŒ€í•œ ë§¤ì…ì±„ë¬´ ì œê±°",
                        },
                    ]
                    df = pd.DataFrame(example_data)
                elif sheet_name == "CAJE02_ì œí’ˆë¯¸ì‹¤í˜„ì´ìµì œê±°":
                    example_data = [
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "45500",
                            "ê³„ì •ëª…": "ë§¤ì¶œì›ê°€",
                            "ë‹¹ê¸°ì „ê¸°": "ì „ê¸°",
                            "ê¸ˆì•¡": 3000000,
                            "ì„¤ëª…": "ì „ê¸° ë¯¸ì‹¤í˜„ì´ìµ",
                        },
                        {
                            "íšŒì‚¬ëª…": "ëª¨íšŒì‚¬",
                            "ê³„ì •ì½”ë“œ": "37500",
                            "ê³„ì •ëª…": "ì´ìµì‰ì—¬ê¸ˆ",
                            "ë‹¹ê¸°ì „ê¸°": "ì „ê¸°",
                            "ê¸ˆì•¡": 3000000,
                            "ì„¤ëª…": "ì „ê¸° ë¯¸ì‹¤í˜„ì´ìµ(ì´ìµì‰ì—¬ê¸ˆ)",
                        },
                        {
                            "íšŒì‚¬ëª…": "ëª¨íšŒì‚¬",
                            "ê³„ì •ì½”ë“œ": "40200",
                            "ê³„ì •ëª…": "ë§¤ì¶œ",
                            "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°",
                            "ê¸ˆì•¡": 10000000,
                            "ì„¤ëª…": "ë‹¹ê¸° íŒë§¤ë¶„ ë§¤ì¶œ",
                        },
                        {
                            "íšŒì‚¬ëª…": "ëª¨íšŒì‚¬",
                            "ê³„ì •ì½”ë“œ": "45500",
                            "ê³„ì •ëª…": "ë§¤ì¶œì›ê°€",
                            "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°",
                            "ê¸ˆì•¡": 6000000,
                            "ì„¤ëª…": "ë‹¹ê¸° íŒë§¤ë¶„ ë§¤ì¶œì›ê°€",
                        },
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "15200",
                            "ê³„ì •ëª…": "ì œí’ˆ(ì¬ê³ ìì‚°)",
                            "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°",
                            "ê¸ˆì•¡": 4000000,
                            "ì„¤ëª…": "ëª¨íšŒì‚¬ê°€ íŒë§¤í•œ ì¬ê³  ë¯¸ì‹¤í˜„ì´ìµ ì œê±°(ì¬ê³ ê°ì†Œ)",
                        },
                    ]
                    df = pd.DataFrame(example_data)
                elif sheet_name == "CAJE03_ìƒê°ìì‚°ë¯¸ì‹¤í˜„ì´ìµì œê±°":
                    example_data = [
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "20600",
                            "ê³„ì •ëª…": "ê¸°ê³„ì¥ì¹˜",
                            "ë‹¹ê¸°ì „ê¸°": "ì „ê¸°",
                            "ê¸ˆì•¡": 5000000,
                            "ì„¤ëª…": "ìíšŒì‚¬Aì—ì„œ ëª¨íšŒì‚¬ì— ì²˜ë¶„",
                        },
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "37500",
                            "ê³„ì •ëª…": "ì´ìµì‰ì—¬ê¸ˆ",
                            "ë‹¹ê¸°ì „ê¸°": "ì „ê¸°",
                            "ê¸ˆì•¡": 5000000,
                            "ì„¤ëª…": "ìíšŒì‚¬A ê³„ìƒ ìœ í˜•ìì‚°ì²˜ë¶„ì´ìµ",
                        },
                        {
                            "íšŒì‚¬ëª…": "ëª¨íšŒì‚¬",
                            "ê³„ì •ì½”ë“œ": "37500",
                            "ê³„ì •ëª…": "ì´ìµì‰ì—¬ê¸ˆ",
                            "ë‹¹ê¸°ì „ê¸°": "ì „ê¸°",
                            "ê¸ˆì•¡": -1000000,
                            "ì„¤ëª…": "ëª¨íšŒì‚¬ ê³„ìƒ ê°ê°€ìƒê°ë¹„ ì¦ë¶„ ì œê±°",
                        },
                        {
                            "íšŒì‚¬ëª…": "ëª¨íšŒì‚¬",
                            "ê³„ì •ì½”ë“œ": "20700",
                            "ê³„ì •ëª…": "ê¸°ê³„ì¥ì¹˜ê°ê°€ìƒê°ëˆ„ê³„ì•¡",
                            "ë‹¹ê¸°ì „ê¸°": "ì „ê¸°",
                            "ê¸ˆì•¡": -1000000,
                            "ì„¤ëª…": "ëª¨íšŒì‚¬ ê°ê°€ìƒê°ëˆ„ê³„ì•¡",
                        },
                        {
                            "íšŒì‚¬ëª…": "ëª¨íšŒì‚¬",
                            "ê³„ì •ì½”ë“œ": "81800",
                            "ê³„ì •ëª…": "ê°ê°€ìƒê°ë¹„",
                            "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°",
                            "ê¸ˆì•¡": 1000000,
                            "ì„¤ëª…": "ëª¨íšŒì‚¬ ê³„ìƒ ê°ê°€ìƒê°ë¹„ ì¦ë¶„ ì œê±°",
                        },
                        {
                            "íšŒì‚¬ëª…": "ëª¨íšŒì‚¬",
                            "ê³„ì •ì½”ë“œ": "20700",
                            "ê³„ì •ëª…": "ê¸°ê³„ì¥ì¹˜ê°ê°€ìƒê°ëˆ„ê³„ì•¡",
                            "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°",
                            "ê¸ˆì•¡": -1000000,
                            "ì„¤ëª…": "ëª¨íšŒì‚¬ ê°ê°€ìƒê°ëˆ„ê³„ì•¡",
                        },
                    ]
                    df = pd.DataFrame(example_data)
                elif sheet_name == "CAJE04_ë°°ë‹¹ì¡°ì •":
                    example_data = [
                        {"íšŒì‚¬ëª…": "ëª¨íšŒì‚¬", "ê³„ì •ì½”ë“œ": "90300", "ê³„ì •ëª…": "ë°°ë‹¹ê¸ˆìˆ˜ìµ", "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°", "ê¸ˆì•¡": 2000000, "ì„¤ëª…": "ìíšŒì‚¬Aë¡œë¶€í„° ë°›ì€ ë°°ë‹¹ê¸ˆìˆ˜ìµ ì œê±°"},
                        {"íšŒì‚¬ëª…": "ìíšŒì‚¬A", "ê³„ì •ì½”ë“œ": "37500", "ê³„ì •ëª…": "ì´ìµì‰ì—¬ê¸ˆ", "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°", "ê¸ˆì•¡": -2000000, "ì„¤ëª…": "ëª¨íšŒì‚¬ì— ì§€ê¸‰í•œ ë°°ë‹¹ê¸ˆ íš¨ê³¼ ì œê±°"},
                    ]
                    df = pd.DataFrame(example_data)
                elif sheet_name == "CAJE96_ì·¨ë“ì¼ì°¨ì´ì¡°ì •":
                    example_data = [
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "37500",
                            "ê³„ì •ëª…": "ì´ìµì‰ì—¬ê¸ˆ",
                            "ë‹¹ê¸°ì „ê¸°": "ì „ê¸°",
                            "ê¸ˆì•¡": 160000,
                            "ì„¤ëª…": "ìíšŒì‚¬A ê³µì •ê°€ì¹˜ì°¨ì´ ìƒê°",
                        },
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "20700",
                            "ê³„ì •ëª…": "ê¸°ê³„ì¥ì¹˜ê°ê°€ìƒê°ëˆ„ê³„ì•¡",
                            "ë‹¹ê¸°ì „ê¸°": "ì „ê¸°",
                            "ê¸ˆì•¡": 160000,
                            "ì„¤ëª…": "ìíšŒì‚¬A ê³µì •ê°€ì¹˜ì°¨ì´ ìƒê°ëˆ„ê³„ì•¡",
                        },
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "81800",
                            "ê³„ì •ëª…": "ê°ê°€ìƒê°ë¹„",
                            "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°",
                            "ê¸ˆì•¡": -160000,
                            "ì„¤ëª…": "ìíšŒì‚¬A ê³µì •ê°€ì¹˜ì°¨ì´ ìƒê°",
                        },
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "20700",
                            "ê³„ì •ëª…": "ê¸°ê³„ì¥ì¹˜ê°ê°€ìƒê°ëˆ„ê³„ì•¡",
                            "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°",
                            "ê¸ˆì•¡": 160000,
                            "ì„¤ëª…": "ìíšŒì‚¬A ê³µì •ê°€ì¹˜ì°¨ì´ ìƒê°ëˆ„ê³„ì•¡",
                        },
                    ]
                    df = pd.DataFrame(example_data)
                elif sheet_name == "CAJE96_ì·¨ë“ì¼ì°¨ì´ì¡°ì •":
                    example_data = [
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "37500",
                            "ê³„ì •ëª…": "ì´ìµì‰ì—¬ê¸ˆ",
                            "ë‹¹ê¸°ì „ê¸°": "ì „ê¸°",
                            "ê¸ˆì•¡": 160000,
                            "ì„¤ëª…": "ìíšŒì‚¬A ê³µì •ê°€ì¹˜ì°¨ì´ ìƒê°",
                        },
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "20700",
                            "ê³„ì •ëª…": "ê¸°ê³„ì¥ì¹˜ê°ê°€ìƒê°ëˆ„ê³„ì•¡",
                            "ë‹¹ê¸°ì „ê¸°": "ì „ê¸°",
                            "ê¸ˆì•¡": 160000,
                            "ì„¤ëª…": "ìíšŒì‚¬A ê³µì •ê°€ì¹˜ì°¨ì´ ìƒê°ëˆ„ê³„ì•¡",
                        },
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "81800",
                            "ê³„ì •ëª…": "ê°ê°€ìƒê°ë¹„",
                            "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°",
                            "ê¸ˆì•¡": -160000,
                            "ì„¤ëª…": "ìíšŒì‚¬A ê³µì •ê°€ì¹˜ì°¨ì´ ìƒê°",
                        },
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "20700",
                            "ê³„ì •ëª…": "ê¸°ê³„ì¥ì¹˜ê°ê°€ìƒê°ëˆ„ê³„ì•¡",
                            "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°",
                            "ê¸ˆì•¡": 160000,
                            "ì„¤ëª…": "ìíšŒì‚¬A ê³µì •ê°€ì¹˜ì°¨ì´ ìƒê°ëˆ„ê³„ì•¡",
                        },
                    ]
                    df = pd.DataFrame(example_data)
                elif sheet_name == "CAJE97_ë²•ì¸ì„¸ì¡°ì •":
                    example_data = [
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "37500",
                            "ê³„ì •ëª…": "ì´ì›”ì´ìµì‰ì—¬ê¸ˆ",
                            "ë‹¹ê¸°ì „ê¸°": "ì·¨ë“ì¼",
                            "ê¸ˆì•¡": 144000,
                            "ì„¤ëª…": "ì·¨ë“ì¼ ê³µì •ê°€ì¹˜ì°¨ì´ ë²•ì¸ì„¸ íš¨ê³¼",
                        },
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "31000",
                            "ê³„ì •ëª…": "ì´ì—°ë²•ì¸ì„¸ë¶€ì±„",
                            "ë‹¹ê¸°ì „ê¸°": "ì·¨ë“ì¼",
                            "ê¸ˆì•¡": -144000,
                            "ì„¤ëª…": "ì·¨ë“ì¼ ê³µì •ê°€ì¹˜ì°¨ì´ ë²•ì¸ì„¸ íš¨ê³¼",
                        },
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "37500",
                            "ê³„ì •ëª…": "ì´ì›”ì´ìµì‰ì—¬ê¸ˆ",
                            "ë‹¹ê¸°ì „ê¸°": "ì „ê¸°",
                            "ê¸ˆì•¡": -28800,
                            "ì„¤ëª…": "ì·¨ë“ì¼ ê³µì •ê°€ì¹˜ì°¨ì´ ìƒê° ë²•ì¸ì„¸ íš¨ê³¼",
                        },
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "31000",
                            "ê³„ì •ëª…": "ì´ì—°ë²•ì¸ì„¸ë¶€ì±„",
                            "ë‹¹ê¸°ì „ê¸°": "ì „ê¸°",
                            "ê¸ˆì•¡": 28800,
                            "ì„¤ëª…": "ì·¨ë“ì¼ ê³µì •ê°€ì¹˜ì°¨ì´ ìƒê° ë²•ì¸ì„¸ íš¨ê³¼",
                        },
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "99800",
                            "ê³„ì •ëª…": "ë²•ì¸ì„¸ë¹„ìš©",
                            "ë‹¹ê¸°ì „ê¸°": "ì „ê¸°",
                            "ê¸ˆì•¡": -600000,
                            "ì„¤ëª…": "ì „ê¸° ì¬ê³  ë¯¸ì‹¤í˜„ì´ìµ ì‹¤í˜„(ëª¨íšŒì‚¬ ì„¸ìœ¨ 20%)",
                        },
                        {
                            "íšŒì‚¬ëª…": "ëª¨íšŒì‚¬",
                            "ê³„ì •ì½”ë“œ": "37500",
                            "ê³„ì •ëª…": "ì´ì›”ì´ìµì‰ì—¬ê¸ˆ",
                            "ë‹¹ê¸°ì „ê¸°": "ì „ê¸°",
                            "ê¸ˆì•¡": -600000,
                            "ì„¤ëª…": "ì „ê¸° ì¬ê³  ë¯¸ì‹¤í˜„ì´ìµ ì‹¤í˜„(ëª¨íšŒì‚¬ ì„¸ìœ¨ 20%)",
                        },
                    ]
                    df = pd.DataFrame(example_data)
                elif sheet_name == "CAJE98_ë¹„ì§€ë°°ì§€ë¶„ì¡°ì •":
                    example_data = [
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "37500",
                            "ê³„ì •ëª…": "ì´ì›”ì´ìµì‰ì—¬ê¸ˆ",
                            "ë‹¹ê¸°ì „ê¸°": "ì „ê¸°",
                            "ê¸ˆì•¡": 500000,
                            "ì„¤ëª…": "ì „ê¸° ëˆ„ì  ìë³¸ë³€ë™ ë¹„ì§€ë°°ì§€ë¶„",
                        },
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "102000",
                            "ê³„ì •ëª…": "ë¹„ì§€ë°°ì§€ë¶„",
                            "ë‹¹ê¸°ì „ê¸°": "ì „ê¸°",
                            "ê¸ˆì•¡": -500000,
                            "ì„¤ëª…": "ì „ê¸° ëˆ„ì  ìë³¸ë³€ë™ ë¹„ì§€ë°°ì§€ë¶„",
                        },
                    ]
                    df = pd.DataFrame(example_data)
                else:
                    df = pd.DataFrame(columns=columns)
                df = df.reindex(columns=columns)
                df.to_excel(writer, sheet_name=sheet_name, index=False)
                ws = writer.sheets[sheet_name]
                header_font = Font(bold=True, color="FFFFFF")
                header_fill = PatternFill(
                    start_color="4F81BD", end_color="4F81BD", fill_type="solid"
                )
                header_alignment = Alignment(
                    horizontal="center", vertical="center", wrap_text=True
                )
                for cell in ws[1]:
                    cell.font = header_font
                    cell.fill = header_fill
                    cell.alignment = header_alignment
                for i, column_name in enumerate(df.columns, 1):
                    ws.column_dimensions[get_column_letter(i)].width = 20

            # --- ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬ ì¶”ê°€ ---
            num_companies = len(info_index_labels)
            validation_formula = f"='Info'!$A$2:$A${num_companies + 1}"
            dv = DataValidation(
                type="list", formula1=validation_formula, allow_blank=True
            )
            dv.error = "ëª©ë¡ì— ìˆëŠ” ê°’ë§Œ ì…ë ¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            dv.errorTitle = "ì˜ëª»ëœ ì…ë ¥"
            dv.prompt = "ëª©ë¡ì—ì„œ íšŒì‚¬ëª…ì„ ì„ íƒí•˜ì„¸ìš”."
            dv.promptTitle = "íšŒì‚¬ëª… ì„ íƒ"

            target_range = "A2:A100001"
            for sheet_name in adjustment_types:
                if sheet_name != "Info":
                    ws = writer.sheets[sheet_name]
                    ws.add_data_validation(dv)
                    dv.add(target_range)
        return output.getvalue()

    def generate_intermediate_adjustments(adj_file, coa_df, subs_files, subs_names, aje_code):
        adj_file.seek(0)
        xls = pd.ExcelFile(adj_file)
        original_sheets = {
            sheet_name: pd.read_excel(xls, sheet_name, dtype={"ê³„ì •ì½”ë“œ": str}) for sheet_name in xls.sheet_names
        }

        if "Info" not in original_sheets:
            st.error("'Info' ì‹œíŠ¸ê°€ ì¡°ì •ë¶„ê°œ íŒŒì¼ì— ì—†ìŠµë‹ˆë‹¤.")
            return None

        info_df = original_sheets["Info"].set_index(original_sheets["Info"].columns[0])

        def parse_percent(s):
            """
            ë‹¤ì–‘í•œ í˜•íƒœì˜ í¼ì„¼íŠ¸ ê°’ì„ ì†Œìˆ˜ì  í˜•íƒœë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
            - '60%': 0.6
            - 60: 0.6 (1ë³´ë‹¤ í¬ë¯€ë¡œ í¼ì„¼íŠ¸ë¡œ ê°„ì£¼)
            - 0.6: 0.6 (1ë³´ë‹¤ ì‘ê±°ë‚˜ ê°™ìœ¼ë¯€ë¡œ ì†Œìˆ˜ì ìœ¼ë¡œ ê°„ì£¼)
            """
            # 1. ì…ë ¥ê°’ì´ ë¬¸ìì—´ì¼ ê²½ìš°
            if isinstance(s, str):
                try:
                    # ë¬¸ìì—´ì€ í•­ìƒ '%'ê°€ ìˆê±°ë‚˜ í¼ì„¼íŠ¸ ìˆ«ìë¡œ ê°„ì£¼í•˜ê³  100ìœ¼ë¡œ ë‚˜ëˆ”
                    return float(s.strip().strip('%')) / 100
                except (ValueError, TypeError):
                    # "hello" ê°™ì´ ë³€í™˜ ë¶ˆê°€ëŠ¥í•œ ë¬¸ìì—´ì€ 0.0 ì²˜ë¦¬
                    return 0.0

            # 2. ì…ë ¥ê°’ì´ ìˆ«ì(int, float)ì¼ ê²½ìš°
            elif isinstance(s, (int, float)):
                # ìˆ«ìì˜ ì ˆëŒ“ê°’ì´ 1ë³´ë‹¤ í¬ë©´ (e.g., 60, -50) í¼ì„¼íŠ¸ë¡œ ê°„ì£¼í•˜ê³  100ìœ¼ë¡œ ë‚˜ëˆ”
                if abs(s) > 1:
                    return float(s) / 100
                # ìˆ«ìì˜ ì ˆëŒ“ê°’ì´ 1ë³´ë‹¤ ì‘ê±°ë‚˜ ê°™ìœ¼ë©´ (e.g., 0.6, -0.5, 1) ì´ë¯¸ ë³€í™˜ëœ ì†Œìˆ˜ì ìœ¼ë¡œ ê°„ì£¼í•˜ê³  ê·¸ëŒ€ë¡œ ë°˜í™˜
                else:
                    return float(s)
        
            # 3. ê·¸ ì™¸ íƒ€ì…ì€ 0.0 ë°˜í™˜
            else:
                return 0.0

        info_df["ë‹¹ê¸°ì„¸ìœ¨_num"] = info_df["ë‹¹ê¸°ì„¸ìœ¨"].apply(parse_percent)
        info_df["ë‹¹ê¸°ì§€ë¶„ìœ¨_num"] = info_df["ë‹¹ê¸°ì§€ë¶„ìœ¨"].apply(parse_percent)
        tax_rates = info_df["ë‹¹ê¸°ì„¸ìœ¨_num"].to_dict()
        nci_rates = (1 - info_df["ë‹¹ê¸°ì§€ë¶„ìœ¨_num"]).to_dict()

        # Create maps for faster lookups
        fs_map = dict(zip(coa_df["ê³„ì •ì½”ë“œ"].astype(str), coa_df["FS_Element"]))
        name_map = dict(zip(coa_df["ê³„ì •ì½”ë“œ"].astype(str), coa_df["ê³„ì •ëª…"]))
        tax_adj_entries, nci_adj_entries = [], []

        # Get special account codes from aje_code DataFrame and CoA
        NCI_EQUITY_CODE = [key for key, value in fs_map.items() if value == "CE"][0]
        
        # ë¹„ì§€ë°°ì§€ë¶„ìˆœì†ìµ ê³„ì •ì„ CoAì—ì„œ 'CR' ì½”ë“œë¡œ ë™ì  íƒìƒ‰
        nci_pl_row = coa_df[coa_df["FS_Element"] == "CR"]
        if not nci_pl_row.empty:
            NCI_PL_CODE = nci_pl_row.iloc[0]["ê³„ì •ì½”ë“œ"]
            NCI_PL_NAME = nci_pl_row.iloc[0]["ê³„ì •ëª…"]
        else:
            NCI_PL_CODE = "310000"  # Fallback
            NCI_PL_NAME = "ë¹„ì§€ë°°ì§€ë¶„ìˆœì†ìµ"
            st.warning("CoA íŒŒì¼ì—ì„œ 'CR' FS_Elementë¥¼ ê°€ì§„ ë¹„ì§€ë°°ì§€ë¶„ìˆœì†ìµ ê³„ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’('310000')ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")

        IT_EXPENSE_CODE = aje_code.loc[aje_code["FS_Element"] == "X", "ê³„ì •ì½”ë“œ"].iloc[0]
        IT_EXPENSE_NAME = aje_code.loc[aje_code["FS_Element"] == "X", "ê³„ì •ëª…"].iloc[0]
        DTA_CODE = aje_code.loc[aje_code["FS_Element"] == "L", "ê³„ì •ì½”ë“œ"].iloc[0]
        DTA_NAME = aje_code.loc[aje_code["FS_Element"] == "L", "ê³„ì •ëª…"].iloc[0]
        RE_CODE = aje_code.loc[aje_code["FS_Element"] == "E", "ê³„ì •ì½”ë“œ"].iloc[0]
        RE_NAME = aje_code.loc[aje_code["FS_Element"] == "E", "ê³„ì •ëª…"].iloc[0]

        # --- Pre-process CAJE02 to find the inventory-holding company for each transaction ---
        caje02_df = original_sheets.get("CAJE02_ì œí’ˆë¯¸ì‹¤í˜„ì´ìµì œê±°")
        tx_rate_company_map = {}
        if caje02_df is not None and 'ì„¤ëª…' in caje02_df.columns:
            # Ensure ê³„ì •ì½”ë“œ is string for mapping
            caje02_df['ê³„ì •ì½”ë“œ'] = caje02_df['ê³„ì •ì½”ë“œ'].astype(str)
            for desc, group in caje02_df.groupby("ì„¤ëª…"):
                asset_rows = group[group["ê³„ì •ì½”ë“œ"].map(fs_map) == 'A']
                if not asset_rows.empty:
                    inventory_holder_company = asset_rows.iloc[0]["íšŒì‚¬ëª…"]
                    tx_rate_company_map[desc] = inventory_holder_company

        # --- 1. Tax and NCI on P/L adjustments from CAJE sheets ---
        for sheet_name, df in original_sheets.items():
            sheet_name_upper = sheet_name.upper()
            if not sheet_name_upper.startswith("CAJE") or sheet_name_upper in [
                "CAJE97_ë²•ì¸ì„¸ì¡°ì •",
                "CAJE98_ë¹„ì§€ë°°ì§€ë¶„ì¡°ì •",
            ]:
                continue

            for _, row in df.iterrows():
                acc_code, corp, period, amount = (
                    str(row.get("ê³„ì •ì½”ë“œ", "")).strip(),
                    row.get("íšŒì‚¬ëª…", ""),
                    row.get("ë‹¹ê¸°ì „ê¸°", ""),
                    pd.to_numeric(row.get("ê¸ˆì•¡"), errors="coerce"),
                )
                if not all([acc_code, corp, period, pd.notna(amount)]):
                    continue

                if period != "ë‹¹ê¸°":
                    continue

                fs_element = fs_map.get(acc_code)
                desc = f"[{sheet_name}] {row.get('ì„¤ëª…', '')} ê´€ë ¨"

                # --- Tax Effect Logic (unchanged) ---
                generate_tax_effect = False
                if sheet_name_upper == "CAJE02_ì œí’ˆë¯¸ì‹¤í˜„ì´ìµì œê±°" and fs_element == 'A':
                    generate_tax_effect = True
                elif sheet_name_upper in ["CAJE03_ìƒê°ìì‚°ë¯¸ì‹¤í˜„ì´ìµì œê±°", "CAJE05_ê¸°íƒ€ì†ìµì¡°ì •", "CAJE96_ì·¨ë“ì¼ì°¨ì´ì¡°ì •"] and fs_element in ['R', 'X']:
                    generate_tax_effect = True

                if generate_tax_effect:
                    tax_rate = tax_rates.get(corp, 0.0)
                    
                    # R(ìˆ˜ìµ), X(ë¹„ìš©)ì—ì„œ ë°œìƒí•œ ì¡°ì •ì˜ ë²•ì¸ì„¸íš¨ê³¼ ê³„ì‚° ì‹œ ë¶€í˜¸ ë³€ê²½
                    if fs_element in ['R', 'X']:
                        tax_effect = -amount * tax_rate
                    else: # A(ìì‚°)ì—ì„œ ë°œìƒí•œ ì¡°ì •
                        tax_effect = amount * tax_rate

                    if abs(tax_effect) > 1:
                        tax_adj_entries.append(
                            {
                                "íšŒì‚¬ëª…": corp, "ê³„ì •ì½”ë“œ": IT_EXPENSE_CODE, "ê³„ì •ëª…": IT_EXPENSE_NAME,
                                "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°", "ê¸ˆì•¡": tax_effect, "ì„¤ëª…": f"{desc} ë²•ì¸ì„¸íš¨ê³¼",
                            }
                        )
                        tax_adj_entries.append(
                            {
                                "íšŒì‚¬ëª…": corp, "ê³„ì •ì½”ë“œ": DTA_CODE, "ê³„ì •ëª…": DTA_NAME,
                                "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°", "ê¸ˆì•¡": tax_effect, "ì„¤ëª…": f"{desc} ë²•ì¸ì„¸íš¨ê³¼",
                            }
                        )

                # --- NCI Effect Logic (P/L part) - UPDATED ---
                is_unrealized_profit_adj = sheet_name_upper in ["CAJE02_ì œí’ˆë¯¸ì‹¤í˜„ì´ìµì œê±°", "CAJE03_ìƒê°ìì‚°ë¯¸ì‹¤í˜„ì´ìµì œê±°", "CAJE96_ì·¨ë“ì¼ì°¨ì´ì¡°ì •"]
                if is_unrealized_profit_adj and fs_element in ["R", "X"]:
                    if corp in nci_rates and nci_rates.get(corp, 0) > 0:
                        
                        tax_rate_corp = corp
                        if sheet_name_upper == "CAJE02_ì œí’ˆë¯¸ì‹¤í˜„ì´ìµì œê±°":
                            description = row.get("ì„¤ëª…", "")
                            tax_rate_corp = tx_rate_company_map.get(description, corp)

                        tax_rate = tax_rates.get(tax_rate_corp, 0.0)
                        nci_rate = nci_rates.get(corp, 0.0)
                        nci_effect = -amount * (1 - tax_rate) * nci_rate
                        if abs(nci_effect) > 1:
                            nci_adj_entries.append(
                                {
                                    "íšŒì‚¬ëª…": corp, "ê³„ì •ì½”ë“œ": RE_CODE, "ê³„ì •ëª…": RE_NAME,
                                    "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°", "ê¸ˆì•¡": -nci_effect, "ì„¤ëª…": f"{desc} ë¹„ì§€ë°°ì§€ë¶„íš¨ê³¼",
                                }
                            )
                            nci_adj_entries.append(
                                {
                                    "íšŒì‚¬ëª…": corp, "ê³„ì •ì½”ë“œ": NCI_PL_CODE, "ê³„ì •ëª…": NCI_PL_NAME,
                                    "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°", "ê¸ˆì•¡": nci_effect, "ì„¤ëª…": f"{desc} ë¹„ì§€ë°°ì§€ë¶„íš¨ê³¼",
                                }
                            )

        # --- 2. NCI on subsidiary's total equity change from 'CE' sheet ---
        for sub_file, sub_name in zip(subs_files, subs_names):
            try:
                sub_file.seek(0)
                sub_xls = pd.ExcelFile(sub_file)
                if "CE" in sub_xls.sheet_names:
                    sce_df = pd.read_excel(sub_xls, sheet_name="CE", header=None)

                    if sce_df.shape[0] < 5 or sce_df.shape[1] < 4:
                        continue

                    nci_rate = nci_rates.get(sub_name, 0.0)
                    if nci_rate <= 0:
                        continue

                    header_row = sce_df.iloc[2]
                    equity_acct_codes = header_row.iloc[3:-1]
                    nci_equity_code = header_row.iloc[-1]

                    for r in range(3, len(sce_df)):
                        data_row = sce_df.iloc[r]
                        row_desc = str(data_row.iloc[1])

                        if "ê¸°ë§" in row_desc or "Ending" in row_desc:
                            break
                        if "ê¸°ì´ˆ" in row_desc or "Beginning" in row_desc:
                            continue

                        ce_adj_code = str(data_row.iloc[2])
                        is_ni_item = "_NI" in ce_adj_code
                        nci_contra_code = NCI_PL_CODE if is_ni_item else nci_equity_code
                        nci_contra_name = NCI_PL_NAME if is_ni_item else "ë¹„ì§€ë°°ì§€ë¶„"

                        change_values = pd.to_numeric(
                            data_row.iloc[3:-1], errors="coerce"
                        ).fillna(0)

                        for i, change in enumerate(change_values):
                            if abs(change) > 1:
                                equity_acct_code = str(equity_acct_codes.iloc[i])
                                nci_effect = change * nci_rate

                                nci_adj_entries.append(
                                    {
                                        "íšŒì‚¬ëª…": sub_name,
                                        "ê³„ì •ì½”ë“œ": equity_acct_code,
                                        "ê³„ì •ëª…": name_map.get(equity_acct_code, ""),
                                        "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°",
                                        "ê¸ˆì•¡": -nci_effect,
                                        "ì„¤ëª…": f"{sub_name} ìë³¸ë³€ë™ ({row_desc})",
                                    }
                                )
                                nci_adj_entries.append(
                                    {
                                        "íšŒì‚¬ëª…": sub_name,
                                        "ê³„ì •ì½”ë“œ": nci_contra_code,
                                        "ê³„ì •ëª…": nci_contra_name,
                                        "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°",
                                        "ê¸ˆì•¡": nci_effect,
                                        "ì„¤ëª…": f"{sub_name} ìë³¸ë³€ë™ ({row_desc})",
                                    }
                                )
            except Exception as e:
                st.warning(f"{sub_name}ì˜ 'CE'ì‹œíŠ¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

        # --- Final assembly of adjustment sheets (unchanged) ---
        final_sheets = original_sheets.copy()
        new_tax_df = pd.DataFrame(tax_adj_entries)
        if (
            "CAJE97_ë²•ì¸ì„¸ì¡°ì •" in final_sheets
            and not final_sheets["CAJE97_ë²•ì¸ì„¸ì¡°ì •"].empty
        ):
            original_tax_df = final_sheets["CAJE97_ë²•ì¸ì„¸ì¡°ì •"].dropna(how="all")
            final_sheets["CAJE97_ë²•ì¸ì„¸ì¡°ì •"] = pd.concat(
                [original_tax_df, new_tax_df], ignore_index=True
            )
        else:
            final_sheets["CAJE97_ë²•ì¸ì„¸ì¡°ì •"] = new_tax_df

        new_nci_df = pd.DataFrame(nci_adj_entries)
        if (
            "CAJE98_ë¹„ì§€ë°°ì§€ë¶„ì¡°ì •" in final_sheets
            and not final_sheets["CAJE98_ë¹„ì§€ë°°ì§€ë¶„ì¡°ì •"].empty
        ):
            original_nci_df = final_sheets["CAJE98_ë¹„ì§€ë°°ì§€ë¶„ì¡°ì •"].dropna(how="all")
            final_sheets["CAJE98_ë¹„ì§€ë°°ì§€ë¶„ì¡°ì •"] = pd.concat(
                [original_nci_df, new_nci_df], ignore_index=True
            )
        else:
            final_sheets["CAJE98_ë¹„ì§€ë°°ì§€ë¶„ì¡°ì •"] = new_nci_df

        return to_excel(final_sheets)


    # --- Step 1: Download Template ---
    st.subheader("Step 1: í…œí”Œë¦¿ ë‹¤ìš´ë¡œë“œ")
    st.write(
        "í…œí”Œë¦¿ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ê¸°ë³¸ ì¡°ì • ëª…ì„¸ì„œ ì‹œíŠ¸ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤."
    )
    template_data = create_adjustment_template()
    st.download_button(
        label="ğŸ“¥ ì¡°ì •ë¶„ê°œ ì…ë ¥ í…œí”Œë¦¿ ë‹¤ìš´ë¡œë“œ (.xlsx)",
        data=template_data,
        file_name="ì¡°ì •ë¶„ê°œ_ì…ë ¥í…œí”Œë¦¿_BeforeTaxNci.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    )

    # --- Step 2: Upload Initial Adjustments ---
    st.subheader("Step 2: ê¸°ë³¸ ì¡°ì • íŒŒì¼ ì—…ë¡œë“œ")
    st.session_state.adj_workflow["initial_file"] = st.file_uploader(
        "ì‘ì„±í•œ ê¸°ë³¸ ì¡°ì • íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”. ('Info' ì‹œíŠ¸ í¬í•¨)",
        type="xlsx",
        key="initial_adj_uploader",
    )

    # --- Step 3: Generate & Download Intermediate File ---
    st.subheader("Step 3: ë²•ì¸ì„¸/NCI ìë™ê³„ì‚° ë° ê²€í† ")
    if st.button(
        "âš™ï¸ ë²•ì¸ì„¸/NCI ì¡°ì • ìë™ê³„ì‚° ì‹¤í–‰",
        disabled=not (
            st.session_state.adj_workflow["initial_file"]
            and st.session_state.files["coa"]
        ),
    ):
        with st.spinner("ìë™ ì¡°ì • ë¶„ê°œë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                coa_df = pd.read_excel(
                    st.session_state.files["coa"], sheet_name="CoA", dtype=str
                )
                subs_files = st.session_state.files["subsidiaries"]
                subs_names = [f.name.split("_")[0] for f in subs_files]
                aje_code = pd.read_excel(st.session_state.files["coa"], sheet_name="AJE", dtype=str)
                intermediate_excel_data = generate_intermediate_adjustments(
                    st.session_state.adj_workflow["initial_file"],
                    coa_df,
                    subs_files,
                    subs_names,
                    aje_code,
                )
                if intermediate_excel_data:
                    st.session_state.adj_workflow["intermediate_data"] = (
                        intermediate_excel_data
                    )
                    st.success(
                        "ìë™ê³„ì‚°ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì•„ë˜ ë²„íŠ¼ìœ¼ë¡œ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ê²€í† í•˜ì„¸ìš”."
                    )
            except Exception as e:
                st.error(f"ìë™ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                st.exception(e)

    if st.session_state.adj_workflow["intermediate_data"]:
        st.download_button(
            label="ğŸ“¥ ê²€í† ìš© íŒŒì¼ ë‹¤ìš´ë¡œë“œ (ìë™ê³„ì‚° í¬í•¨)",
            data=st.session_state.adj_workflow["intermediate_data"],
            file_name="ì¡°ì •ë¶„ê°œ_ì…ë ¥í…œí”Œë¦¿_TaxNci.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        )

    # --- Step 4: Upload Final File ---
    st.subheader("Step 4: ìµœì¢… ì¡°ì • íŒŒì¼ ì—…ë¡œë“œ")
    st.write("ê²€í†  ë° ìˆ˜ì •ì„ ì™„ë£Œí•œ ìµœì¢… ì¡°ì • íŒŒì¼ì„ ì—…ë¡œë“œí•©ë‹ˆë‹¤.")
    st.session_state.adj_workflow["final_file"] = st.file_uploader(
        "ìµœì¢… ì¡°ì • íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", type="xlsx", key="final_adj_uploader"
    )

    # --- Step 5 & 6: Generate Final CAJE and Display ---
    st.subheader("Step 5: ìµœì¢… ë¶„ê°œ ìƒì„± ë° ê²°ê³¼ í™•ì¸")

    def build_caje_from_template(adjustment_file, coa_df_internal):
        fs_map = dict(zip(coa_df_internal["ê³„ì •ì½”ë“œ"], coa_df_internal["FS_Element"]))

        def get_bspl_sign(fs_element):
            return -1 if fs_element in ["A", "X", "CA"] else 1

        ni_code = None
        try:
            r_rows = coa_df_internal[coa_df_internal["FS_Element"] == "R"]
            if not r_rows.empty:
                ni_code = r_rows.iloc[0].get("L1_code")
        except (IndexError, KeyError):
            ni_code = None

        xls = pd.ExcelFile(adjustment_file)
        all_bspl_entries, all_cf_entries = [], []

        for sheet_name in xls.sheet_names:
            if not sheet_name.upper().startswith("CAJE"):
                continue
            caje_type = sheet_name.split("_")[0].upper()
            df = pd.read_excel(xls, sheet_name, dtype={"ê³„ì •ì½”ë“œ": str}).fillna("")

            # --- A. BS/PL Adjustment Logic ---
            df_for_bspl = df.copy()
            if caje_type in ["CAJE01", "CAJE04", "CAJE05", "CAJE99"]:
                df_for_bspl = df[df["ë‹¹ê¸°ì „ê¸°"] == "ë‹¹ê¸°"]

            for _, row in df_for_bspl.iterrows():
                acc_code = str(row.get("ê³„ì •ì½”ë“œ", "")).strip()
                if not acc_code:
                    continue
                fs_element = fs_map.get(acc_code, "")
                amount = pd.to_numeric(row.get("ê¸ˆì•¡"), errors="coerce")
                if pd.isna(amount) or amount == 0:
                    continue

                final_amount = amount * get_bspl_sign(fs_element)
                all_bspl_entries.append(
                    {
                        "ì¡°ì •ìœ í˜•": caje_type,
                        "íšŒì‚¬ëª…": row.get("íšŒì‚¬ëª…"),
                        "ê³„ì •ì½”ë“œ": acc_code,
                        "ê¸ˆì•¡": final_amount,
                        "ì„¤ëª…": row.get("ì„¤ëª…"),
                        "FS_Element": fs_element,
                    }
                )

            # --- B. CF Adjustment Logic ---
            if caje_type == "CAJE02":
                if ni_code is None:
                    st.warning(
                        f"[{sheet_name}] CFì¡°ì • ê±´ë„ˆëœ€: ë‹¹ê¸°ìˆœì´ìµ ê³„ì • ì½”ë“œë¥¼ CoAì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                    )
                    continue
                df_with_fs = df.merge(
                    coa_df_internal[["ê³„ì •ì½”ë“œ", "FS_Element"]],
                    on="ê³„ì •ì½”ë“œ",
                    how="left",
                )
                pl_rows = df_with_fs[df_with_fs["FS_Element"].isin(["R", "X"])].copy()
                bs_rows = df_with_fs[
                    df_with_fs["FS_Element"].isin(["A", "L", "E"])
                ].copy()
                if pl_rows.empty or bs_rows.empty:
                    st.warning(
                        f"[{sheet_name}] CFì¡°ì • ê±´ë„ˆëœ€: ì‹œíŠ¸ì—ì„œ ì†ìµ(R/X) ë˜ëŠ” ì¬ë¬´ìƒíƒœ(A/L/E) ê³„ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                    )
                    continue

                pl_pivot = pl_rows.pivot_table(
                    index=["ê³„ì •ì½”ë“œ", "FS_Element"],
                    columns="ë‹¹ê¸°ì „ê¸°",
                    values="ê¸ˆì•¡",
                    aggfunc="sum",
                ).fillna(0)
                if "ë‹¹ê¸°" not in pl_pivot.columns:
                    pl_pivot["ë‹¹ê¸°"] = 0
                if "ì „ê¸°" not in pl_pivot.columns:
                    pl_pivot["ì „ê¸°"] = 0
                pl_pivot["change"] = pl_pivot["ë‹¹ê¸°"] + pl_pivot["ì „ê¸°"]
                pl_pivot["impact"] = pl_pivot.apply(
                    lambda r: r["change"] if r.name[1] == "X" else -r["change"], axis=1
                )
                total_pl_impact = pl_pivot["impact"].sum()

                inventory_acc_code = bs_rows.iloc[0]["ê³„ì •ì½”ë“œ"]
                corp_name = df.iloc[0]["íšŒì‚¬ëª…"]

                # Line 1: NI Entry (+)
                all_cf_entries.append(
                    {
                        "ì¡°ì •ìœ í˜•": caje_type,
                        "íšŒì‚¬ëª…": corp_name,
                        "ê³„ì •ì½”ë“œ": ni_code,
                        "ì¡°ì •ê¸ˆì•¡": total_pl_impact,
                        "ì„¤ëª…": "[ë¹„í˜„ê¸ˆì†ìµ] ë¯¸ì‹¤í˜„ì´ìµ(NI)",
                    }
                )
                # Line 2: Inventory Entry (-)
                all_cf_entries.append(
                    {
                        "ì¡°ì •ìœ í˜•": caje_type,
                        "íšŒì‚¬ëª…": corp_name,
                        "ê³„ì •ì½”ë“œ": inventory_acc_code,
                        "ì¡°ì •ê¸ˆì•¡": -total_pl_impact,
                        "ì„¤ëª…": "[ë¹„í˜„ê¸ˆì†ìµ] ë¯¸ì‹¤í˜„ì´ìµ(ì¬ê³ )",
                    }
                )
            elif caje_type == "CAJE03":
                if ni_code is None:
                    st.warning(
                        f"[{sheet_name}] CFì¡°ì • ê±´ë„ˆëœ€: ë‹¹ê¸°ìˆœì´ìµ ê³„ì • ì½”ë“œë¥¼ CoAì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                    )
                    continue
                df_with_fs = df.merge(
                    coa_df_internal[["ê³„ì •ì½”ë“œ", "FS_Element"]],
                    on="ê³„ì •ì½”ë“œ",
                    how="left",
                )
                pl_rows = df_with_fs[df_with_fs["FS_Element"].isin(["X", "R"])].copy()
                bs_rows = df_with_fs[
                    df_with_fs["FS_Element"].isin(["A", "L", "E"])
                ].copy()
                if pl_rows.empty or bs_rows.empty:
                    st.warning(
                        f"[{sheet_name}] CFì¡°ì • ê±´ë„ˆëœ€: ì‹œíŠ¸ì—ì„œ ì†ìµ(R/X) ë˜ëŠ” ì¬ë¬´ìƒíƒœ(A/L/E) ê³„ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                    )
                    continue

                pl_pivot = pl_rows.pivot_table(
                    index=["ê³„ì •ì½”ë“œ", "FS_Element"],
                    columns="ë‹¹ê¸°ì „ê¸°",
                    values="ê¸ˆì•¡",
                    aggfunc="sum",
                ).fillna(0)
                if "ë‹¹ê¸°" not in pl_pivot.columns:
                    pl_pivot["ë‹¹ê¸°"] = 0
                if "ì „ê¸°" not in pl_pivot.columns:
                    pl_pivot["ì „ê¸°"] = 0
                pl_pivot["change"] = pl_pivot["ë‹¹ê¸°"] + pl_pivot["ì „ê¸°"]
                pl_pivot["impact"] = pl_pivot.apply(
                    lambda r: r["change"] if r.name[1] == "X" else -r["change"], axis=1
                )
                total_pl_impact = pl_pivot["impact"].sum()

                pl_acc_code = pl_rows.iloc[0]["ê³„ì •ì½”ë“œ"]
                corp_name = df.iloc[0]["íšŒì‚¬ëª…"]

                # Line 1: NI Entry (+)
                all_cf_entries.append(
                    {
                        "ì¡°ì •ìœ í˜•": caje_type,
                        "íšŒì‚¬ëª…": corp_name,
                        "ê³„ì •ì½”ë“œ": ni_code,
                        "ì¡°ì •ê¸ˆì•¡": total_pl_impact,
                        "ì„¤ëª…": "[ë¹„í˜„ê¸ˆì†ìµ] ë¯¸ì‹¤í˜„ì´ìµ(NI)",
                    }
                )
                # Line 2: PL Entry (-)
                all_cf_entries.append(
                    {
                        "ì¡°ì •ìœ í˜•": caje_type,
                        "íšŒì‚¬ëª…": corp_name,
                        "ê³„ì •ì½”ë“œ": pl_acc_code,
                        "ì¡°ì •ê¸ˆì•¡": -total_pl_impact,
                        "ì„¤ëª…": "[ë¹„í˜„ê¸ˆì†ìµ] ë¯¸ì‹¤í˜„ì´ìµ(ì†ìµ)",
                    }
                )
            elif caje_type == "CAJE04":
                if ni_code is None:
                    st.warning(
                        f"[{sheet_name}] CFì¡°ì • ê±´ë„ˆëœ€: ë‹¹ê¸°ìˆœì´ìµ ê³„ì • ì½”ë“œë¥¼ CoAì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                    )
                    continue
                df_with_fs = df.merge(
                    coa_df_internal[["ê³„ì •ì½”ë“œ", "FS_Element"]],
                    on="ê³„ì •ì½”ë“œ",
                    how="left",
                )
                pl_rows = df_with_fs[df_with_fs["FS_Element"].isin(["X", "R"])].copy()
                bs_rows = df_with_fs[
                    df_with_fs["FS_Element"].isin(["A", "L", "E"])
                ].copy()
                if pl_rows.empty or bs_rows.empty:
                    st.warning(
                        f"[{sheet_name}] CFì¡°ì • ê±´ë„ˆëœ€: ì‹œíŠ¸ì—ì„œ ì†ìµ(R/X) ë˜ëŠ” ì¬ë¬´ìƒíƒœ(A/L/E) ê³„ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                    )
                    continue

                pl_pivot = pl_rows.pivot_table(
                    index=["ê³„ì •ì½”ë“œ", "FS_Element"],
                    columns="ë‹¹ê¸°ì „ê¸°",
                    values="ê¸ˆì•¡",
                    aggfunc="sum",
                ).fillna(0)
                if "ë‹¹ê¸°" not in pl_pivot.columns:
                    pl_pivot["ë‹¹ê¸°"] = 0
                if "ì „ê¸°" not in pl_pivot.columns:
                    pl_pivot["ì „ê¸°"] = 0
                pl_pivot["change"] = pl_pivot["ë‹¹ê¸°"] + pl_pivot["ì „ê¸°"]
                pl_pivot["impact"] = pl_pivot.apply(
                    lambda r: r["change"] if r.name[1] == "X" else -r["change"], axis=1
                )
                total_pl_impact = pl_pivot["impact"].sum()

                pl_acc_code = pl_rows.iloc[0]["ê³„ì •ì½”ë“œ"]
                corp_name = df.iloc[0]["íšŒì‚¬ëª…"]

                # Line 1: NI Entry (+)
                all_cf_entries.append(
                    {
                        "ì¡°ì •ìœ í˜•": caje_type,
                        "íšŒì‚¬ëª…": corp_name,
                        "ê³„ì •ì½”ë“œ": ni_code,
                        "ì¡°ì •ê¸ˆì•¡": total_pl_impact,
                        "ì„¤ëª…": "[ì†ìµ/ì¬ë¬´í™œë™] ë¯¸ì‹¤í˜„ì´ìµ(NI)",
                    }
                )
                # Line 2: RE/PL Entry (-)
                all_cf_entries.append(
                    {
                        "ì¡°ì •ìœ í˜•": caje_type,
                        "íšŒì‚¬ëª…": corp_name,
                        "ê³„ì •ì½”ë“œ": pl_acc_code,
                        "ì¡°ì •ê¸ˆì•¡": total_pl_impact,
                        "ì„¤ëª…": "[ì†ìµ/ì¬ë¬´í™œë™] ë¯¸ì‹¤í˜„ì´ìµ(ì†ìµ)",
                    }
                )
            else:
                grouped = df.groupby(["íšŒì‚¬ëª…", "ê³„ì •ì½”ë“œ", "ì„¤ëª…"])
                for (corp, acc_code, desc), group in grouped:
                    pivot_df = group.pivot_table(
                        columns="ë‹¹ê¸°ì „ê¸°", values="ê¸ˆì•¡", aggfunc="sum"
                    )
                    current_amt = (
                        pivot_df["ë‹¹ê¸°"].item() if "ë‹¹ê¸°" in pivot_df.columns else 0
                    )
                    prior_amt = (
                        pivot_df["ì „ê¸°"].item() if "ì „ê¸°" in pivot_df.columns else 0
                    )
                    fs_element = fs_map.get(acc_code, "")

                    cf_adj_amt, cf_desc = 0, desc
                    if caje_type == "CAJE01":
                        change_amt = current_amt - prior_amt
                        if fs_element == "L":
                            cf_adj_amt = change_amt
                        else:  # For 'A' and others
                            cf_adj_amt = -change_amt
                        cf_desc = f"[ìš´ì „ìë³¸] {desc}"
                    elif caje_type == "CAJE05":
                        cf_adj_amt, cf_desc = current_amt, f"[ë¹„í˜„ê¸ˆì†ìµ] {desc}"

                    if abs(cf_adj_amt) > 1e-6:
                        all_cf_entries.append(
                            {
                                "ì¡°ì •ìœ í˜•": caje_type,
                                "íšŒì‚¬ëª…": corp,
                                "ê³„ì •ì½”ë“œ": acc_code,
                                "ì¡°ì •ê¸ˆì•¡": cf_adj_amt,
                                "ì„¤ëª…": cf_desc,
                            }
                        )

        bspl_cols = ["ì¡°ì •ìœ í˜•", "íšŒì‚¬ëª…", "ê³„ì •ì½”ë“œ", "ê¸ˆì•¡", "ì„¤ëª…", "FS_Element"]
        cf_cols = ["ì¡°ì •ìœ í˜•", "íšŒì‚¬ëª…", "ê³„ì •ì½”ë“œ", "ì¡°ì •ê¸ˆì•¡", "ì„¤ëª…"]

        caje_bspl_df = (
            pd.DataFrame(all_bspl_entries, columns=bspl_cols)
            if all_bspl_entries
            else pd.DataFrame(columns=bspl_cols)
        )
        caje_cf_df = (
            pd.DataFrame(all_cf_entries, columns=cf_cols)
            if all_cf_entries
            else pd.DataFrame(columns=cf_cols)
        )

        return caje_bspl_df, caje_cf_df

    if st.button(
        "ğŸš€ ìµœì¢… ì—°ê²°ì¡°ì •ë¶„ê°œ ìƒì„± ì‹¤í–‰",
        disabled=not (
            st.session_state.adj_workflow["final_file"]
            and st.session_state.files["coa"]
        ),
    ):
        with st.spinner("ìµœì¢… ì¡°ì • ë¶„ê°œë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            try:
                coa_df = pd.read_excel(
                    st.session_state.files["coa"], sheet_name="CoA", dtype=str
                )
                caje_bspl_df, caje_cf_df = build_caje_from_template(
                    st.session_state.adj_workflow["final_file"], coa_df
                )
                st.session_state.results["caje_bspl_df"] = caje_bspl_df
                st.session_state.results["caje_cf_df"] = caje_cf_df
                st.session_state.caje_generated = True
                st.success("âœ… ìµœì¢… ì¡°ì • ë¶„ê°œ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

                if not caje_bspl_df.empty and "ê¸ˆì•¡" in caje_bspl_df.columns:
                    total_adj_sum = caje_bspl_df["ê¸ˆì•¡"].sum()
                    if abs(total_adj_sum) > 1:
                        st.error(
                            f"âŒ **[BS/PL CAJE ê²€ì¦]** ì¡°ì •ë¶„ê°œ í•©ê³„ê°€ 0ì´ ì•„ë‹™ë‹ˆë‹¤ (ì°¨ëŒ€ ë¶ˆì¼ì¹˜): {total_adj_sum:,.0f}"
                        )
                    else:
                        st.success(
                            f"âœ… **[BS/PL CAJE ê²€ì¦]** ì¡°ì •ë¶„ê°œ í•©ê³„ê°€ 0ìœ¼ë¡œ ì¼ì¹˜í•©ë‹ˆë‹¤."
                        )

            except Exception as e:
                st.error(f"ìµœì¢… ì¡°ì • ë¶„ê°œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                st.exception(e)

    if not st.session_state.files["coa"]:
        st.warning("ë¨¼ì € ì‚¬ì´ë“œë°”ì—ì„œ CoA íŒŒì¼ì„ ì—…ë¡œë“œí•´ì•¼ í•©ë‹ˆë‹¤.")

    if st.session_state.caje_generated:
        st.markdown("#### ğŸ“„ ì¬ë¬´ìƒíƒœí‘œ/ì†ìµê³„ì‚°ì„œ ì¡°ì • ë¶„ê°œ (BS/PL CAJE)")
        st.dataframe(st.session_state.results.get("caje_bspl_df"))
        st.markdown("#### ğŸŒŠ í˜„ê¸ˆíë¦„í‘œ ì¡°ì • ë¶„ê°œ (CF CAJE)")
        st.dataframe(st.session_state.results.get("caje_cf_df"))
        caje_excel_data = to_excel(
            {
                "CAJE_BSPL": st.session_state.results.get(
                    "caje_bspl_df", pd.DataFrame()
                ),
                "CAJE_CF": st.session_state.results.get("caje_cf_df", pd.DataFrame()),
            }
        )
        st.download_button(
            label="ğŸ“¥ ìƒì„±ëœ ì¡°ì • ë¶„ê°œ(CAJE) ë‹¤ìš´ë¡œë“œ (.xlsx)",
            data=caje_excel_data,
            file_name="CAJE_generated.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        )
        st.info(
            "ìƒì„±ëœ BS/PL CAJE ë°ì´í„°ëŠ” 'ì—°ê²° ì¬ë¬´ì œí‘œ' íƒ­ì˜ 'ì—°ê²° ì¡°ì •' ë°ì´í„°ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        )


with tab4:
    st.header("4. ì™¸í™” ì¬ë¬´ì œí‘œ í™˜ì‚°")
    st.write(
        "ì™¸í™”ë¡œ ì‘ì„±ëœ ì¬ë¬´ì œí‘œ(FS) íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´, ì§€ì •ëœ í™˜ìœ¨ì— ë”°ë¼ ì›í™”ë¡œ í™˜ì‚°í•˜ê³  ê²°ê³¼ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤."
    )
    st.subheader("Step 1: íŒŒì¼ ì—…ë¡œë“œ")
    st.info(
        "í™˜ì‚°í•  FSíŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”. íŒŒì¼ì˜ ì²« ë‘ ë°ì´í„° í–‰ì—ëŠ” ê¸°ë§í™˜ìœ¨ê³¼ í‰ê· í™˜ìœ¨ì´ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤."
    )
    fcfs_file = st.file_uploader("ì™¸í™” FS íŒŒì¼", type="xlsx", key="fcfs_uploader")
    st.subheader("Step 2: í™˜ì‚° ì‹¤í–‰")
    if st.button("âš™ï¸ ì™¸í™”FS í™˜ì‚° ì‹¤í–‰", disabled=not fcfs_file):
        with st.spinner("ì™¸í™” ì¬ë¬´ì œí‘œë¥¼ í™˜ì‚°í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                log_stream = io.StringIO()
                with redirect_stdout(log_stream):
                    closing_rate, average_rate, df = read_rates_and_table(fcfs_file)
                    pre_summary = precheck_foreign_currency(df)
                    translated_df, totals_summary = translate_fcfs(
                        df, closing_rate, average_rate
                    )
                log_contents = log_stream.getvalue()
                st.session_state.fcfs_results["log"] = log_contents.strip().split("\n")
                rates_summary_df = pd.DataFrame(
                    {
                        "í•­ëª©": ["ê¸°ë§í™˜ìœ¨", "í‰ê· í™˜ìœ¨"],
                        "ê°’": [closing_rate, average_rate],
                    }
                )
                pre_summary_df = pd.DataFrame(
                    {"í•­ëª©": list(pre_summary.keys()), "ê°’": list(pre_summary.values())}
                )
                totals_summary_df = pd.DataFrame(
                    {
                        "í•­ëª©": list(totals_summary.keys()),
                        "ê°’": list(totals_summary.values()),
                    }
                )
                summary_df = pd.concat(
                    [rates_summary_df, pre_summary_df, totals_summary_df],
                    ignore_index=True,
                )
                summary_df["ê°’"] = summary_df["ê°’"].astype(str)
                st.session_state.fcfs_results["translated_df"] = translated_df
                st.session_state.fcfs_results["summary_df"] = summary_df
                st.success("ğŸ‰ ì™¸í™” ì¬ë¬´ì œí‘œ í™˜ì‚°ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            except Exception as e:
                st.error(f"í™˜ì‚° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                st.exception(e)
    st.subheader("Step 3: ê²°ê³¼ í™•ì¸ ë° ë‹¤ìš´ë¡œë“œ")
    if st.session_state.fcfs_results.get("log"):
        with st.expander("ğŸ” ì²˜ë¦¬ ë¡œê·¸ ë³´ê¸°"):
            st.code("\n".join(st.session_state.fcfs_results["log"]))
    if st.session_state.fcfs_results.get("translated_df") is not None:
        st.markdown("#### ğŸ“„ í™˜ì‚°ëœ ì¬ë¬´ì œí‘œ")
        st.dataframe(st.session_state.fcfs_results["translated_df"])
        st.markdown("#### ğŸ“Š í™˜ì‚° ìš”ì•½")
        st.dataframe(st.session_state.fcfs_results["summary_df"])
        excel_data = to_excel(
            {
                "translated": st.session_state.fcfs_results["translated_df"],
                "summary": st.session_state.fcfs_results["summary_df"],
            }
        )
        st.download_button(
            label="ğŸ“¥ í™˜ì‚° ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (Excel)",
            data=excel_data,
            file_name="FCFS_translated.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        )
