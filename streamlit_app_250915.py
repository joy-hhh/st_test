import streamlit as st
import pandas as pd
import io
from pathlib import Path
from openpyxl.styles import Font, PatternFill, Alignment
from openpyxl.worksheet.datavalidation import DataValidation
from openpyxl.utils import get_column_letter
from contextlib import redirect_stdout
import warnings

# openpyxlì˜ Data Validation ê´€ë ¨ ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œ
warnings.filterwarnings('ignore', category=UserWarning, module='openpyxl')

st.set_page_config(
    page_title="ConsolLab", page_icon="ConsolLab_logo.png", layout="wide"
)

# --- App Title ---
col1, col2 = st.columns([1, 5])
with col1:
    st.image("ConsolLab_logo.png", width=130)
with col2:
    st.title("ConsolLab")
    st.caption("ì—°ê²°ë´‡ ConsolLab : ì—°ê²° ì¬ë¬´ì œí‘œ ìë™í™” ìƒì„±ê¸°")

# --- Session State ì´ˆê¸°í™” ---
if "files" not in st.session_state:
    st.session_state.files = {
        "coa": None,
        "parent": None,
        "subsidiaries": [],
        "adjustment": None,
        "footnotes": [],
    }
if "results" not in st.session_state:
    st.session_state.results = {
        "consolidation_wp_bs": None,
        "consolidation_wp_pl": None,
        "consolidation_wp_cf": None,
        "combined_footnotes": None,
        "validation_log": [],
        "caje_bspl_df": None,
        "caje_cf_df": None,
    }
if "caje_generated" not in st.session_state:
    st.session_state.caje_generated = False
if "fcfs_results" not in st.session_state:
    st.session_state.fcfs_results = {
        "translated_df": None,
        "summary_df": None,
        "log": [],
    }


# =================================================================================================
# --- Helper Functions ---
# =================================================================================================
@st.cache_data
def to_excel(df_dict):
    """
    ì—¬ëŸ¬ ë°ì´í„°í”„ë ˆì„ì„ í•˜ë‚˜ì˜ Excel íŒŒì¼ ë²„í¼ì— ì‹œíŠ¸ë¡œ ì €ì¥í•˜ê³ , ìŠ¤íƒ€ì¼ì„ ì ìš©í•©ë‹ˆë‹¤.
    df_dict: {'sheet_name': DataFrame} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
    """
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine="openpyxl") as writer:
        # ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬ ì¤€ë¹„
        validation_formula = None
        if "Info" in df_dict and not df_dict["Info"].empty:
            info_df = df_dict["Info"]
            num_companies = len(info_df)
            if num_companies > 0:
                validation_formula = f"='Info'!$A$2:$A${num_companies + 1}"

        for sheet_name, df in df_dict.items():
            if df is None:  # df.empty ì¡°ê±´ ì œê±°í•˜ì—¬ ë¹ˆ ì‹œíŠ¸ë„ ìƒì„±
                continue

            # ì†Œê³„ í–‰ ì •ë³´ ì¶”ì¶œ í›„, 'is_subtotal' ì—´ì€ ì—‘ì…€ì—ì„œ ì œì™¸
            is_subtotal_col = df["is_subtotal"] if "is_subtotal" in df.columns else None
            df_to_write = (
                df.drop(columns=["is_subtotal"]) if is_subtotal_col is not None else df
            )
            df_to_write.to_excel(writer, sheet_name=sheet_name, index=False)

            ws = writer.sheets[sheet_name]

            # í—¤ë” ìŠ¤íƒ€ì¼ ì •ì˜
            header_font = Font(bold=True, color="FFFFFF")
            header_fill = PatternFill(
                start_color="4F81BD", end_color="4F81BD", fill_type="solid"
            )
            header_alignment = Alignment(
                horizontal="center", vertical="center", wrap_text=True
            )

            # í—¤ë” ìŠ¤íƒ€ì¼ ì ìš©
            for cell in ws[1]:
                cell.font = header_font
                cell.fill = header_fill
                cell.alignment = header_alignment

            # ì†Œê³„ í–‰ì— ë³¼ë“œì²´ ì ìš©
            if is_subtotal_col is not None:
                bold_font = Font(bold=True)
                for row_idx, is_sub in enumerate(is_subtotal_col):
                    if is_sub:
                        # openpyxl í–‰ì€ 1-based, í—¤ë”ê°€ ìˆìœ¼ë¯€ë¡œ +2
                        for cell in ws[row_idx + 2]:
                            cell.font = bold_font

            # ì—´ ë„ˆë¹„ ë° ìˆ«ì ì„œì‹ ì ìš©
            for i, column_name in enumerate(
                df_to_write.columns, 1
            ):  # openpyxlì€ 1-based index
                column_letter = get_column_letter(i)
                ws.column_dimensions[column_letter].width = 17

                if pd.api.types.is_numeric_dtype(
                    df_to_write[df_to_write.columns[i - 1]]
                ):
                    # ì‹œíŠ¸ ì´ë¦„ì— ë”°ë¼ ë‹¤ë¥¸ ìˆ«ì ì„œì‹ ì ìš©
                    number_format = "0.000" if sheet_name == "Info" else "#,##0"
                    for cell in ws[column_letter][1:]:
                        if isinstance(cell.value, (int, float)):
                            cell.number_format = number_format
                            cell.alignment = Alignment(
                                horizontal="right", vertical="center"
                            )
            
            # ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬ ì ìš©
            if validation_formula and sheet_name.startswith("CAJE") and "íšŒì‚¬ëª…" in df_to_write.columns:
                dv = DataValidation(
                    type="list", formula1=validation_formula, allow_blank=True
                )
                dv.error = "ëª©ë¡ì— ìˆëŠ” ê°’ë§Œ ì…ë ¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                dv.errorTitle = "ì˜ëª»ëœ ì…ë ¥"
                dv.prompt = "ëª©ë¡ì—ì„œ íšŒì‚¬ëª…ì„ ì„ íƒí•˜ì„¸ìš”."
                dv.promptTitle = "íšŒì‚¬ëª… ì„ íƒ"
                
                company_col_idx = list(df_to_write.columns).index("íšŒì‚¬ëª…") + 1
                company_col_letter = get_column_letter(company_col_idx)
                target_range = f"{company_col_letter}2:{company_col_letter}10000"
                ws.add_data_validation(dv)
                dv.add(target_range)


    return output.getvalue()

def parse_percent(s):
    """
    ë‹¤ì–‘í•œ í˜•íƒœì˜ í¼ì„¼íŠ¸ ê°’ì„ ì†Œìˆ˜ì  í˜•íƒœë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    - '60%': 0.6
    - 60: 0.6 (1ë³´ë‹¤ í¬ë¯€ë¡œ í¼ì„¼íŠ¸ë¡œ ê°„ì£¼)
    - 0.6: 0.6 (1ë³´ë‹¤ ì‘ê±°ë‚˜ ê°™ìœ¼ë¯€ë¡œ ì†Œìˆ˜ì ìœ¼ë¡œ ê°„ì£¼)
    """
    # 1. ì…ë ¥ê°’ì´ ë¬¸ìì—´ì¼ ê²½ìš°
    if isinstance(s, str):
        try:
            # ë¬¸ìì—´ì€ í•­ìƒ '%'ê°€ ìˆê±°ë‚˜ í¼ì„¼íŠ¸ ìˆ«ìë¡œ ê°„ì£¼í•˜ê³  100ìœ¼ë¡œ ë‚˜ëˆ”
            return float(s.strip().strip('%')) / 100
        except (ValueError, TypeError):
            # "hello" ê°™ì´ ë³€í™˜ ë¶ˆê°€ëŠ¥í•œ ë¬¸ìì—´ì€ 0.0 ì²˜ë¦¬
            return 0.
    # 2. ì…ë ¥ê°’ì´ ìˆ«ì(int, float)ì¼ ê²½ìš°
    elif isinstance(s, (int, float)):
        # ìˆ«ìì˜ ì ˆëŒ“ê°’ì´ 1ë³´ë‹¤ í¬ë©´ (e.g., 60, -50) í¼ì„¼íŠ¸ë¡œ ê°„ì£¼í•˜ê³  100ìœ¼ë¡œ ë‚˜ëˆ”
        if abs(s) > 1:
            return float(s) / 100
        # ìˆ«ìì˜ ì ˆëŒ“ê°’ì´ 1ë³´ë‹¤ ì‘ê±°ë‚˜ ê°™ìœ¼ë©´ (e.g., 0.6, -0.5, 1) ì´ë¯¸ ë³€í™˜ëœ ì†Œìˆ˜ì ìœ¼ë¡œ ê°„ì£¼í•˜ê³  ê·¸ëŒ€ë¡œ ë°˜í™˜
        else:
            return float(s)

    # 3. ê·¸ ì™¸ íƒ€ì…ì€ 0.0 ë°˜í™˜
    else:
        return 0.0

def log_validation(message):
    """ê²€ì¦ ê²°ê³¼ë¥¼ ì„¸ì…˜ ìƒíƒœì— ê¸°ë¡í•©ë‹ˆë‹¤."""
    st.session_state.results["validation_log"].append(message)


# =================================================================================================
# --- ì™¸í™”FSí™˜ì‚°ìš© í•¨ìˆ˜ ë° ì„¤ì • (from fcfs_translate.py) ---
# =================================================================================================
AMOUNT_COL_CANDIDATES = ("ì™¸í™”ê¸ˆì•¡", "FC_Amount", "Amount")
EQUITY_CARRY_COL = "ì´ì›”ê¸ˆì•¡"
NAME_COL_CANDIDATES = ("ê³„ì •ëª…", "Account", "Name")
EPS_BS = 1e-6


def _first_numeric_in_row(row):
    s = pd.to_numeric(row, errors="coerce").dropna()
    return None if s.empty else float(s.iloc[0])


def _find_col(df, candidates):
    for c in candidates:
        if c in df.columns:
            return c
    return None


def read_rates_and_table(xlsx_path):
    all_df = pd.read_excel(xlsx_path, header=0)
    closing_rate = _first_numeric_in_row(all_df.iloc[0])
    average_rate = _first_numeric_in_row(all_df.iloc[1])
    if closing_rate is None or average_rate is None:
        raise ValueError("ê¸°ë§/í‰ê· í™˜ìœ¨ì„ 2~3í–‰(ë°ì´í„° ì²« 2í–‰)ì—ì„œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    df = all_df.drop(index=[0, 1]).reset_index(drop=True)
    if "FS_Element" not in df.columns:
        raise ValueError("íŒŒì¼ì— FS_Element ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. (A/L/E/RE/R/X/PI)")
    return closing_rate, average_rate, df


def precheck_foreign_currency(df, eps=EPS_BS):
    df = df.copy()
    amount_col = _find_col(df, AMOUNT_COL_CANDIDATES)
    if amount_col is None:
        raise ValueError(
            f"ì™¸í™”ê¸ˆì•¡ ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í›„ë³´={AMOUNT_COL_CANDIDATES}"
        )
    df[amount_col] = pd.to_numeric(df[amount_col], errors="coerce").fillna(0.0)
    is_A = df["FS_Element"].eq("A")
    is_L = df["FS_Element"].eq("L")
    is_E = df["FS_Element"].eq("E")
    is_RE = df["FS_Element"].eq("RE")
    is_R = df["FS_Element"].eq("R")
    is_X = df["FS_Element"].eq("X")
    a_fc = df.loc[is_A, amount_col].sum()
    l_fc = df.loc[is_L, amount_col].sum()
    e_fc = df.loc[is_E | is_RE, amount_col].sum()
    ni_fc = df.loc[is_R, amount_col].sum() - df.loc[is_X, amount_col].sum()
    bs_gap_fc = a_fc - l_fc - e_fc
    print(
        f"[PRECHECK] (ì™¸í™”) A-L-(E+RE) = {bs_gap_fc}",
        "->",
        "OK" if abs(bs_gap_fc) < eps else "NG",
    )
    print(f"[PRECHECK] (ì™¸í™”) NI_FC = {ni_fc}")
    return {
        "A_FC": a_fc,
        "L_FC": l_fc,
        "E_plus_RE_FC": e_fc,
        "NI_FC": ni_fc,
        "BS_GAP_FC": bs_gap_fc,
        "BS_OK_FC": abs(bs_gap_fc) < eps,
    }


def translate_fcfs(df, closing_rate, average_rate, eps=EPS_BS):
    df = df.copy()
    amount_col = _find_col(df, AMOUNT_COL_CANDIDATES)
    if amount_col is None:
        raise ValueError(
            f"ì™¸í™”ê¸ˆì•¡ ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í›„ë³´={AMOUNT_COL_CANDIDATES}"
        )
    name_col = _find_col(df, NAME_COL_CANDIDATES)
    df[amount_col] = pd.to_numeric(df[amount_col], errors="coerce").fillna(0.0)
    if EQUITY_CARRY_COL in df.columns:
        df[EQUITY_CARRY_COL] = pd.to_numeric(
            df[EQUITY_CARRY_COL], errors="coerce"
        ).fillna(0.0)
    out_col = "ê¸ˆì•¡"
    if out_col not in df.columns:
        df[out_col] = 0.0
    is_A = df["FS_Element"].eq("A")
    is_L = df["FS_Element"].eq("L")
    is_E = df["FS_Element"].eq("E")
    is_RE = df["FS_Element"].eq("RE")
    is_R = df["FS_Element"].eq("R")
    is_X = df["FS_Element"].eq("X")
    is_PI = df["FS_Element"].eq("PI")
    df.loc[is_A | is_L, out_col] = df.loc[is_A | is_L, amount_col] * closing_rate
    df.loc[is_E | is_RE, out_col] = (
        df[EQUITY_CARRY_COL] if EQUITY_CARRY_COL in df.columns else 0.0
    )
    df.loc[is_R, out_col] = df.loc[is_R, amount_col] * average_rate
    df.loc[is_X, out_col] = df.loc[is_X, amount_col] * average_rate
    ni_krw = df.loc[is_R, out_col].sum() - df.loc[is_X, out_col].sum()
    if is_RE.any():
        re_idxs = df.index[is_RE]
        df.loc[re_idxs[0], out_col] = df.loc[re_idxs[0], out_col] + ni_krw
    else:
        new_row = {col: None for col in df.columns}
        new_row["FS_Element"] = "RE"
        new_row[out_col] = ni_krw
        new_row[amount_col] = 0.0
        if EQUITY_CARRY_COL in df.columns:
            new_row[EQUITY_CARRY_COL] = 0.0
        df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)
        is_RE = df["FS_Element"].eq("RE")
    assets_sum = df.loc[df["FS_Element"].eq("A"), out_col].sum()
    liabs_sum = df.loc[df["FS_Element"].eq("L"), out_col].sum()
    equity_sum = df.loc[df["FS_Element"].isin(["E", "RE"]), out_col].sum()
    diff = assets_sum - liabs_sum - equity_sum
    if is_PI.any():
        pi_idxs = df.index[is_PI]
        df.loc[pi_idxs, out_col] = 0.0
        df.loc[pi_idxs[0], out_col] = diff
    else:
        new_row = {col: None for col in df.columns}
        new_row["FS_Element"] = "PI"
        new_row[out_col] = diff
        new_row[amount_col] = 0.0
        if EQUITY_CARRY_COL in df.columns:
            new_row[EQUITY_CARRY_COL] = 0.0
        if name_col is not None:
            new_row[name_col] = "í•´ì™¸ì‚¬ì—…í™˜ì‚°ì†ìµ(PI)"
        df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)
    pi_krw = diff
    e_total_with_pi = df.loc[df["FS_Element"].isin(["E", "RE", "PI"]), out_col].sum()
    bs_gap_after = assets_sum - liabs_sum - e_total_with_pi
    print(
        f"[POSTCHECK] (í™˜ì‚° í›„) A-L-(E+RE+PI) = {bs_gap_after:.4f}",
        "  -> ",
        "OK" if abs(bs_gap_after) < eps else "NG",
    )
    print(
        f"[POSTCHECK] A={assets_sum:.2f}, L={liabs_sum:.2f}, (E+RE+PI)={e_total_with_pi:.2f}, NI(from R&X)={ni_krw:.2f}, PI={pi_krw:.2f}"
    )
    totals = {
        "A(KRW)": assets_sum,
        "L(KRW)": liabs_sum,
        "E_plus_RE_plus_PI(KRW)": e_total_with_pi,
        "NI(KRW from R&X)": ni_krw,
        "PI(KRW)": pi_krw,
        "A-L-(E+RE+PI) (after)": bs_gap_after,
    }
    cols_to_check = [amount_col, out_col]
    if EQUITY_CARRY_COL in df.columns:
        cols_to_check.append(EQUITY_CARRY_COL)
    is_zero_row = (df[cols_to_check].fillna(0) == 0).all(axis=1)
    df = df[~is_zero_row].reset_index(drop=True)
    return df, totals


# --- ì‚¬ì´ë“œë°” íŒŒì¼ ì—…ë¡œë“œ ---
with st.sidebar:
    st.header("ğŸ“ íŒŒì¼ ì—…ë¡œë“œ")
    st.info("íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ì„¸ì…˜ì— ì €ì¥ë©ë‹ˆë‹¤. ì„¸ì…˜ ì¢…ë£Œì‹œ ë©”ëª¨ë¦¬ì—ì„œ ì‚­ì œë©ë‹ˆë‹¤.")
    st.session_state.files["coa"] = st.file_uploader(
        "1. CoA (ê³„ì • ì²´ê³„)", type="xlsx", key="coa_uploader"
    )
    st.session_state.files["parent"] = st.file_uploader(
        "2. ëª¨íšŒì‚¬ ì¬ë¬´ì œí‘œ (BSPL, CF ì‹œíŠ¸ í¬í•¨)", type="xlsx", key="parent_uploader"
    )
    st.session_state.files["subsidiaries"] = st.file_uploader(
        "3. ìíšŒì‚¬ ì¬ë¬´ì œí‘œ (ë‹¤ì¤‘ ì„ íƒ ê°€ëŠ¥)",
        type="xlsx",
        accept_multiple_files=True,
        key="subs_uploader",
    )
    st.session_state.files["adjustment"] = st.file_uploader(
        "4. ì—°ê²° ì¡°ì • ë¶„ê°œ (CAJE ì—…ë¡œë“œ)", type="xlsx", key="adj_uploader"
    )

# --- íƒ­ êµ¬ì„± ---
tab1, tab2, tab3, tab4 = st.tabs(
    ["ğŸ“ˆ ì—°ê²° ì¬ë¬´ì œí‘œ", "ğŸ“ ì£¼ì„ ëŒ€ì‚¬", "ğŸ” ì—°ê²°ì¡°ì •", "ğŸŒ ì™¸í™”FSí™˜ì‚°"]
)

# =================================================================================================
# --- ì—°ê²° ì¬ë¬´ì œí‘œ íƒ­ ---
# =================================================================================================
with tab1:
    st.header("1. ì—°ê²° ì¬ë¬´ì œí‘œ ìƒì„±")
    st.write(
        "CoA, ëª¨íšŒì‚¬, ìíšŒì‚¬ ì¬ë¬´ì œí‘œì™€ ì—°ê²° ì¡°ì • ë°ì´í„°ë¥¼ í†µí•©í•˜ì—¬ ì—°ê²° ì¬ë¬´ìƒíƒœí‘œ, ì†ìµê³„ì‚°ì„œ, í˜„ê¸ˆíë¦„í‘œ, ìë³¸ë³€ë™í‘œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
    )

    def generate_sce_df(coa_df, parent_ce_df, subs_ce_dfs, parent_name, subs_names, adjustment_file, merged_bspl_df):
        """ì‚¬ìš©ì ì •ì˜ ì–‘ì‹ì˜ CE ì‹œíŠ¸ë¥¼ íŒŒì‹±í•˜ì—¬ ì—°ê²° ìë³¸ë³€ë™í‘œ(SCE)ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        # 1. CoA ê¸°ë°˜ ë™ì  ì»¬ëŸ¼ ì •ì˜
        e_element_df = coa_df[coa_df['FS_Element'] == 'E'].dropna(axis=1).copy()
        if e_element_df.shape[1] < 4:
            log_validation("âš ï¸ [ìë³¸ë³€ë™í‘œ] CoAì˜ ìë³¸(E) í•­ëª©ì— ë ˆë²¨ ì •ë³´ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return pd.DataFrame()
        level_code_col = e_element_df.columns[-2]
        level_name_col = e_element_df.columns[-1]
        equity_groups = e_element_df[[level_code_col, level_name_col]].dropna().drop_duplicates().sort_values(by=level_code_col)
        l3_codes_map = pd.Series(equity_groups[level_name_col].values, index=equity_groups[level_code_col]).to_dict()

        nci_equity_row = coa_df[coa_df["FS_Element"] == "CE"]
        if not nci_equity_row.empty:
            nci_code = nci_equity_row.iloc[0]["ê³„ì •ì½”ë“œ"]
            nci_name = nci_equity_row.iloc[0]["ê³„ì •ëª…"]
            l3_codes_map[nci_code] = nci_name
        else:
            log_validation("âš ï¸ [ìë³¸ë³€ë™í‘œ] CoAì—ì„œ ë¹„ì§€ë°°ì§€ë¶„(CE) ê³„ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        sce_cols = list(l3_codes_map.values())
        col_to_l3_map = {v: k for k, v in l3_codes_map.items()}

        # 2. ì…ë ¥ëœ CE ì‹œíŠ¸ íŒŒì‹± (ìœ„ì¹˜ ê¸°ë°˜ìœ¼ë¡œ ìˆ˜ì •)
        all_parsed_dfs = []
        all_input_dfs = [(parent_name, parent_ce_df)] + list(zip(subs_names, subs_ce_dfs))

        for name, df in all_input_dfs:
            if df.empty:
                continue
            try:
                code_row_index = df[df.iloc[:, 2] == 'ê³„ì •ì½”ë“œ'].index[0]
                codes = df.iloc[code_row_index, 3:].astype(str).str.strip().tolist()
                data_start_row = code_row_index + 1
                
                data_df = df.iloc[data_start_row:].copy()
                
                num_desc_cols = 3
                num_data_cols = len(codes)
                data_df = data_df.iloc[:, :(num_desc_cols + num_data_cols)]

                # ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì»¬ëŸ¼ ì´ë¦„ì„ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •
                desc_names = ['_col_company', 'êµ¬ë¶„', 'ê³„ì •ì½”ë“œ'] 
                data_df.columns = desc_names + codes
                data_df['íšŒì‚¬ëª…'] = name
                all_parsed_dfs.append(data_df)
            except (IndexError, KeyError) as e:
                log_validation(f"âš ï¸ [ìë³¸ë³€ë™í‘œ] {name}ì˜ CE ì‹œíŠ¸ ì–‘ì‹ì„ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
                continue

        if not all_parsed_dfs:
            log_validation("âš ï¸ [ìë³¸ë³€ë™í‘œ] ìœ íš¨í•œ CE ì‹œíŠ¸ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()

        combined_ce_df = pd.concat(all_parsed_dfs, ignore_index=True)
        rename_dict = {code: name for code, name in l3_codes_map.items() if code in combined_ce_df.columns}
        combined_ce_df.rename(columns=rename_dict, inplace=True)

        for col in sce_cols:
            if col in combined_ce_df.columns:
                combined_ce_df[col] = pd.to_numeric(combined_ce_df[col], errors='coerce').fillna(0)
            else:
                combined_ce_df[col] = 0

        # 3. ê¸°ì´ˆìë³¸ ê³„ì‚°
        beginning_simple_sum = combined_ce_df[combined_ce_df['ê³„ì •ì½”ë“œ'] == 'Beginning'][sce_cols].sum()

        adj_xls = pd.ExcelFile(adjustment_file)

        if "CAJE_BSPL" in adj_xls.sheet_names:
            full_adj_df = pd.read_excel(adj_xls, "CAJE_BSPL", dtype={'ê³„ì •ì½”ë“œ': str})
        else:
            full_adj_df = pd.DataFrame()

        beginning_adjustments = pd.Series(dtype='float64')
        if not full_adj_df.empty:
            full_adj_df = full_adj_df.dropna(subset=['ê³„ì •ì½”ë“œ'])

            if not full_adj_df.empty:
                full_adj_df['ê³„ì •ì½”ë“œ'] = full_adj_df['ê³„ì •ì½”ë“œ'].astype(str).str.strip().str.split('.').str[0]
                if 'FS_Element' in full_adj_df.columns:
                    full_adj_df = full_adj_df.drop(columns=['FS_Element'])
                full_adj_df = full_adj_df.merge(coa_df[['ê³„ì •ì½”ë“œ', 'FS_Element', 'L3_code']], on='ê³„ì •ì½”ë“œ', how='left')

                # FIX: L3_codeê°€ ì—†ëŠ” ìë³¸/ë¹„ì§€ë°°ì§€ë¶„ í•­ëª©ì€ ê³„ì •ì½”ë“œë¥¼ L3_codeë¡œ ì‚¬ìš©
                is_equity_like = full_adj_df['FS_Element'].isin(['E', 'CE'])
                is_l3_missing = full_adj_df['L3_code'].isna()
                full_adj_df.loc[is_equity_like & is_l3_missing, 'L3_code'] = full_adj_df.loc[is_equity_like & is_l3_missing, 'ê³„ì •ì½”ë“œ']

                full_adj_df['ê¸ˆì•¡'] = pd.to_numeric(full_adj_df['ê¸ˆì•¡'], errors='coerce').fillna(0)

                beg_adj_df = full_adj_df[full_adj_df['ë‹¹ê¸°ì „ê¸°'] != 'ë‹¹ê¸°'].copy()
                beg_equity_adjs = beg_adj_df[beg_adj_df['FS_Element'].isin(['E', 'CE'])].copy()

                if not beg_equity_adjs.empty:
                    beg_equity_adjs.loc[:, 'ê¸ˆì•¡'] *= -1
                    beginning_adjustments = beg_equity_adjs.groupby('L3_code')['ê¸ˆì•¡'].sum()

        beginning_row = pd.Series(0, index=sce_cols, name='ê¸°ì´ˆ')
        beginning_row.update(beginning_simple_sum)
        for code, amount in beginning_adjustments.items():
            if code in l3_codes_map:
                beginning_row[l3_codes_map[code]] += amount

        # 4. ë‹¹ê¸° ë³€ë™ë¶„ ê³„ì‚°
        current_changes_df = combined_ce_df[~combined_ce_df['ê³„ì •ì½”ë“œ'].isin(['Beginning', 'Ending'])].copy()
        
        r_adj_sum = merged_bspl_df.loc[merged_bspl_df["FS_Element"] == "R", "ì—°ê²°ì¡°ì •"].sum()
        x_adj_sum = merged_bspl_df.loc[merged_bspl_df["FS_Element"] == "X", "ì—°ê²°ì¡°ì •"].sum()
        pl_adj_sum = -r_adj_sum - x_adj_sum
        nci_pl_adj = merged_bspl_df.loc[merged_bspl_df["FS_Element"] == "CR", "ì—°ê²°ì¡°ì •"].sum()
        
        ni_adj_row = pd.DataFrame([{'êµ¬ë¶„': 'ë‹¹ê¸°ìˆœì†ìµ(ì—°ê²°ì¡°ì •)', 'ì´ìµì‰ì—¬ê¸ˆ': pl_adj_sum - nci_pl_adj, 'ë¹„ì§€ë°°ì§€ë¶„': nci_pl_adj}]).fillna(0)
        
        curr_adj_df = full_adj_df[full_adj_df['ë‹¹ê¸°ì „ê¸°'] == 'ë‹¹ê¸°'].copy()
        curr_equity_adjs = curr_adj_df[curr_adj_df['FS_Element'].isin(['E', 'CE'])].copy()
        curr_equity_adjs.loc[:, 'ê¸ˆì•¡'] *= -1
        
        pl_related_codes = merged_bspl_df[merged_bspl_df['FS_Element'].isin(['R', 'X', 'CR'])]['ê³„ì •ì½”ë“œ'].unique()
        
        # FS_Element == 'R' ê³„ì •ì´ë©´ ê¸ˆì•¡ì„ ìŒìˆ˜ë¡œ ë³€í™˜
        direct_equity_adjs = curr_equity_adjs[~curr_equity_adjs['ê³„ì •ì½”ë“œ'].isin(pl_related_codes)].copy()
        # direct_equity_adjs.loc[direct_equity_adjs['FS_Element'] == 'R', 'ê¸ˆì•¡'] *= -1
        # ê³„ì •ì½”ë“œë³„ í•©ì‚°
        direct_adj_by_code = direct_equity_adjs.groupby('L3_code')['ê¸ˆì•¡'].sum()
        

        direct_adj_row_data = {'êµ¬ë¶„': 'ê¸°íƒ€ìë³¸(ì—°ê²°ì¡°ì •)'}
        for code, amount in direct_adj_by_code.items():
            if code in l3_codes_map:
                direct_adj_row_data[l3_codes_map[code]] = amount
        direct_adj_row = pd.DataFrame([direct_adj_row_data]).fillna(0)

        # 5. ìµœì¢… ì¡°ë¦½
        beg_sce = pd.DataFrame([beginning_row])
        final_sce = pd.concat([beg_sce, current_changes_df.groupby('êµ¬ë¶„')[sce_cols].sum()], ignore_index=False)
        final_sce = pd.concat([final_sce, ni_adj_row.set_index('êµ¬ë¶„')], ignore_index=False)
        if not direct_adj_row.empty and direct_adj_row.drop(columns=['êµ¬ë¶„']).iloc[0].abs().sum() > 1:
             final_sce = pd.concat([final_sce, direct_adj_row.set_index('êµ¬ë¶„')], ignore_index=False)

        final_sce = final_sce.loc[(final_sce[sce_cols].abs().sum(axis=1)) > 1].fillna(0)
        final_sce.loc['ê¸°ë§', sce_cols] = final_sce[sce_cols].sum()

        # 6. ê²€ì¦ í–‰ ì¶”ê°€
        l3_map = dict(zip(coa_df['ê³„ì •ì½”ë“œ'], coa_df['L3_code']))
        if 'L3_code' not in merged_bspl_df.columns:
             merged_bspl_df['L3_code'] = merged_bspl_df['ê³„ì •ì½”ë“œ'].map(l3_map)

        # For CE elements (NCI), if L3_code is null, use the account code itself.
        is_ce = merged_bspl_df['FS_Element'] == 'CE'
        is_l3_missing = merged_bspl_df['L3_code'].isna()
        merged_bspl_df.loc[is_ce & is_l3_missing, 'L3_code'] = merged_bspl_df.loc[is_ce & is_l3_missing, 'ê³„ì •ì½”ë“œ']

        l3_totals = merged_bspl_df.groupby('L3_code')['ì—°ê²°ê¸ˆì•¡'].sum()
        
        verification_row = pd.Series(index=sce_cols, name="ê²€ì¦(ì—°ê²°BS)")
        for col, code in col_to_l3_map.items():
            verification_row[col] = l3_totals.get(code, 0)
        final_sce.loc['ê²€ì¦(ì—°ê²°BS)'] = verification_row

        final_sce = final_sce.reset_index().rename(columns={'index': 'êµ¬ë¶„'})
        
        # 'êµ¬ë¶„'ì— ì¤‘ë³µì´ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ì²« ë²ˆì§¸ 'ê³„ì •ì½”ë“œ'ë¥¼ ì‚¬ìš©í•˜ë„ë¡ ì¤‘ë³µì„ ì œê±°í•˜ì—¬ mapì„ ìƒì„±
        temp_map_df = combined_ce_df[['êµ¬ë¶„', 'ê³„ì •ì½”ë“œ']].dropna(subset=['êµ¬ë¶„']).drop_duplicates(subset=['êµ¬ë¶„'])
        row_to_code_map = pd.Series(temp_map_df.ê³„ì •ì½”ë“œ.values, index=temp_map_df.êµ¬ë¶„).to_dict()

        row_to_code_map.update({'ê¸°ì´ˆ': 'Beginning', 'ê¸°ë§': 'Ending', 'ê²€ì¦(ì—°ê²°BS)': 'Verification', 'ë‹¹ê¸°ìˆœì†ìµ(ì—°ê²°ì¡°ì •)': 'CE11_NI', 'ê¸°íƒ€ìë³¸(ì—°ê²°ì¡°ì •)': 'CE12_CAJE'})
        final_sce.insert(1, 'ì¡°ì •ì½”ë“œ', final_sce['êµ¬ë¶„'].map(row_to_code_map).fillna('CE9999'))
        
        return final_sce

    if st.button(
        "ğŸš€ ì—°ê²° ì¬ë¬´ì œí‘œ ìƒì„± ì‹¤í–‰",
        key="run_consolidation",
        disabled=not (
            st.session_state.files["coa"] and st.session_state.files["parent"]
        ),
    ):
        with st.spinner("ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ê³  ìˆìŠµë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."):
            # Reset previous results
            st.session_state.results["validation_log"] = []
            st.session_state.results["consolidation_wp_bs"] = None
            st.session_state.results["consolidation_wp_pl"] = None
            st.session_state.results["consolidation_wp_cf"] = None
            st.session_state.results["consolidation_wp_sce"] = None


            # íŒŒì¼ëª…ì—ì„œ íšŒì‚¬ ì´ë¦„ ì¶”ì¶œ
            parent_name = st.session_state.files["parent"].name.split("_")[0]
            subs_names = [
                f.name.split("_")[0] for f in st.session_state.files["subsidiaries"]
            ]

            try:
                # ----------------------------------------------------------------
                # 1. ë°ì´í„° ì¤€ë¹„ (íŒŒì¼ ì½ê¸° ë° ì „ì²˜ë¦¬)
                # ----------------------------------------------------------------
                @st.cache_data
                def load_and_clean_data(
                    coa_file, parent_file, parent_name, subs_files, subs_names, adj_file
                ):
                    def clean_df(df, key_col="ê³„ì •ì½”ë“œ"):
                        if key_col in df.columns:
                            df[key_col] = (
                                df[key_col]
                                .astype(str)
                                .str.strip()
                                .str.split(".")
                                .str[0]
                            )
                            df = df.dropna(subset=[key_col])
                        return df

                    def read_fs_sheets(file, file_name=""):
                        try:
                            file.seek(0)
                            xls = pd.ExcelFile(file)
                            bspl_df = (
                                pd.read_excel(
                                    xls, sheet_name="BSPL", dtype={"ê³„ì •ì½”ë“œ": str}
                                )
                                if "BSPL" in xls.sheet_names
                                else pd.DataFrame()
                            )
                            cf_df = (
                                pd.read_excel(
                                    xls,
                                    sheet_name="CF",
                                    dtype={"ê³„ì •ì½”ë“œ": str, "CF_code": str},
                                )
                                if "CF" in xls.sheet_names
                                else pd.DataFrame()
                            )

                            bspl_df = clean_df(bspl_df, "ê³„ì •ì½”ë“œ")
                            if "CF_code" in cf_df.columns:
                                cf_df = clean_df(cf_df, "CF_code")
                            elif "ê³„ì •ì½”ë“œ" in cf_df.columns:
                                cf_df = clean_df(cf_df, "ê³„ì •ì½”ë“œ").rename(
                                    columns={"ê³„ì •ì½”ë“œ": "CF_code"}
                                )

                            for df in [bspl_df, cf_df]:
                                if "ê¸ˆì•¡" in df.columns:
                                    df["ê¸ˆì•¡"] = pd.to_numeric(
                                        df["ê¸ˆì•¡"], errors="coerce"
                                    ).fillna(0)

                            return bspl_df, cf_df
                        except Exception as e:
                            st.error(f"'{file_name}' íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                            return pd.DataFrame(), pd.DataFrame()
                    
                    coa_file.seek(0)
                    coa_df = clean_df(
                        pd.read_excel(coa_file, sheet_name="CoA", dtype=str), "ê³„ì •ì½”ë“œ"
                    )
                    xls_coa = pd.ExcelFile(coa_file)
                    cf_coa_df = pd.DataFrame()
                    if "CF" in xls_coa.sheet_names:
                        cf_coa_df = pd.read_excel(xls_coa, sheet_name="CF", dtype=str)
                        if "CF_code" in cf_coa_df.columns:
                            cf_coa_df = clean_df(cf_coa_df, "CF_code")
                    else:
                        log_validation(
                            "ê²½ê³ : CoA íŒŒì¼ì— 'CF' ì‹œíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. í˜„ê¸ˆíë¦„í‘œ ì§‘ê³„ê°€ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                        )

                    aje_code = pd.read_excel(coa_file, sheet_name="AJE", dtype=str)

                    parent_bspl_df, parent_cf_df = read_fs_sheets(
                        parent_file, parent_name
                    )
                    parent_bspl_df = parent_bspl_df.rename(
                        columns={"ê¸ˆì•¡": parent_name}
                    )
                    parent_cf_df = parent_cf_df.rename(columns={"ê¸ˆì•¡": parent_name})

                    subs_bspl_dfs, subs_cf_dfs = [], []
                    for f, sub_name in zip(subs_files, subs_names):
                        bspl, cf = read_fs_sheets(f, sub_name)
                        subs_bspl_dfs.append(bspl.rename(columns={"ê¸ˆì•¡": sub_name}))
                        subs_cf_dfs.append(cf.rename(columns={"ê¸ˆì•¡": sub_name}))

                    caje_bspl_df, caje_cf_df, re_code = (
                        pd.DataFrame(),
                        pd.DataFrame(),
                        None,
                    )
                    if adj_file:
                        try:
                            adj_file.seek(0)
                            xls_adj = pd.ExcelFile(adj_file)
                            if "CAJE_BSPL" in xls_adj.sheet_names:
                                caje_bspl_df = pd.read_excel(
                                    xls_adj,
                                    sheet_name="CAJE_BSPL",
                                    dtype={"ê³„ì •ì½”ë“œ": str},
                                )
                                caje_bspl_df = clean_df(caje_bspl_df, "ê³„ì •ì½”ë“œ")
                                if "ê¸ˆì•¡" in caje_bspl_df.columns:
                                    caje_bspl_df["ê¸ˆì•¡"] = pd.to_numeric(
                                        caje_bspl_df["ê¸ˆì•¡"], errors="coerce"
                                    ).fillna(0)

                            if "CAJE_CF" in xls_adj.sheet_names:
                                caje_cf_df = pd.read_excel(
                                    xls_adj,
                                    sheet_name="CAJE_CF",
                                    dtype={"ê³„ì •ì½”ë“œ": str},
                                )
                                caje_cf_df = clean_df(caje_cf_df, "ê³„ì •ì½”ë“œ")
                                if "ì¡°ì •ê¸ˆì•¡" in caje_cf_df.columns:
                                    caje_cf_df["ì¡°ì •ê¸ˆì•¡"] = pd.to_numeric(
                                        caje_cf_df["ì¡°ì •ê¸ˆì•¡"], errors="coerce"
                                    ).fillna(0)




                        except Exception as e:
                            log_validation(
                                f"ğŸš¨ ì˜¤ë¥˜: ì¡°ì •ë¶„ê°œ íŒŒì¼({adj_file.name}) ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
                            )

                    return (
                        coa_df,
                        cf_coa_df,
                        parent_bspl_df,
                        parent_cf_df,
                        subs_bspl_dfs,
                        subs_cf_dfs,
                        caje_bspl_df,
                        caje_cf_df,
                        re_code,
                        aje_code,
                    )

                (
                    coa_df,
                    cf_coa_df,
                    parent_bspl_df,
                    parent_cf_df,
                    subs_bspl_dfs,
                    subs_cf_dfs,
                    caje_bspl_df,
                    caje_cf_df_from_file,
                    re_code,
                    aje_code
                ) = load_and_clean_data(
                    st.session_state.files["coa"],
                    st.session_state.files["parent"],
                    parent_name,
                    st.session_state.files["subsidiaries"],
                    tuple(subs_names),  # ë¦¬ìŠ¤íŠ¸ëŠ” í•´ì‹œ ë¶ˆê°€ëŠ¥í•˜ë¯€ë¡œ íŠœí”Œë¡œ ë³€í™˜
                    st.session_state.files["adjustment"],
                )

                # ----------------------------------------------------------------
                # 2. ë°ì´í„° ê²€ì¦
                # ----------------------------------------------------------------
                def check_duplicates(df, name):
                    if "ê³„ì •ì½”ë“œ" in df.columns:
                        dups = df["ê³„ì •ì½”ë“œ"].value_counts().loc[lambda x: x > 1]
                        if not dups.empty:
                            log_validation(
                                f"âš ï¸ **[{name}]** ì¤‘ë³µ ê³„ì •ì½”ë“œ ë°œê²¬: {', '.join(dups.index)}"
                            )

                def check_missing_in_coa(df, coa_codes, name):
                    if "ê³„ì •ì½”ë“œ" in df.columns:
                        missing = set(df["ê³„ì •ì½”ë“œ"]) - coa_codes
                        if missing:
                            log_validation(
                                f"ğŸš¨ **[{name}]** CoAì— ì—†ëŠ” ê³„ì •ì½”ë“œ ë°œê²¬: {', '.join(sorted(list(missing)))}"
                            )

                def check_balance_sheet_equation(df, coa_df, column_name):
                    """ì¬ë¬´ìƒíƒœí‘œ ì°¨ëŒ€ ê²€ì¦ (ìì‚° = ë¶€ì±„ + ìë³¸)"""
                    if "ê³„ì •ì½”ë“œ" in df.columns and column_name in df.columns:
                        if "FS_Element" in df.columns:
                            merged = df
                        elif "FS_Element" in coa_df.columns:
                            merged = df.merge(
                                coa_df[["ê³„ì •ì½”ë“œ", "FS_Element"]],
                                on="ê³„ì •ì½”ë“œ",
                                how="left",
                            )
                        else:
                            return  # Cannot perform check

                        total_assets = pd.to_numeric(
                            merged[merged["FS_Element"].isin(["A", "CA"])][column_name],
                            errors="coerce",
                        ).sum()
                        total_liabilities = pd.to_numeric(
                            merged[merged["FS_Element"] == "L"][column_name],
                            errors="coerce",
                        ).sum()
                        total_equity = pd.to_numeric(
                            merged[merged["FS_Element"].isin(["E", "CE"])][column_name],
                            errors="coerce",
                        ).sum()
                        difference = total_assets - (total_liabilities + total_equity)

                        if abs(difference) > 1:  # ì‚¬ì†Œí•œ ë°˜ì˜¬ë¦¼ ì˜¤ë¥˜ëŠ” ë¬´ì‹œ
                            log_validation(
                                f"âŒ **[{column_name}]** ì¬ë¬´ìƒíƒœí‘œ ì°¨ëŒ€ ë¶ˆì¼ì¹˜: {difference:,.0f}"
                            )
                        else:
                            log_validation(
                                f"âœ… **[{column_name}]** ì¬ë¬´ìƒíƒœí‘œ ì°¨ëŒ€ ì¼ì¹˜"
                            )

                check_duplicates(parent_bspl_df, parent_name)
                for name, df in zip(subs_names, subs_bspl_dfs):
                    check_duplicates(df, name)

                coa_codes = set(coa_df["ê³„ì •ì½”ë“œ"])
                check_missing_in_coa(parent_bspl_df, coa_codes, parent_name)
                for name, df in zip(subs_names, subs_bspl_dfs):
                    check_missing_in_coa(df, coa_codes, name)

                # ----------------------------------------------------------------
                # 3. BS/PL ë°ì´í„° í†µí•© ë° ê³„ì‚°
                # ----------------------------------------------------------------
                merged_bspl_df = coa_df.merge(parent_bspl_df[["ê³„ì •ì½”ë“œ", parent_name]], on="ê³„ì •ì½”ë“œ", how="left", sort=False)
                for name, df in zip(subs_names, subs_bspl_dfs):
                    merged_bspl_df = merged_bspl_df.merge(df[["ê³„ì •ì½”ë“œ", name]], on="ê³„ì •ì½”ë“œ", how="left", sort=False)

                bspl_val_cols = [parent_name] + subs_names
                merged_bspl_df[bspl_val_cols] = merged_bspl_df[bspl_val_cols].fillna(0)
                merged_bspl_df["ë‹¨ìˆœí•©ê³„"] = merged_bspl_df[bspl_val_cols].sum(axis=1)

                check_balance_sheet_equation(merged_bspl_df, coa_df, parent_name)
                for name in subs_names:
                    check_balance_sheet_equation(merged_bspl_df, coa_df, name)
                check_balance_sheet_equation(merged_bspl_df, coa_df, "ë‹¨ìˆœí•©ê³„")

                if not caje_bspl_df.empty and "ê³„ì •ì½”ë“œ" in caje_bspl_df.columns:
                    adj_bspl_grouped = caje_bspl_df.groupby("ê³„ì •ì½”ë“œ")["ê¸ˆì•¡"].sum().reset_index()
                    adj_with_fs = adj_bspl_grouped.merge(coa_df[["ê³„ì •ì½”ë“œ", "FS_Element"]], on="ê³„ì •ì½”ë“œ", how="left")
                    is_ler = adj_with_fs["FS_Element"].isin(["L", "E", "R", "CE", "CR"])
                    adj_with_fs.loc[is_ler, "ê¸ˆì•¡"] *= -1
                    merged_bspl_df = merged_bspl_df.merge(adj_with_fs[["ê³„ì •ì½”ë“œ", "ê¸ˆì•¡"]].rename(columns={"ê¸ˆì•¡": "ì—°ê²°ì¡°ì •"}), on="ê³„ì •ì½”ë“œ", how="left", sort=False)
                    merged_bspl_df["ì—°ê²°ì¡°ì •"] = merged_bspl_df["ì—°ê²°ì¡°ì •"].fillna(0)
                else:
                    merged_bspl_df["ì—°ê²°ì¡°ì •"] = 0

                
                nci_equity_row = coa_df[coa_df["FS_Element"] == "CE"]
                if not nci_equity_row.empty:
                    nci_code = nci_equity_row.iloc[0]["ê³„ì •ì½”ë“œ"]
                    nci_name = nci_equity_row.iloc[0]["ê³„ì •ëª…"]
                
                nci_pl_row = coa_df[coa_df["FS_Element"] == "CR"]
                if not nci_pl_row.empty:
                    NCI_PL_CODE = nci_pl_row.iloc[0]["ê³„ì •ì½”ë“œ"]
                    NCI_PL_NAME = nci_pl_row.iloc[0]["ê³„ì •ëª…"]

                nci_pl_sum = merged_bspl_df.loc[merged_bspl_df["FS_Element"] == "CR", "ì—°ê²°ì¡°ì •"].sum()

                if not nci_pl_row.empty and not nci_equity_row.empty:
                    nci_equity_code = nci_equity_row.iloc[0]['ê³„ì •ì½”ë“œ']
                    if (merged_bspl_df['ê³„ì •ì½”ë“œ'] == nci_equity_code).any():
                        merged_bspl_df.loc[merged_bspl_df['ê³„ì •ì½”ë“œ'] == nci_equity_code, 'ì—°ê²°ì¡°ì •'] += nci_pl_sum
                
                r_adj_sum = merged_bspl_df.loc[merged_bspl_df["FS_Element"] == "R", "ì—°ê²°ì¡°ì •"].sum()
                x_adj_sum = merged_bspl_df.loc[merged_bspl_df["FS_Element"] == "X", "ì—°ê²°ì¡°ì •"].sum()
                pl_adj_sum = r_adj_sum - x_adj_sum

                aje_code = pd.read_excel(
                    st.session_state.files["coa"], sheet_name="AJE", dtype=str
                )
                re_code = aje_code.loc[aje_code["FS_Element"] == "E", "ê³„ì •ì½”ë“œ"].iloc[0]
                merged_bspl_df.loc[merged_bspl_df["ê³„ì •ì½”ë“œ"] == re_code, "ì—°ê²°ì¡°ì •"] += pl_adj_sum
                        
                merged_bspl_df["ì—°ê²°ê¸ˆì•¡"] = merged_bspl_df["ë‹¨ìˆœí•©ê³„"] + merged_bspl_df["ì—°ê²°ì¡°ì •"]
                log_validation("--- ì—°ê²°ê¸ˆì•¡ ê¸°ì¤€ ì°¨ëŒ€ ê²€ì¦ ---")
                check_balance_sheet_equation(merged_bspl_df, coa_df, "ì—°ê²°ê¸ˆì•¡")

                # ----------------------------------------------------------------
                # 4. CF ë°ì´í„° í†µí•© ë° ê³„ì‚°
                # ----------------------------------------------------------------
                CF_KEY = "CF_code"
                merged_cf_df = pd.DataFrame()
                if not cf_coa_df.empty and CF_KEY in cf_coa_df.columns:
                    merged_cf_df = cf_coa_df.merge(parent_cf_df[[CF_KEY, parent_name]], on=CF_KEY, how="left", sort=False)
                    for name, df in zip(subs_names, subs_cf_dfs):
                        if CF_KEY in df.columns:
                            merged_cf_df = merged_cf_df.merge(df[[CF_KEY, name]], on=CF_KEY, how="left", sort=False)
                    
                    cf_val_cols = [parent_name] + subs_names
                    merged_cf_df[cf_val_cols] = merged_cf_df[cf_val_cols].fillna(0)
                    merged_cf_df["ë‹¨ìˆœí•©ê³„"] = merged_cf_df[cf_val_cols].sum(axis=1)

                    if not caje_cf_df_from_file.empty and "ê³„ì •ì½”ë“œ" in caje_cf_df_from_file.columns and "ì¡°ì •ê¸ˆì•¡" in caje_cf_df_from_file.columns:
                        adj_cf_grouped = caje_cf_df_from_file.groupby("ê³„ì •ì½”ë“œ")["ì¡°ì •ê¸ˆì•¡"].sum().reset_index()
                        merged_cf_df = merged_cf_df.merge(adj_cf_grouped.rename(columns={"ì¡°ì •ê¸ˆì•¡": "ì—°ê²°ì¡°ì •"}), on="ê³„ì •ì½”ë“œ", how="left")
                    else:
                        merged_cf_df["ì—°ê²°ì¡°ì •"] = 0
                    
                    merged_cf_df["ì—°ê²°ì¡°ì •"] = merged_cf_df["ì—°ê²°ì¡°ì •"].fillna(0)
                    merged_cf_df["ì—°ê²°ê¸ˆì•¡"] = merged_cf_df["ë‹¨ìˆœí•©ê³„"] + merged_cf_df["ì—°ê²°ì¡°ì •"]

                # ----------------------------------------------------------------
                # 5. ì†Œê³„ ë° ìµœì¢… FS ìƒì„±
                # ----------------------------------------------------------------
                def generate_fs_with_subtotals(
                    df,
                    name_cols,
                    amount_cols,
                    name_code_map,
                    desc_col="ê³„ì •ëª…",
                    code_col="ê³„ì •ì½”ë“œ",
                ):
                    df = df.copy()

                    # Sign ë¡œì§ ì ìš©
                    apply_sign_logic = "sign" in df.columns
                    if apply_sign_logic:
                        df["sign"] = pd.to_numeric(df["sign"], errors="coerce").fillna(
                            1
                        )
                        for col in amount_cols:
                            if col in df.columns:
                                df[col] = df[col] * df["sign"]

                    # ì†Œê³„ ê³„ì‚°ì„ ìœ„í•œ ì¬ê·€ í•¨ìˆ˜
                    def recursive_subtotal(data, current_name_cols, level=0):
                        if not current_name_cols or data.empty:
                            return data

                        current_col, remaining_cols = (
                            current_name_cols[0],
                            current_name_cols[1:],
                        )
                        all_sub_dfs = []

                        # ë ˆë²¨ ì •ë³´ê°€ ìˆëŠ” ê·¸ë£¹ ë¨¼ì € ì²˜ë¦¬
                        for key, group in data.dropna(subset=[current_col]).groupby(
                            current_col, sort=False
                        ):
                            sub_df = recursive_subtotal(
                                group, remaining_cols, level + 1
                            )

                            # í•©ê³„ í–‰ ìƒì„±
                            sum_data = {col: "" for col in data.columns}
                            sum_data.update(group[amount_cols].sum())
                            sum_data[desc_col] = f"{'' * level}{key}"  # ë“¤ì—¬ì“°ê¸°
                            sum_data[code_col] = name_code_map.get(key, "")

                            # FS_Element, sign ë“± ë©”íƒ€ë°ì´í„° ë³µì‚¬
                            if not group.empty:
                                for col in ["FS_Element", "sign"]:
                                    if col in group.columns:
                                        sum_data[col] = group.iloc[0][col]

                            sum_row = pd.DataFrame([sum_data])
                            all_sub_dfs.append(
                                pd.concat([sub_df, sum_row], ignore_index=True)
                            )

                        # ë ˆë²¨ ì •ë³´ê°€ ì—†ëŠ”(NaN) ê·¸ë£¹ì„ ë‚˜ì¤‘ì— ì²˜ë¦¬í•˜ì—¬ ì•„ë˜ë¡œ ë³´ëƒ„
                        nan_group = data[data[current_col].isna()]
                        if not nan_group.empty:
                            all_sub_dfs.append(
                                recursive_subtotal(nan_group, remaining_cols, level + 1)
                            )

                        # all_sub_dfsê°€ ë¹„ì–´ìˆëŠ” ê²½ìš° ì—ëŸ¬ ë°©ì§€
                        if not all_sub_dfs:
                            return pd.DataFrame(columns=data.columns)

                        return pd.concat(all_sub_dfs, ignore_index=True)

                    final_df = recursive_subtotal(df, name_cols)

                    # Sign ì›ë³µ
                    if apply_sign_logic and not final_df.empty:
                        final_df["sign"] = (
                            pd.to_numeric(final_df["sign"], errors="coerce")
                            .fillna(1)
                            .replace(0, 1)
                        )
                        final_df[amount_cols] = final_df[amount_cols].divide(
                            final_df["sign"], axis=0
                        )

                    return final_df

                # BS, PL, CF ë°ì´í„° ë¶„ë¦¬ ë° ì†Œê³„ ìƒì„±
                df_bs = merged_bspl_df[
                    merged_bspl_df["FS_Element"].isin(["A", "L", "E", "CA", "CE"])
                ].copy()
                df_bs["sign"] = (
                    df_bs["FS_Element"]
                    .map({"A": -1, "CA": -1, "L": 1, "E": 1, "CE": 1})
                    .fillna(1)
                )

                df_pl = merged_bspl_df[
                    merged_bspl_df["FS_Element"].isin(["R", "X", "CR"])
                ].copy()
                df_pl["sign"] = df_pl["FS_Element"].map({"R": 1, "X": -1, "CR": 1}).fillna(1)

                df_cf = merged_cf_df.copy()
                if "FS_Element" in df_cf.columns:  # CFì˜ FS_ElementëŠ” ë¶€í˜¸ë¡œ ì‚¬ìš©
                    df_cf["sign"] = pd.to_numeric(
                        df_cf["FS_Element"], errors="coerce"
                    ).fillna(1)

                # ì†Œê³„ ìƒì„±ì„ ìœ„í•œ ì„¤ì •
                con_amtcols = (
                    [parent_name] + subs_names + ["ë‹¨ìˆœí•©ê³„", "ì—°ê²°ì¡°ì •", "ì—°ê²°ê¸ˆì•¡"]
                )
                bspl_name_cols = [
                    c
                    for c in coa_df.columns
                    if c.startswith("L") and not c.endswith("code")
                ]
                cf_name_cols = [
                    c
                    for c in cf_coa_df.columns
                    if c.startswith("L") and not c.endswith("code")
                ]

                # ì´ë¦„-ì½”ë“œ ë§¤í•‘ ìƒì„±
                bspl_name_code_map = {
                    row[name]: row[code]
                    for code, name in zip(
                        [
                            c
                            for c in coa_df.columns
                            if c.startswith("L") and c.endswith("code")
                        ],
                        bspl_name_cols,
                    )
                    for _, row in coa_df.iterrows()
                    if pd.notna(row.get(name))
                }
                cf_name_code_map = {
                    row[name]: row[code]
                    for code, name in zip(
                        [
                            c
                            for c in cf_coa_df.columns
                            if c.startswith("L") and c.endswith("code")
                        ],
                        cf_name_cols,
                    )
                    for _, row in cf_coa_df.iterrows()
                    if pd.notna(row.get(name))
                }

                # ìµœì¢… FS ìƒì„±
                bs_final = generate_fs_with_subtotals(
                    df_bs, bspl_name_cols, con_amtcols, bspl_name_code_map
                )
                pl_final = generate_fs_with_subtotals(
                    df_pl, bspl_name_cols, con_amtcols, bspl_name_code_map
                )
                cf_final = generate_fs_with_subtotals(
                    df_cf,
                    cf_name_cols,
                    con_amtcols,
                    cf_name_code_map,
                    desc_col="í˜„ê¸ˆíë¦„í‘œ",
                    code_col="CF_code",
                )

                # ë¶ˆí•„ìš”í•œ ë ˆë²¨ ì»¬ëŸ¼ ì œê±° ë° ìµœì¢… ì •ë¦¬
                level_cols = [c for c in coa_df.columns if c.startswith("L")] + [
                    c for c in cf_coa_df.columns if c.startswith("L")
                ]
                l_cols_to_drop = list(set(level_cols + ["sign"]))
                bs_final.drop(
                    columns=[c for c in l_cols_to_drop if c in bs_final.columns],
                    inplace=True,
                )
                pl_final.drop(
                    columns=[c for c in l_cols_to_drop if c in pl_final.columns],
                    inplace=True,
                )
                cf_final.drop(
                    columns=[c for c in l_cols_to_drop if c in cf_final.columns],
                    inplace=True,
                )

                # ì†Œê³„ í–‰ ì‹ë³„ ë° 'is_subtotal' ì»¬ëŸ¼ ì¶”ê°€
                bspl_name_cols = [
                    c
                    for c in coa_df.columns
                    if c.startswith("L") and not c.endswith("code")
                ]
                if bspl_name_cols:
                    bspl_subtotal_names = set(coa_df[bspl_name_cols].stack().unique())
                    if not bs_final.empty:
                        bs_final["is_subtotal"] = bs_final["ê³„ì •ëª…"].isin(
                            bspl_subtotal_names
                        )
                    if not pl_final.empty:
                        pl_final["is_subtotal"] = pl_final["ê³„ì •ëª…"].isin(
                            bspl_subtotal_names
                        )

                cf_name_cols = [
                    c
                    for c in cf_coa_df.columns
                    if c.startswith("L") and not c.endswith("code")
                ]
                if not cf_coa_df.empty and cf_name_cols:
                    cf_subtotal_names = set(cf_coa_df[cf_name_cols].stack().unique())
                    if not cf_final.empty:
                        cf_final["is_subtotal"] = cf_final["í˜„ê¸ˆíë¦„í‘œ"].isin(
                            cf_subtotal_names
                        )

                # 0ì— ê°€ê¹Œìš´ ê°’ ì •ë¦¬ ë° ì •ìˆ˜ ë³€í™˜
                processed_dfs = []
                for df in [bs_final, pl_final, cf_final]:
                    if not df.empty:
                        df = df.copy()
                        amt_cols_in_df = [c for c in con_amtcols if c in df.columns]

                        if amt_cols_in_df:
                            df.loc[
                                (df[amt_cols_in_df].abs().sum(axis=1)) < 0.01,
                                amt_cols_in_df,
                            ] = 0
                            df[amt_cols_in_df] = (
                                df[amt_cols_in_df].fillna(0).round().astype("int64")
                            )

                            # ê¸ˆì•¡ì´ ëª¨ë‘ 0ì´ë©´ì„œ ì†Œê³„ê°€ ì•„ë‹Œ í–‰ì„ ì œê±°
                            if "is_subtotal" in df.columns:
                                all_zeros = (df[amt_cols_in_df] == 0).all(axis=1)
                                is_not_subtotal = df["is_subtotal"] == False
                                rows_to_remove = all_zeros & is_not_subtotal
                                df = df[~rows_to_remove]
                            else:
                                log_validation(
                                    "âš ï¸ ê²½ê³ : 'is_subtotal' ì»¬ëŸ¼ì´ ì—†ì–´ ì¼ë¶€ 0ì› í–‰ì´ ì œê±°ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                                )
                    processed_dfs.append(df)
                bs_final, pl_final, cf_final = processed_dfs

                # --- CF ê²€ì¦ ë¡œì§ ì¶”ê°€ (ì—°ê²°ì¡°ì • í•©ê³„) ---
                if (
                    not df_cf.empty
                    and "ì—°ê²°ì¡°ì •" in df_cf.columns
                    and "sign" in df_cf.columns
                ):
                    # Signì„ ë°˜ì˜í•œ ì—°ê²°ì¡°ì • ê¸ˆì•¡ì˜ í•©ê³„ê°€ 0ì¸ì§€ ê²€ì¦
                    total_cf_adjustment = (df_cf["ì—°ê²°ì¡°ì •"] * df_cf["sign"]).sum()
                    if abs(total_cf_adjustment) > 1:  # ì‚¬ì†Œí•œ ë°˜ì˜¬ë¦¼ ì˜¤ë¥˜ëŠ” ë¬´ì‹œ
                        log_validation(
                            f"âŒ **[í˜„ê¸ˆíë¦„í‘œ ê²€ì¦]** ì—°ê²°ì¡°ì •ì˜ í•©ê³„(ë¶€í˜¸ ë°˜ì˜)ê°€ 0ì´ ì•„ë‹™ë‹ˆë‹¤: {total_cf_adjustment:,.0f}"
                        )
                    else:
                        log_validation(
                            f"âœ… **[í˜„ê¸ˆíë¦„í‘œ ê²€ì¦]** ì—°ê²°ì¡°ì •ì˜ í•©ê³„(ë¶€í˜¸ ë°˜ì˜)ê°€ 0ìœ¼ë¡œ ì¼ì¹˜í•©ë‹ˆë‹¤."
                        )

                # CF ë‘ë²ˆì§¸ í–‰(ë‹¹ê¸°ìˆœì´ìµ ë¶€ë¶„í•©) ì œê±°
                cf_final = cf_final.drop(cf_final.index[1])
                # ì„¸ì…˜ ìƒíƒœì— ê²°ê³¼ ì €ì¥
                st.session_state.results["consolidation_wp_bs"] = bs_final
                st.session_state.results["consolidation_wp_pl"] = pl_final
                st.session_state.results["consolidation_wp_cf"] = cf_final

                # --- 6. ìë³¸ë³€ë™í‘œ ìƒì„± ---
                sce_final = pd.DataFrame()
                try:
                    parent_file = st.session_state.files["parent"]
                    parent_file.seek(0)
                    xls_parent = pd.ExcelFile(parent_file)
                    parent_ce_df = pd.read_excel(xls_parent, sheet_name="CE", header=None) if "CE" in xls_parent.sheet_names else pd.DataFrame()

                    subs_ce_dfs = []
                    for f in st.session_state.files["subsidiaries"]:
                        f.seek(0)
                        xls_sub = pd.ExcelFile(f)
                        subs_ce_dfs.append(pd.read_excel(xls_sub, sheet_name="CE", header=None) if "CE" in xls_sub.sheet_names else pd.DataFrame())
                    
                    adj_file = st.session_state.files["adjustment"]
                    if adj_file:
                        adj_file.seek(0)
                        sce_final = generate_sce_df(coa_df, parent_ce_df, subs_ce_dfs, parent_name, subs_names, adj_file, merged_bspl_df)
                    else:
                        log_validation("âš ï¸ [ìë³¸ë³€ë™í‘œ] ì¡°ì •ë¶„ê°œ íŒŒì¼ì´ ì—†ì–´ ìë³¸ë³€ë™í‘œë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

                except Exception as e:
                    log_validation(f"âš ï¸ **[ìë³¸ë³€ë™í‘œ ìƒì„± ì˜¤ë¥˜]** ìë³¸ë³€ë™í‘œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                
                st.session_state.results["consolidation_wp_sce"] = sce_final
                # --------------------------

                st.success("ğŸ‰ ì—°ê²° ì¬ë¬´ì œí‘œ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

            except Exception as e:
                st.error(f"ì—°ê²° ì¬ë¬´ì œí‘œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                st.exception(e)

    # --- ê²°ê³¼ í‘œì‹œ ---
    if st.session_state.results["validation_log"]:
        with st.expander("ğŸ” ë°ì´í„° ê²€ì¦ ë¡œê·¸ ë³´ê¸°", expanded=True):
            for log in st.session_state.results["validation_log"]:
                st.markdown(log, unsafe_allow_html=True)

    if (
        st.session_state.results.get("consolidation_wp_bs") is not None
        and not st.session_state.results["consolidation_wp_bs"].empty
    ):
        st.subheader("ğŸ“„ ì—°ê²° ì¬ë¬´ìƒíƒœí‘œ")
        st.dataframe(st.session_state.results["consolidation_wp_bs"].style.format(precision=0, thousands=","))
        st.subheader("ğŸ“„ ì—°ê²° ì†ìµê³„ì‚°ì„œ")
        st.dataframe(st.session_state.results["consolidation_wp_pl"].style.format(precision=0, thousands=","))
        st.subheader("ğŸ“„ ì—°ê²° í˜„ê¸ˆíë¦„í‘œ")
        st.dataframe(st.session_state.results["consolidation_wp_cf"].style.format(precision=0, thousands=","))
        
        if st.session_state.results.get("consolidation_wp_sce") is not None and not st.session_state.results["consolidation_wp_sce"].empty:
            st.subheader("ğŸ“„ ì—°ê²° ìë³¸ë³€ë™í‘œ")
            st.dataframe(st.session_state.results["consolidation_wp_sce"].style.format(precision=0, thousands=","))

        # --- ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ---
        excel_data = to_excel({
                "Consol_BS": st.session_state.results["consolidation_wp_bs"],
                "Consol_PL": st.session_state.results["consolidation_wp_pl"],
                "Consol_CF": st.session_state.results["consolidation_wp_cf"],
                "Consol_SCE": st.session_state.results.get("consolidation_wp_sce", pd.DataFrame()),
            })
        st.download_button(
            label="ğŸ“¥ ì „ì²´ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (Excel)",
            data=excel_data,
            file_name="consolidated_fs_results.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        )
    elif not (st.session_state.files["coa"] and st.session_state.files["parent"]):
        st.info("ì‚¬ì´ë“œë°”ì—ì„œ CoAì™€ ëª¨íšŒì‚¬ ìíšŒì‚¬ ì—°ê²°ì¡°ì •ë¶„ê°œ íŒŒì¼ì„ ì—…ë¡œë“œí•œ í›„ 'ìƒì„± ì‹¤í–‰' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")

with tab2:
    st.header("2. ì£¼ì„ ëŒ€ì‚¬ (Reconciliation)")
    st.write(
        "ëª¨íšŒì‚¬ ì£¼ì„ì„ ê¸°ì¤€ìœ¼ë¡œ ìíšŒì‚¬ ì£¼ì„ë“¤ì˜ ìˆ«ì ë°ì´í„°ë¥¼ ìœ„ì¹˜ ê¸°ë°˜ìœ¼ë¡œ í•©ì‚°í•˜ê³ , ì—°ê²°ì •ì‚°í‘œì™€ ëŒ€ì‚¬í•©ë‹ˆë‹¤."
    )
    footnote_parent_file = st.file_uploader("1. ëª¨íšŒì‚¬ ì£¼ì„ íŒŒì¼", type="xlsx")
    footnote_subs_files = st.file_uploader(
        "2. ìíšŒì‚¬ ì£¼ì„ íŒŒì¼ (ë‹¤ì¤‘ ì„ íƒ ê°€ëŠ¥)", type="xlsx", accept_multiple_files=True
    )
    if st.button("ğŸ”„ ì£¼ì„ ëŒ€ì‚¬ ì‹¤í–‰", disabled=not footnote_parent_file):
        if (
            st.session_state.results.get("consolidation_wp_bs") is None
            and footnote_subs_files
        ):
            st.warning(
                "ëŒ€ì‚¬ë¥¼ ìœ„í•´ì„œëŠ” ë¨¼ì € 'ì—°ê²° ì¬ë¬´ì œí‘œ' íƒ­ì—ì„œ 'ìƒì„± ì‹¤í–‰'ì„ ì™„ë£Œí•´ì•¼ í•©ë‹ˆë‹¤."
            )
            st.stop()
        with st.spinner("ì£¼ì„ íŒŒì¼ì„ ì·¨í•©í•˜ê³  ëŒ€ì‚¬í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            try:
                st.session_state.results["combined_footnotes"] = {}
                parent_sheets = pd.read_excel(
                    footnote_parent_file, sheet_name=None, dtype=str
                )
                subs_files_data = [
                    (Path(f.name).stem, pd.read_excel(f, sheet_name=None, dtype=str))
                    for f in footnote_subs_files
                ]

                conso_wp_df = pd.concat(
                    [
                        st.session_state.results.get(
                            "consolidation_wp_bs", pd.DataFrame()
                        ),
                        st.session_state.results.get(
                            "consolidation_wp_pl", pd.DataFrame()
                        ),
                    ]
                )
                conso_map = (
                    conso_wp_df.set_index("ê³„ì •ì½”ë“œ")["ì—°ê²°ê¸ˆì•¡"].to_dict()
                    if not conso_wp_df.empty
                    else {}
                )

                for sheet_name, parent_df in parent_sheets.items():
                    if "ì£¼ì„" not in sheet_name:
                        continue
                    all_dfs_for_sheet = []
                    parent_df_copy = parent_df.copy()
                    parent_df_copy["ì†ŒìŠ¤íŒŒì¼"] = Path(footnote_parent_file.name).stem
                    all_dfs_for_sheet.append(parent_df_copy)
                    for name, sheets in subs_files_data:
                        if sheet_name in sheets:
                            sub_df_copy = sheets[sheet_name].copy()
                            sub_df_copy["ì†ŒìŠ¤íŒŒì¼"] = name
                            all_dfs_for_sheet.append(sub_df_copy)
                    should_concat = any(
                        pd.to_numeric(df[col], errors="coerce").isna().any()
                        for df in all_dfs_for_sheet
                        for col in df.columns[2:-1]
                        if len(df.columns) > 3
                    )
                    if should_concat:
                        final_df = pd.concat(all_dfs_for_sheet, ignore_index=True)
                    else:
                        final_df = all_dfs_for_sheet[0].copy()
                        value_cols = final_df.columns[2:-1]
                        final_df[value_cols] = (
                            final_df[value_cols]
                            .apply(pd.to_numeric, errors="coerce")
                            .fillna(0)
                        )
                        for next_df in all_dfs_for_sheet[1:]:
                            next_value_cols = next_df.columns[2:-1]
                            next_df[next_value_cols] = (
                                next_df[next_value_cols]
                                .apply(pd.to_numeric, errors="coerce")
                                .fillna(0)
                            )
                            final_df[value_cols] = final_df[value_cols].add(
                                next_df[next_value_cols].values, fill_value=0
                            )
                        if footnote_subs_files:
                            final_df["ì†ŒìŠ¤íŒŒì¼"] = "combined"
                        if "ê³„ì •ì½”ë“œ" in final_df.columns and not conso_wp_df.empty:
                            numeric_cols = final_df.select_dtypes(
                                include="number"
                            ).columns
                            if not numeric_cols.empty:
                                last_numeric_col = numeric_cols[-1]
                                if "ì—°ê²°ì¡°ì •" in conso_wp_df.columns:
                                    adj_map = conso_wp_df.set_index("ê³„ì •ì½”ë“œ")[
                                        "ì—°ê²°ì¡°ì •"
                                    ].to_dict()
                                    final_df["ê³„ì •ì½”ë“œ_str"] = (
                                        final_df["ê³„ì •ì½”ë“œ"].astype(str).str.strip()
                                    )
                                    adj_values = (
                                        final_df["ê³„ì •ì½”ë“œ_str"].map(adj_map).fillna(0)
                                    )
                                    final_df[last_numeric_col] += adj_values
                                    final_df = final_df.drop(columns=["ê³„ì •ì½”ë“œ_str"])
                        if "ê³„ì •ì½”ë“œ" in final_df.columns and conso_map:
                            last_numeric_col = final_df.select_dtypes(
                                include="number"
                            ).columns[-1]

                            def check_value_match(row):
                                code = str(row["ê³„ì •ì½”ë“œ"]).strip()
                                if not code:
                                    return ""
                                footnote_value = row[last_numeric_col]
                                conso_value = conso_map.get(code)
                                if conso_value is None:
                                    return "ë¶ˆì¼ì¹˜ (ì •ì‚°í‘œì— ì½”ë“œ ì—†ìŒ)"
                                if abs(footnote_value - conso_value) < 1:
                                    return "ì¼ì¹˜"
                                else:
                                    return f"ë¶ˆì¼ì¹˜ (ì°¨ì´: {footnote_value - conso_value:,.0f})"

                            final_df["ëŒ€ì‚¬ê²°ê³¼"] = final_df.apply(
                                check_value_match, axis=1
                            )
                    st.session_state.results["combined_footnotes"][
                        sheet_name
                    ] = final_df
                st.success("ğŸ‰ ì£¼ì„ ì·¨í•© ë° ëŒ€ì‚¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            except Exception as e:
                st.error(f"ì£¼ì„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

    if st.session_state.results.get("combined_footnotes"):
        st.subheader("ğŸ“’ ì·¨í•©ëœ ì£¼ì„ ë°ì´í„°")
        for sheet_name, df in st.session_state.results["combined_footnotes"].items():
            with st.expander(f"ì‹œíŠ¸: {sheet_name}", expanded=False):
                st.dataframe(df)
        footnote_excel_data = to_excel(st.session_state.results["combined_footnotes"])
        st.download_button(
            label="ğŸ“¥ ì·¨í•©ëœ ì£¼ì„ ë‹¤ìš´ë¡œë“œ (Excel)",
            data=footnote_excel_data,
            file_name="combined_footnotes.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        )

with tab3:
    st.header("3. ì—°ê²° ì¡°ì • ë¶„ê°œ ìƒì„±")
    st.write(
        "ê¸°ë³¸ ì¡°ì •ëª…ì„¸ ì…ë ¥ í›„, ë²•ì¸ì„¸/ë¹„ì§€ë°°ì§€ë¶„(NCI) ì¡°ì •ëª…ì„¸ë¥¼ ìë™ ìƒì„±í•˜ê³ , ìµœì¢… ê²€í†  í›„ ì „ì²´ ì¡°ì •ë¶„ê°œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
    )

    # --- Session State for Tab 3 ---
    if "adj_workflow" not in st.session_state:
        st.session_state.adj_workflow = {
            "initial_file": None,
            "intermediate_data": None,
            "final_file": None,
        }

    @st.cache_data
    def create_adjustment_template():
        adjustment_types = [
            "CAJE00_íˆ¬ììë³¸ìƒê³„",
            "CAJE01_ì±„ê¶Œì±„ë¬´ì œê±°",
            "CAJE02_ì œí’ˆë¯¸ì‹¤í˜„ì´ìµì œê±°",
            "CAJE03_ìƒê°ìì‚°ë¯¸ì‹¤í˜„ì´ìµì œê±°",
            "CAJE04_ë°°ë‹¹ì¡°ì •",
            "CAJE05_ê¸°íƒ€ì†ìµì¡°ì •",
            "CAJE96_ì·¨ë“ì¼ì°¨ì´ì¡°ì •",
            "CAJE97_ë²•ì¸ì„¸ì¡°ì •",
            "CAJE98_ë¹„ì§€ë°°ì§€ë¶„ì¡°ì •",
            "CAJE99_ê¸°íƒ€ì¡°ì •",
        ]
        columns = ["íšŒì‚¬ëª…", "ê³„ì •ì½”ë“œ", "ê³„ì •ëª…", "ë‹¹ê¸°ì „ê¸°", "ê¸ˆì•¡", "ì„¤ëª…"]
        output = io.BytesIO()

        with pd.ExcelWriter(output, engine="openpyxl") as writer:
            # 'Info' ì‹œíŠ¸ ìƒì„±
            info_data = {
                "ë‹¹ê¸°ì„¸ìœ¨": [0.2, 0.18, 0.16],
                "ë‹¹ê¸°ì§€ë¶„ìœ¨": [1, 0.60, 0.80],
            }
            info_index_labels = ["ëª¨íšŒì‚¬", "ìíšŒì‚¬A", "ìíšŒì‚¬B"]
            info_df = pd.DataFrame(info_data, index=info_index_labels)
            info_df.index.name = "íšŒì‚¬ëª…"
            info_df.to_excel(writer, sheet_name="Info")

            # 'Info' ì‹œíŠ¸ ìŠ¤íƒ€ì¼ ì ìš©
            ws_info = writer.sheets["Info"]
            header_font = Font(bold=True, color="FFFFFF")
            header_fill = PatternFill(
                start_color="4F81BD", end_color="4F81BD", fill_type="solid"
            )
            header_alignment = Alignment(
                horizontal="center", vertical="center", wrap_text=True
            )
            for cell in ws_info[1]:
                cell.font = header_font
                cell.fill = header_fill
                cell.alignment = header_alignment
            ws_info.column_dimensions[get_column_letter(1)].width = 20
            for i, col_name in enumerate(info_df.columns, 2):
                ws_info.column_dimensions[get_column_letter(i)].width = 20

            for sheet_name in adjustment_types:
                if sheet_name == "CAJE00_íˆ¬ììë³¸ìƒê³„":
                    example_data = [
                        {
                            "íšŒì‚¬ëª…": "ëª¨íšŒì‚¬",
                            "ê³„ì •ì½”ë“œ": "19200",
                            "ê³„ì •ëª…": "ì¢…ì†ê¸°ì—…íˆ¬ì",
                            "ë‹¹ê¸°ì „ê¸°": "ì·¨ë“ì¼",
                            "ê¸ˆì•¡": 3400000,
                            "ì„¤ëª…": "ìíšŒì‚¬A íˆ¬ìê¸ˆì•¡ ì œê±°",
                        },
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "33100",
                            "ê³„ì •ëª…": "ìë³¸ê¸ˆ",
                            "ë‹¹ê¸°ì „ê¸°": "ì·¨ë“ì¼",
                            "ê¸ˆì•¡": 3000000,
                            "ì„¤ëª…": "ìíšŒì‚¬A ìë³¸ê¸ˆ ì œê±°",
                        },
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "37500",
                            "ê³„ì •ëª…": "ì´ìµì‰ì—¬ê¸ˆ",
                            "ë‹¹ê¸°ì „ê¸°": "ì·¨ë“ì¼",
                            "ê¸ˆì•¡": 1000000,
                            "ì„¤ëª…": "ìíšŒì‚¬A ì´ìµì‰ì—¬ê¸ˆ(ì·¨ë“ì‹œì ) ì œê±°",
                        },
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "20600",
                            "ê³„ì •ëª…": "ê¸°ê³„ì¥ì¹˜",
                            "ë‹¹ê¸°ì „ê¸°": "ì·¨ë“ì¼",
                            "ê¸ˆì•¡": -800000,
                            "ì„¤ëª…": "ìíšŒì‚¬A ê³µì •ê°€ì¹˜ì°¨ì´ ê³„ìƒ",
                        },
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "101000",
                            "ê³„ì •ëª…": "ì˜ì—…ê¶Œ",
                            "ë‹¹ê¸°ì „ê¸°": "ì·¨ë“ì¼",
                            "ê¸ˆì•¡": -200000,
                            "ì„¤ëª…": "ìíšŒì‚¬A ì˜ì—…ê¶Œ ê³„ìƒ",
                        },
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "201100",
                            "ê³„ì •ëª…": "ë¹„ì§€ë°°ì§€ë¶„",
                            "ë‹¹ê¸°ì „ê¸°": "ì·¨ë“ì¼",
                            "ê¸ˆì•¡": -1600000,
                            "ì„¤ëª…": "ìíšŒì‚¬A ë¹„ì§€ë°°ì§€ë¶„ ê³„ìƒ",
                        },
                    ]
                    df = pd.DataFrame(example_data)
                elif sheet_name == "CAJE01_ì±„ê¶Œì±„ë¬´ì œê±°":
                    example_data = [
                        {
                            "íšŒì‚¬ëª…": "ëª¨íšŒì‚¬",
                            "ê³„ì •ì½”ë“œ": "10800",
                            "ê³„ì •ëª…": "ë§¤ì¶œì±„ê¶Œ",
                            "ë‹¹ê¸°ì „ê¸°": "ì „ê¸°",
                            "ê¸ˆì•¡": 20000000,
                            "ì„¤ëª…": "ìíšŒì‚¬Aì— ëŒ€í•œ ë§¤ì¶œì±„ê¶Œ ì œê±°",
                        },
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "25100",
                            "ê³„ì •ëª…": "ë§¤ì…ì±„ë¬´",
                            "ë‹¹ê¸°ì „ê¸°": "ì „ê¸°",
                            "ê¸ˆì•¡": 20000000,
                            "ì„¤ëª…": "ëª¨íšŒì‚¬ì— ëŒ€í•œ ë§¤ì…ì±„ë¬´ ì œê±°",
                        },
                        {
                            "íšŒì‚¬ëª…": "ëª¨íšŒì‚¬",
                            "ê³„ì •ì½”ë“œ": "10800",
                            "ê³„ì •ëª…": "ë§¤ì¶œì±„ê¶Œ",
                            "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°",
                            "ê¸ˆì•¡": 10000000,
                            "ì„¤ëª…": "ìíšŒì‚¬Aì— ëŒ€í•œ ë§¤ì¶œì±„ê¶Œ ì œê±°",
                        },
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "25100",
                            "ê³„ì •ëª…": "ë§¤ì…ì±„ë¬´",
                            "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°",
                            "ê¸ˆì•¡": 10000000,
                            "ì„¤ëª…": "ëª¨íšŒì‚¬ì— ëŒ€í•œ ë§¤ì…ì±„ë¬´ ì œê±°",
                        },
                    ]
                    df = pd.DataFrame(example_data)
                elif sheet_name == "CAJE02_ì œí’ˆë¯¸ì‹¤í˜„ì´ìµì œê±°":
                    example_data = [
                        {
                            "íšŒì‚¬ëª…": "ëª¨íšŒì‚¬",
                            "ê³„ì •ì½”ë“œ": "45500",
                            "ê³„ì •ëª…": "ë§¤ì¶œì›ê°€",
                            "ë‹¹ê¸°ì „ê¸°": "ì „ê¸°",
                            "ê¸ˆì•¡": 3000000,
                            "ì„¤ëª…": "ì „ê¸° ë¯¸ì‹¤í˜„ì´ìµ",
                        },
                        {
                            "íšŒì‚¬ëª…": "ëª¨íšŒì‚¬",
                            "ê³„ì •ì½”ë“œ": "37500",
                            "ê³„ì •ëª…": "ì´ìµì‰ì—¬ê¸ˆ",
                            "ë‹¹ê¸°ì „ê¸°": "ì „ê¸°",
                            "ê¸ˆì•¡": 3000000,
                            "ì„¤ëª…": "ì „ê¸° ë¯¸ì‹¤í˜„ì´ìµ(ì´ìµì‰ì—¬ê¸ˆ)",
                        },
                        {
                            "íšŒì‚¬ëª…": "ëª¨íšŒì‚¬",
                            "ê³„ì •ì½”ë“œ": "40200",
                            "ê³„ì •ëª…": "ë§¤ì¶œ",
                            "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°",
                            "ê¸ˆì•¡": 10000000,
                            "ì„¤ëª…": "ë‹¹ê¸° íŒë§¤ë¶„ ë§¤ì¶œ",
                        },
                        {
                            "íšŒì‚¬ëª…": "ëª¨íšŒì‚¬",
                            "ê³„ì •ì½”ë“œ": "45500",
                            "ê³„ì •ëª…": "ë§¤ì¶œì›ê°€",
                            "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°",
                            "ê¸ˆì•¡": 6000000,
                            "ì„¤ëª…": "ë‹¹ê¸° íŒë§¤ë¶„ ë§¤ì¶œì›ê°€",
                        },
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "15200",
                            "ê³„ì •ëª…": "ì œí’ˆ(ì¬ê³ ìì‚°)",
                            "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°",
                            "ê¸ˆì•¡": 4000000,
                            "ì„¤ëª…": "ëª¨íšŒì‚¬ê°€ íŒë§¤í•œ ì¬ê³  ë¯¸ì‹¤í˜„ì´ìµ ì œê±°(ì¬ê³ ê°ì†Œ)",
                        },
                    ]
                    df = pd.DataFrame(example_data)
                elif sheet_name == "CAJE03_ìƒê°ìì‚°ë¯¸ì‹¤í˜„ì´ìµì œê±°":
                    example_data = [
                        {
                            "íšŒì‚¬ëª…": "ëª¨íšŒì‚¬",
                            "ê³„ì •ì½”ë“œ": "20600",
                            "ê³„ì •ëª…": "ê¸°ê³„ì¥ì¹˜",
                            "ë‹¹ê¸°ì „ê¸°": "ì „ê¸°",
                            "ê¸ˆì•¡": 5000000,
                            "ì„¤ëª…": "ìíšŒì‚¬Aì—ì„œ ëª¨íšŒì‚¬ì— ì²˜ë¶„ ëª¨íšŒì‚¬ ë³´ìœ ",
                        },
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "37500",
                            "ê³„ì •ëª…": "ì´ìµì‰ì—¬ê¸ˆ",
                            "ë‹¹ê¸°ì „ê¸°": "ì „ê¸°",
                            "ê¸ˆì•¡": 5000000,
                            "ì„¤ëª…": "ìíšŒì‚¬A ê³„ìƒ ìœ í˜•ìì‚°ì²˜ë¶„ì´ìµ",
                        },
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "37500",
                            "ê³„ì •ëª…": "ì´ìµì‰ì—¬ê¸ˆ",
                            "ë‹¹ê¸°ì „ê¸°": "ì „ê¸°",
                            "ê¸ˆì•¡": -1000000,
                            "ì„¤ëª…": "ê°ê°€ìƒê°ë¹„ ì¦ë¶„ ì œê±° - ìœ í˜•ìì‚°ì²˜ë¶„ì´ìµ íš¨ê³¼ ê°ì†Œ",
                        },
                        {
                            "íšŒì‚¬ëª…": "ëª¨íšŒì‚¬",
                            "ê³„ì •ì½”ë“œ": "20700",
                            "ê³„ì •ëª…": "ê¸°ê³„ì¥ì¹˜ê°ê°€ìƒê°ëˆ„ê³„ì•¡",
                            "ë‹¹ê¸°ì „ê¸°": "ì „ê¸°",
                            "ê¸ˆì•¡": -1000000,
                            "ì„¤ëª…": "ê°ê°€ìƒê°ëˆ„ê³„ì•¡ ì¦ê°€",
                        },
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "81800",
                            "ê³„ì •ëª…": "ê°ê°€ìƒê°ë¹„",
                            "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°",
                            "ê¸ˆì•¡": 1000000,
                            "ì„¤ëª…": "ê°ê°€ìƒê°ë¹„ ì¦ë¶„ ì œê±° - ìœ í˜•ìì‚°ì²˜ë¶„ì´ìµ íš¨ê³¼ ê°ì†Œ",
                        },
                        {
                            "íšŒì‚¬ëª…": "ëª¨íšŒì‚¬",
                            "ê³„ì •ì½”ë“œ": "20700",
                            "ê³„ì •ëª…": "ê¸°ê³„ì¥ì¹˜ê°ê°€ìƒê°ëˆ„ê³„ì•¡",
                            "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°",
                            "ê¸ˆì•¡": -1000000,
                            "ì„¤ëª…": "ê°ê°€ìƒê°ëˆ„ê³„ì•¡ ì¦ê°€",
                        },
                    ]
                    df = pd.DataFrame(example_data)
                elif sheet_name == "CAJE04_ë°°ë‹¹ì¡°ì •":
                    example_data = [
                        {"íšŒì‚¬ëª…": "ëª¨íšŒì‚¬", "ê³„ì •ì½”ë“œ": "90300", "ê³„ì •ëª…": "ë°°ë‹¹ê¸ˆìˆ˜ìµ", "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°", "ê¸ˆì•¡": 1200000, "ì„¤ëª…": "ìíšŒì‚¬Aë¡œë¶€í„° ë°›ì€ ë°°ë‹¹ê¸ˆìˆ˜ìµ ì œê±°"},
                        {"íšŒì‚¬ëª…": "ìíšŒì‚¬A", "ê³„ì •ì½”ë“œ": "201100", "ê³„ì •ëª…": "ë¹„ì§€ë°°ì§€ë¶„", "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°", "ê¸ˆì•¡": 800000, "ì„¤ëª…": "ë°°ë‹¹ê¸ˆ ë¹„ì§€ë°°ì§€ë¶„ ì¡°ì •"},
                        {"íšŒì‚¬ëª…": "ìíšŒì‚¬A", "ê³„ì •ì½”ë“œ": "37500", "ê³„ì •ëª…": "ì´ìµì‰ì—¬ê¸ˆ", "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°", "ê¸ˆì•¡": -2000000, "ì„¤ëª…": "ëª¨íšŒì‚¬ì— ì§€ê¸‰í•œ ë°°ë‹¹ê¸ˆ íš¨ê³¼ ì œê±°"},
                    ]
                    df = pd.DataFrame(example_data)
                elif sheet_name == "CAJE96_ì·¨ë“ì¼ì°¨ì´ì¡°ì •":
                    example_data = [
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "37500",
                            "ê³„ì •ëª…": "ì´ìµì‰ì—¬ê¸ˆ",
                            "ë‹¹ê¸°ì „ê¸°": "ì „ê¸°",
                            "ê¸ˆì•¡": 160000,
                            "ì„¤ëª…": "ìíšŒì‚¬A ê³µì •ê°€ì¹˜ì°¨ì´ ìƒê°",
                        },
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "20700",
                            "ê³„ì •ëª…": "ê¸°ê³„ì¥ì¹˜ê°ê°€ìƒê°ëˆ„ê³„ì•¡",
                            "ë‹¹ê¸°ì „ê¸°": "ì „ê¸°",
                            "ê¸ˆì•¡": 160000,
                            "ì„¤ëª…": "ìíšŒì‚¬A ê³µì •ê°€ì¹˜ì°¨ì´ ìƒê°ëˆ„ê³„ì•¡",
                        },
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "81800",
                            "ê³„ì •ëª…": "ê°ê°€ìƒê°ë¹„",
                            "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°",
                            "ê¸ˆì•¡": -160000,
                            "ì„¤ëª…": "ìíšŒì‚¬A ê³µì •ê°€ì¹˜ì°¨ì´ ìƒê°",
                        },
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "20700",
                            "ê³„ì •ëª…": "ê¸°ê³„ì¥ì¹˜ê°ê°€ìƒê°ëˆ„ê³„ì•¡",
                            "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°",
                            "ê¸ˆì•¡": 160000,
                            "ì„¤ëª…": "ìíšŒì‚¬A ê³µì •ê°€ì¹˜ì°¨ì´ ìƒê°ëˆ„ê³„ì•¡",
                        },
                    ]
                    df = pd.DataFrame(example_data)
                elif sheet_name == "CAJE96_ì·¨ë“ì¼ì°¨ì´ì¡°ì •":
                    example_data = [
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "37500",
                            "ê³„ì •ëª…": "ì´ìµì‰ì—¬ê¸ˆ",
                            "ë‹¹ê¸°ì „ê¸°": "ì „ê¸°",
                            "ê¸ˆì•¡": 160000,
                            "ì„¤ëª…": "ìíšŒì‚¬A ê³µì •ê°€ì¹˜ì°¨ì´ ìƒê°",
                        },
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "20700",
                            "ê³„ì •ëª…": "ê¸°ê³„ì¥ì¹˜ê°ê°€ìƒê°ëˆ„ê³„ì•¡",
                            "ë‹¹ê¸°ì „ê¸°": "ì „ê¸°",
                            "ê¸ˆì•¡": 160000,
                            "ì„¤ëª…": "ìíšŒì‚¬A ê³µì •ê°€ì¹˜ì°¨ì´ ìƒê°ëˆ„ê³„ì•¡",
                        },
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "81800",
                            "ê³„ì •ëª…": "ê°ê°€ìƒê°ë¹„",
                            "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°",
                            "ê¸ˆì•¡": -160000,
                            "ì„¤ëª…": "ìíšŒì‚¬A ê³µì •ê°€ì¹˜ì°¨ì´ ìƒê°",
                        },
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "20700",
                            "ê³„ì •ëª…": "ê¸°ê³„ì¥ì¹˜ê°ê°€ìƒê°ëˆ„ê³„ì•¡",
                            "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°",
                            "ê¸ˆì•¡": 160000,
                            "ì„¤ëª…": "ìíšŒì‚¬A ê³µì •ê°€ì¹˜ì°¨ì´ ìƒê°ëˆ„ê³„ì•¡",
                        },
                    ]
                    df = pd.DataFrame(example_data)
                elif sheet_name == "CAJE97_ë²•ì¸ì„¸ì¡°ì •":
                    example_data = [
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "37500",
                            "ê³„ì •ëª…": "ì´ì›”ì´ìµì‰ì—¬ê¸ˆ",
                            "ë‹¹ê¸°ì „ê¸°": "ì·¨ë“ì¼",
                            "ê¸ˆì•¡": 144000,
                            "ì„¤ëª…": "ì·¨ë“ì¼ ê³µì •ê°€ì¹˜ì°¨ì´ ë²•ì¸ì„¸ íš¨ê³¼",
                        },
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "31000",
                            "ê³„ì •ëª…": "ì´ì—°ë²•ì¸ì„¸ë¶€ì±„",
                            "ë‹¹ê¸°ì „ê¸°": "ì·¨ë“ì¼",
                            "ê¸ˆì•¡": -144000,
                            "ì„¤ëª…": "ì·¨ë“ì¼ ê³µì •ê°€ì¹˜ì°¨ì´ ë²•ì¸ì„¸ íš¨ê³¼",
                        },
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "37500",
                            "ê³„ì •ëª…": "ì´ì›”ì´ìµì‰ì—¬ê¸ˆ",
                            "ë‹¹ê¸°ì „ê¸°": "ì „ê¸°",
                            "ê¸ˆì•¡": -28800,
                            "ì„¤ëª…": "ì·¨ë“ì¼ ê³µì •ê°€ì¹˜ì°¨ì´ ìƒê° ë²•ì¸ì„¸ íš¨ê³¼",
                        },
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "31000",
                            "ê³„ì •ëª…": "ì´ì—°ë²•ì¸ì„¸ë¶€ì±„",
                            "ë‹¹ê¸°ì „ê¸°": "ì „ê¸°",
                            "ê¸ˆì•¡": 28800,
                            "ì„¤ëª…": "ì·¨ë“ì¼ ê³µì •ê°€ì¹˜ì°¨ì´ ìƒê° ë²•ì¸ì„¸ íš¨ê³¼",
                        },
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "99800",
                            "ê³„ì •ëª…": "ë²•ì¸ì„¸ë¹„ìš©",
                            "ë‹¹ê¸°ì „ê¸°": "ì „ê¸°",
                            "ê¸ˆì•¡": -600000,
                            "ì„¤ëª…": "ì¬ê³  ë¯¸ì‹¤í˜„ì´ìµ ì‹¤í˜„ ë²•ì¸ì„¸ íš¨ê³¼",
                        },
                        {
                            "íšŒì‚¬ëª…": "ëª¨íšŒì‚¬",
                            "ê³„ì •ì½”ë“œ": "37500",
                            "ê³„ì •ëª…": "ì´ì›”ì´ìµì‰ì—¬ê¸ˆ",
                            "ë‹¹ê¸°ì „ê¸°": "ì „ê¸°",
                            "ê¸ˆì•¡": -600000,
                            "ì„¤ëª…": "ì¬ê³  ë¯¸ì‹¤í˜„ì´ìµ ì‹¤í˜„ ë²•ì¸ì„¸ íš¨ê³¼",
                        },
                        {
                            "íšŒì‚¬ëª…": "ëª¨íšŒì‚¬",
                            "ê³„ì •ì½”ë“œ": "37500",
                            "ê³„ì •ëª…": "ì´ìµì‰ì—¬ê¸ˆ",
                            "ë‹¹ê¸°ì „ê¸°": "ì „ê¸°",
                            "ê¸ˆì•¡": -800000,
                            "ì„¤ëª…": "ìœ í˜•ìì‚°ì²˜ë¶„ì´ìµ íš¨ê³¼ ê°ì†Œ ê´€ë ¨ ë²•ì¸ì„¸íš¨ê³¼",
                        },
                        {
                            "íšŒì‚¬ëª…": "ëª¨íšŒì‚¬",
                            "ê³„ì •ì½”ë“œ": "31000",
                            "ê³„ì •ëª…": "ì´ì—°ë²•ì¸ì„¸ë¶€ì±„",
                            "ë‹¹ê¸°ì „ê¸°": "ì „ê¸°",
                            "ê¸ˆì•¡": 800000,
                            "ì„¤ëª…": "ìœ í˜•ìì‚°ì²˜ë¶„ì´ìµ íš¨ê³¼ ê°ì†Œ ê´€ë ¨ ë²•ì¸ì„¸íš¨ê³¼",
                        },
                    ]
                    df = pd.DataFrame(example_data)
                elif sheet_name == "CAJE98_ë¹„ì§€ë°°ì§€ë¶„ì¡°ì •":
                    example_data = [
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "37500",
                            "ê³„ì •ëª…": "ì´ì›”ì´ìµì‰ì—¬ê¸ˆ",
                            "ë‹¹ê¸°ì „ê¸°": "ì „ê¸°",
                            "ê¸ˆì•¡": 500000,
                            "ì„¤ëª…": "ì „ê¸° ëˆ„ì  ìë³¸ë³€ë™ ë¹„ì§€ë°°ì§€ë¶„",
                        },
                        {
                            "íšŒì‚¬ëª…": "ìíšŒì‚¬A",
                            "ê³„ì •ì½”ë“œ": "201100",
                            "ê³„ì •ëª…": "ë¹„ì§€ë°°ì§€ë¶„",
                            "ë‹¹ê¸°ì „ê¸°": "ì „ê¸°",
                            "ê¸ˆì•¡": -500000,
                            "ì„¤ëª…": "ì „ê¸° ëˆ„ì  ìë³¸ë³€ë™ ë¹„ì§€ë°°ì§€ë¶„",
                        },
                    ]
                    df = pd.DataFrame(example_data)
                else:
                    df = pd.DataFrame(columns=columns)
                df = df.reindex(columns=columns)
                df.to_excel(writer, sheet_name=sheet_name, index=False)
                ws = writer.sheets[sheet_name]
                header_font = Font(bold=True, color="FFFFFF")
                header_fill = PatternFill(
                    start_color="4F81BD", end_color="4F81BD", fill_type="solid"
                )
                header_alignment = Alignment(
                    horizontal="center", vertical="center", wrap_text=True
                )
                for cell in ws[1]:
                    cell.font = header_font
                    cell.fill = header_fill
                    cell.alignment = header_alignment
                for i, column_name in enumerate(df.columns, 1):
                    ws.column_dimensions[get_column_letter(i)].width = 20

            # --- ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬ ì¶”ê°€ ---
            num_companies = len(info_index_labels)
            validation_formula = f"='Info'!$A$2:$A${num_companies + 1}"
            dv = DataValidation(
                type="list", formula1=validation_formula, allow_blank=True
            )
            dv.error = "ëª©ë¡ì— ìˆëŠ” ê°’ë§Œ ì…ë ¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            dv.errorTitle = "ì˜ëª»ëœ ì…ë ¥"
            dv.prompt = "ëª©ë¡ì—ì„œ íšŒì‚¬ëª…ì„ ì„ íƒí•˜ì„¸ìš”."
            dv.promptTitle = "íšŒì‚¬ëª… ì„ íƒ"

            target_range = "A2:A100001"
            for sheet_name in adjustment_types:
                if sheet_name != "Info":
                    ws = writer.sheets[sheet_name]
                    ws.add_data_validation(dv)
                    dv.add(target_range)
        return output.getvalue()

    def generate_intermediate_adjustments(adj_file, coa_df, subs_files, subs_names, aje_code):
        adj_file.seek(0)
        xls = pd.ExcelFile(adj_file)
        original_sheets = {
            sheet_name: pd.read_excel(xls, sheet_name, dtype={"ê³„ì •ì½”ë“œ": str}) for sheet_name in xls.sheet_names
        }

        if "Info" not in original_sheets:
            st.error("'Info' ì‹œíŠ¸ê°€ ì¡°ì •ë¶„ê°œ íŒŒì¼ì— ì—†ìŠµë‹ˆë‹¤.")
            return None

        info_df = original_sheets["Info"].set_index(original_sheets["Info"].columns[0])

        info_df["ë‹¹ê¸°ì„¸ìœ¨_num"] = info_df["ë‹¹ê¸°ì„¸ìœ¨"].apply(parse_percent)
        info_df["ë‹¹ê¸°ì§€ë¶„ìœ¨_num"] = info_df["ë‹¹ê¸°ì§€ë¶„ìœ¨"].apply(parse_percent)
        tax_rates = info_df["ë‹¹ê¸°ì„¸ìœ¨_num"].to_dict()
        nci_rates = (1 - info_df["ë‹¹ê¸°ì§€ë¶„ìœ¨_num"]).to_dict()

        # Create maps for faster lookups
        fs_map = dict(zip(coa_df["ê³„ì •ì½”ë“œ"].astype(str), coa_df["FS_Element"]))
        name_map = dict(zip(coa_df["ê³„ì •ì½”ë“œ"].astype(str), coa_df["ê³„ì •ëª…"]))
        tax_adj_entries, nci_adj_entries = [], []

        # Get special account codes from aje_code DataFrame and CoA
        nci_pl_row = coa_df[coa_df["FS_Element"] == "CR"]
        if not nci_pl_row.empty:
            NCI_PL_CODE = nci_pl_row.iloc[0]["ê³„ì •ì½”ë“œ"]
            NCI_PL_NAME = nci_pl_row.iloc[0]["ê³„ì •ëª…"]
        else:
            NCI_PL_CODE = "302000"  # Fallback
            NCI_PL_NAME = "ë¹„ì§€ë°°ì§€ë¶„ìˆœì†ìµ"
            st.warning("CoA íŒŒì¼ì—ì„œ 'CR' FS_Elementë¥¼ ê°€ì§„ ë¹„ì§€ë°°ì§€ë¶„ìˆœì†ìµ ê³„ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’('302000')ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")

        nci_equity_row = coa_df[coa_df["FS_Element"] == "CE"]
        if not nci_equity_row.empty:
            NCI_EQUITY_CODE = nci_equity_row.iloc[0]["ê³„ì •ì½”ë“œ"]
            NCI_EQUITY_NAME = nci_equity_row.iloc[0]["ê³„ì •ëª…"]
        else:
            NCI_EQUITY_CODE = "201100"  # Fallback
            NCI_EQUITY_NAME = "ë¹„ì§€ë°°ì§€ë¶„"
            st.warning("CoA íŒŒì¼ì—ì„œ 'CE' FS_Elementë¥¼ ê°€ì§„ ë¹„ì§€ë°°ì§€ë¶„ ê³„ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’('201100')ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")

        IT_EXPENSE_CODE = aje_code.loc[aje_code["FS_Element"] == "X", "ê³„ì •ì½”ë“œ"].iloc[0]
        IT_EXPENSE_NAME = aje_code.loc[aje_code["FS_Element"] == "X", "ê³„ì •ëª…"].iloc[0]
        DTA_CODE = aje_code.loc[aje_code["FS_Element"] == "L", "ê³„ì •ì½”ë“œ"].iloc[0]
        DTA_NAME = aje_code.loc[aje_code["FS_Element"] == "L", "ê³„ì •ëª…"].iloc[0]
        RE_CODE = aje_code.loc[aje_code["FS_Element"] == "E", "ê³„ì •ì½”ë“œ"].iloc[0]
        RE_NAME = aje_code.loc[aje_code["FS_Element"] == "E", "ê³„ì •ëª…"].iloc[0]

        # --- 1. Tax and NCI on P/L adjustments from CAJE sheets ---
        for sheet_name, df_orig in original_sheets.items():
            sheet_name_upper = sheet_name.upper()
            if not sheet_name_upper.startswith("CAJE"):
                continue
            
            if "ê¸ˆì•¡" in df_orig.columns:
                df_orig["ê¸ˆì•¡"] = pd.to_numeric(df_orig["ê¸ˆì•¡"], errors="coerce").fillna(0)

            caje_type = sheet_name_upper.split("_")[0]
            if caje_type in ["CAJE97", "CAJE98"]:
                continue

            df = df_orig[df_orig["ë‹¹ê¸°ì „ê¸°"] == "ë‹¹ê¸°"].copy()
            if df.empty:
                continue

            df["ê¸ˆì•¡"] = pd.to_numeric(df.get("ê¸ˆì•¡"), errors="coerce")
            df = df.dropna(subset=["ê¸ˆì•¡", "ê³„ì •ì½”ë“œ", "íšŒì‚¬ëª…"])
            if df.empty:
                continue
            df["ê³„ì •ì½”ë“œ"] = df["ê³„ì •ì½”ë“œ"].astype(str).str.strip()
            df["FS_Element"] = df["ê³„ì •ì½”ë“œ"].map(fs_map)

            if caje_type == "CAJE02":
                pl_rows = df[df["FS_Element"].isin(["R", "X"])]

                df_orig_with_fs = df_orig.copy()
                df_orig_with_fs["ê³„ì •ì½”ë“œ"] = (
                    df_orig_with_fs["ê³„ì •ì½”ë“œ"].astype(str).str.strip()
                )
                df_orig_with_fs["FS_Element"] = df_orig_with_fs["ê³„ì •ì½”ë“œ"].map(fs_map)
                asset_rows = df_orig_with_fs[df_orig_with_fs["FS_Element"] == "A"]

                if asset_rows.empty or pl_rows.empty:
                    continue

                asset_corp = asset_rows.iloc[0]["íšŒì‚¬ëª…"]
                tax_rate = tax_rates.get(asset_corp, 0.0)

                # Tax effect
                unrealized_profit_amount = asset_rows["ê¸ˆì•¡"].sum()
                tax_effect = unrealized_profit_amount * tax_rate
                if abs(tax_effect) > 1:
                    desc = f"[{sheet_name}] ë¯¸ì‹¤í˜„ì´ìµ ë²•ì¸ì„¸íš¨ê³¼"
                    tax_adj_entries.append(
                        {
                            "íšŒì‚¬ëª…": asset_corp,
                            "ê³„ì •ì½”ë“œ": IT_EXPENSE_CODE,
                            "ê³„ì •ëª…": IT_EXPENSE_NAME,
                            "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°",
                            "ê¸ˆì•¡": tax_effect,
                            "ì„¤ëª…": desc,
                        }
                    )
                    tax_adj_entries.append(
                        {
                            "íšŒì‚¬ëª…": asset_corp,
                            "ê³„ì •ì½”ë“œ": DTA_CODE,
                            "ê³„ì •ëª…": DTA_NAME,
                            "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°",
                            "ê¸ˆì•¡": tax_effect,
                            "ì„¤ëª…": desc,
                        }
                    )

                # NCI effect
                for _, pl_row in pl_rows.iterrows():
                    pl_corp = pl_row["íšŒì‚¬ëª…"]
                    nci_rate = nci_rates.get(pl_corp, 0.0)
                    if nci_rate > 0:
                        amount = pl_row["ê¸ˆì•¡"]
                        nci_effect = -amount * (1 - tax_rate) * nci_rate
                        if abs(nci_effect) > 1:
                            desc = f"[{sheet_name}] {pl_row.get('ì„¤ëª…', '')} ê´€ë ¨"
                            nci_adj_entries.append(
                                {
                                    "íšŒì‚¬ëª…": asset_corp,
                                    "ê³„ì •ì½”ë“œ": RE_CODE,
                                    "ê³„ì •ëª…": RE_NAME,
                                    "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°",
                                    "ê¸ˆì•¡": -nci_effect,
                                    "ì„¤ëª…": f"{desc} ë¹„ì§€ë°°ì§€ë¶„íš¨ê³¼",
                                }
                            )
                            nci_adj_entries.append(
                                {
                                    "íšŒì‚¬ëª…": asset_corp,
                                    "ê³„ì •ì½”ë“œ": NCI_PL_CODE,
                                    "ê³„ì •ëª…": NCI_PL_NAME,
                                    "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°",
                                    "ê¸ˆì•¡": nci_effect,
                                    "ì„¤ëª…": f"{desc} ë¹„ì§€ë°°ì§€ë¶„íš¨ê³¼",
                                }
                            )

            elif caje_type == "CAJE03":
                pl_rows = df[df["FS_Element"].isin(["R", "X"])]

                df_orig_with_fs = df_orig.copy()
                df_orig_with_fs["ê³„ì •ì½”ë“œ"] = (
                    df_orig_with_fs["ê³„ì •ì½”ë“œ"].astype(str).str.strip()
                )
                df_orig_with_fs["FS_Element"] = df_orig_with_fs["ê³„ì •ì½”ë“œ"].map(fs_map)
                asset_rows = df_orig_with_fs[df_orig_with_fs["FS_Element"] == "A"]

                if asset_rows.empty or pl_rows.empty:
                    continue

                asset_corp = asset_rows.iloc[0]["íšŒì‚¬ëª…"]

                for _, pl_row in pl_rows.iterrows():
                    pl_corp = pl_row["íšŒì‚¬ëª…"]
                    amount = pl_row["ê¸ˆì•¡"]
                    tax_rate = tax_rates.get(asset_corp, 0.0)
                    desc = f"[{sheet_name}] {pl_row.get('ì„¤ëª…', '')} ê´€ë ¨"

                    # Tax effect
                    if pl_row["FS_Element"] == "X": 
                        tax_effect = -amount * tax_rate
                    else:
                        tax_effect = amount * tax_rate
                    
                    if abs(tax_effect) > 1:
                        tax_adj_entries.append(
                            {
                                "íšŒì‚¬ëª…": asset_corp,
                                "ê³„ì •ì½”ë“œ": IT_EXPENSE_CODE,
                                "ê³„ì •ëª…": IT_EXPENSE_NAME,
                                "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°",
                                "ê¸ˆì•¡": tax_effect,
                                "ì„¤ëª…": f"{desc} ë²•ì¸ì„¸íš¨ê³¼",
                            }
                        )
                        tax_adj_entries.append(
                            {
                                "íšŒì‚¬ëª…": asset_corp,
                                "ê³„ì •ì½”ë“œ": DTA_CODE,
                                "ê³„ì •ëª…": DTA_NAME,
                                "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°",
                                "ê¸ˆì•¡": tax_effect,
                                "ì„¤ëª…": f"{desc} ë²•ì¸ì„¸íš¨ê³¼",
                            }
                        )
                        
                    nci_rate = nci_rates.get(pl_corp, 0.0)

                    # NCI effect
                    if nci_rate > 0:
                        nci_effect = -amount * (1 - tax_rate) * nci_rate
                        if abs(nci_effect) > 1:
                            nci_adj_entries.append(
                                {
                                    "íšŒì‚¬ëª…": asset_corp,
                                    "ê³„ì •ì½”ë“œ": RE_CODE,
                                    "ê³„ì •ëª…": RE_NAME,
                                    "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°",
                                    "ê¸ˆì•¡": -nci_effect,
                                    "ì„¤ëª…": f"{desc} ë¹„ì§€ë°°ì§€ë¶„íš¨ê³¼",
                                }
                            )
                            nci_adj_entries.append(
                                {
                                    "íšŒì‚¬ëª…": asset_corp,
                                    "ê³„ì •ì½”ë“œ": NCI_PL_CODE,
                                    "ê³„ì •ëª…": NCI_PL_NAME,
                                    "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°",
                                    "ê¸ˆì•¡": nci_effect,
                                    "ì„¤ëª…": f"{desc} ë¹„ì§€ë°°ì§€ë¶„íš¨ê³¼",
                                }
                            )

            elif caje_type == "CAJE96":
                pl_rows = df[df["FS_Element"].isin(["R", "X"])]
                for _, pl_row in pl_rows.iterrows():
                    corp = pl_row["íšŒì‚¬ëª…"]
                    amount = pl_row["ê¸ˆì•¡"]
                    tax_rate = tax_rates.get(corp, 0.0)
                    nci_rate = nci_rates.get(corp, 0.0)
                    desc = f"[{sheet_name}] {pl_row.get('ì„¤ëª…', '')} ê´€ë ¨"

                    # Tax effect
                    if pl_row["FS_Element"] == "X": 
                        tax_effect = -amount * tax_rate
                    else:
                        tax_effect = amount * tax_rate
                        
                    if abs(tax_effect) > 1:
                        tax_adj_entries.append(
                            {
                                "íšŒì‚¬ëª…": corp,
                                "ê³„ì •ì½”ë“œ": IT_EXPENSE_CODE,
                                "ê³„ì •ëª…": IT_EXPENSE_NAME,
                                "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°",
                                "ê¸ˆì•¡": tax_effect,
                                "ì„¤ëª…": f"{desc} ë²•ì¸ì„¸íš¨ê³¼",
                            }
                        )
                        tax_adj_entries.append(
                            {
                                "íšŒì‚¬ëª…": corp,
                                "ê³„ì •ì½”ë“œ": DTA_CODE,
                                "ê³„ì •ëª…": DTA_NAME,
                                "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°",
                                "ê¸ˆì•¡": tax_effect,
                                "ì„¤ëª…": f"{desc} ë²•ì¸ì„¸íš¨ê³¼",
                            }
                        )

                    # NCI effect
                    if nci_rate > 0:
                        nci_effect = -amount * (1 - tax_rate) * nci_rate
                        if abs(nci_effect) > 1:
                            nci_adj_entries.append(
                                {
                                    "íšŒì‚¬ëª…": corp,
                                    "ê³„ì •ì½”ë“œ": RE_CODE,
                                    "ê³„ì •ëª…": RE_NAME,
                                    "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°",
                                    "ê¸ˆì•¡": -nci_effect,
                                    "ì„¤ëª…": f"{desc} ë¹„ì§€ë°°ì§€ë¶„íš¨ê³¼",
                                }
                            )
                            nci_adj_entries.append(
                                {
                                    "íšŒì‚¬ëª…": corp,
                                    "ê³„ì •ì½”ë“œ": NCI_PL_CODE,
                                    "ê³„ì •ëª…": NCI_PL_NAME,
                                    "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°",
                                    "ê¸ˆì•¡": nci_effect,
                                    "ì„¤ëª…": f"{desc} ë¹„ì§€ë°°ì§€ë¶„íš¨ê³¼",
                                }
                            )

            elif caje_type == "CAJE05":
                pl_rows = df[df["FS_Element"].isin(["R", "X"])]
                for _, pl_row in pl_rows.iterrows():
                    corp = pl_row["íšŒì‚¬ëª…"]
                    amount = pl_row["ê¸ˆì•¡"]
                    tax_rate = tax_rates.get(corp, 0.0)
                    nci_rate = nci_rates.get(corp, 0.0)
                    desc = f"[{sheet_name}] {pl_row.get('ì„¤ëª…', '')} ê´€ë ¨"
                    
                    # Tax effect
                    if pl_row["FS_Element"] == "X": 
                        tax_effect = -amount * tax_rate
                    else:
                        tax_effect = amount * tax_rate
                    
                    if abs(tax_effect) > 1:
                        tax_adj_entries.append(
                            {
                                "íšŒì‚¬ëª…": corp,
                                "ê³„ì •ì½”ë“œ": IT_EXPENSE_CODE,
                                "ê³„ì •ëª…": IT_EXPENSE_NAME,
                                "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°",
                                "ê¸ˆì•¡": tax_effect,
                                "ì„¤ëª…": f"{desc} ë²•ì¸ì„¸íš¨ê³¼",
                            }
                        )
                        tax_adj_entries.append(
                            {
                                "íšŒì‚¬ëª…": corp,
                                "ê³„ì •ì½”ë“œ": DTA_CODE,
                                "ê³„ì •ëª…": DTA_NAME,
                                "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°",
                                "ê¸ˆì•¡": tax_effect,
                                "ì„¤ëª…": f"{desc} ë²•ì¸ì„¸íš¨ê³¼",
                            }
                        )
                        
                    # NCI effect
                    if nci_rate > 0:
                        nci_effect = -amount * (1 - tax_rate) * nci_rate
                        if abs(nci_effect) > 1:
                            nci_adj_entries.append(
                                {
                                    "íšŒì‚¬ëª…": corp,
                                    "ê³„ì •ì½”ë“œ": RE_CODE,
                                    "ê³„ì •ëª…": RE_NAME,
                                    "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°",
                                    "ê¸ˆì•¡": -nci_effect,
                                    "ì„¤ëª…": f"{desc} ë¹„ì§€ë°°ì§€ë¶„íš¨ê³¼",
                                }
                            )
                            nci_adj_entries.append(
                                {
                                    "íšŒì‚¬ëª…": corp,
                                    "ê³„ì •ì½”ë“œ": NCI_PL_CODE,
                                    "ê³„ì •ëª…": NCI_PL_NAME,
                                    "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°",
                                    "ê¸ˆì•¡": nci_effect,
                                    "ì„¤ëª…": f"{desc} ë¹„ì§€ë°°ì§€ë¶„íš¨ê³¼",
                                }
                            )

                        
        # --- 2. NCI on subsidiary's total equity change from 'CE' sheet ---
        for sub_file, sub_name in zip(subs_files, subs_names):
            try:
                sub_file.seek(0)
                sub_xls = pd.ExcelFile(sub_file)
                if "CE" in sub_xls.sheet_names:
                    sce_df = pd.read_excel(sub_xls, sheet_name="CE", header=None)

                    if sce_df.shape[0] < 5 or sce_df.shape[1] < 4:
                        continue

                    nci_rate = nci_rates.get(sub_name, 0.0)
                    if nci_rate <= 0:
                        continue

                    for r in range(3, len(sce_df)):
                        data_row = sce_df.iloc[r]
                        row_desc = str(data_row.iloc[1])

                        if "ê¸°ë§" in row_desc or "Ending" in row_desc:
                            break
                        if "ê¸°ì´ˆ" in row_desc or "Beginning" in row_desc:
                            continue

                        ce_adj_code = str(data_row.iloc[2])
                        is_ni_item = "_NI" in ce_adj_code
                        nci_contra_code = NCI_PL_CODE if is_ni_item else NCI_EQUITY_CODE
                        nci_contra_name = NCI_PL_NAME if is_ni_item else NCI_EQUITY_NAME

                        # Get the numeric values for the current row
                        change_values = pd.to_numeric(
                            data_row.iloc[3:-1], errors="coerce"
                        ).fillna(0)

                        # Calculate the sum for the row (ì•ˆë¶„ ëŒ€ìƒ í•©ê³„)
                        row_sum = change_values.sum()

                        # If there's no significant change in the row, skip to the next row
                        if abs(row_sum) <= 1:
                            continue

                        # Calculate the total NCI amount for the row
                        total_nci_per_row = row_sum * nci_rate

                        # Create a safe divisor to avoid ZeroDivisionError
                        safe_row_sum = row_sum if row_sum != 0 else 1

                        # Calculate the weight of each column's value relative to the row sum
                        weights = change_values / safe_row_sum

                        # Distribute the total NCI amount across the columns based on weights
                        nci_distribution = weights * total_nci_per_row

                        # Create adjustment entries for each distributed NCI amount
                        header_row = sce_df.iloc[1]
                        equity_acct_codes = header_row.iloc[3:-1]
                        for i, nci_effect in enumerate(nci_distribution):
                            if abs(nci_effect) > 1:
                                equity_acct_code = str(equity_acct_codes.iloc[i])

                                # Debit entry to the specific equity account
                                nci_adj_entries.append(
                                    {
                                        "íšŒì‚¬ëª…": sub_name,
                                        "ê³„ì •ì½”ë“œ": equity_acct_code,
                                        "ê³„ì •ëª…": name_map.get(equity_acct_code, ""),
                                        "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°",
                                        "ê¸ˆì•¡": nci_effect,
                                        "ì„¤ëª…": f"{sub_name} ìë³¸ë³€ë™ ({row_desc})",
                                    }
                                )
                                # Credit entry to the NCI contra account
                                nci_adj_entries.append(
                                    {
                                        "íšŒì‚¬ëª…": sub_name,
                                        "ê³„ì •ì½”ë“œ": nci_contra_code,
                                        "ê³„ì •ëª…": nci_contra_name,
                                        "ë‹¹ê¸°ì „ê¸°": "ë‹¹ê¸°",
                                        "ê¸ˆì•¡": -nci_effect,
                                        "ì„¤ëª…": f"{sub_name} ìë³¸ë³€ë™ ({row_desc})",
                                    }
                                )

                else:
                    log_validation(f"âš ï¸ **[{sub_name}]** ìë³¸ë³€ë™í‘œ(CE) ì‹œíŠ¸ê°€ ì—†ì–´ ìë³¸ë³€ë™ì— ë”°ë¥¸ ë¹„ì§€ë°°ì§€ë¶„ ì¡°ì •ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            except Exception as e:
                st.warning(f"{sub_name}ì˜ 'CE'ì‹œíŠ¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

        # --- Final assembly of adjustment sheets ---
        final_sheets = original_sheets.copy()
        sheet_names = list(final_sheets.keys())

        def find_sheet_name_by_prefix(prefix):
            for name in sheet_names:
                if name.upper().startswith(prefix):
                    return name
            return f"{prefix}_ìë™ìƒì„±" # Fallback to a new sheet name

        # Handle Tax Adjustments (CAJE97)
        caje97_sheet_name = find_sheet_name_by_prefix("CAJE97")
        new_tax_df = pd.DataFrame(tax_adj_entries)
        if caje97_sheet_name in final_sheets and not final_sheets[caje97_sheet_name].empty:
            original_tax_df = final_sheets[caje97_sheet_name].dropna(how="all")
            final_sheets[caje97_sheet_name] = pd.concat(
                [original_tax_df, new_tax_df], ignore_index=True
            )
        elif not new_tax_df.empty:
            final_sheets[caje97_sheet_name] = new_tax_df

        # Handle NCI Adjustments (CAJE98)
        caje98_sheet_name = find_sheet_name_by_prefix("CAJE98")
        new_nci_df = pd.DataFrame(nci_adj_entries)
        if caje98_sheet_name in final_sheets and not final_sheets[caje98_sheet_name].empty:
            original_nci_df = final_sheets[caje98_sheet_name].dropna(how="all")
            final_sheets[caje98_sheet_name] = pd.concat(
                [original_nci_df, new_nci_df], ignore_index=True
            )
        elif not new_nci_df.empty:
            final_sheets[caje98_sheet_name] = new_nci_df

        return to_excel(final_sheets)


    # --- Step 1: Download Template ---
    st.subheader("Step 1: í…œí”Œë¦¿ ë‹¤ìš´ë¡œë“œ")
    st.write(
        "í…œí”Œë¦¿ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ê¸°ë³¸ ì¡°ì • ëª…ì„¸ì„œ ì‹œíŠ¸ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤."
    )
    template_data = create_adjustment_template()
    st.download_button(
        label="ğŸ“¥ ì¡°ì •ëª…ì„¸ ì…ë ¥ í…œí”Œë¦¿ ë‹¤ìš´ë¡œë“œ (.xlsx)",
        data=template_data,
        file_name="ì¡°ì •ëª…ì„¸_ì…ë ¥í…œí”Œë¦¿_BeforeTaxNci.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    )

    # --- Step 2: Upload Initial Adjustments ---
    st.subheader("Step 2: ê¸°ë³¸ ì¡°ì • íŒŒì¼ ì—…ë¡œë“œ")
    st.session_state.adj_workflow["initial_file"] = st.file_uploader(
        "ì‘ì„±í•œ ê¸°ë³¸ ì¡°ì • íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”('Info' ì‹œíŠ¸ í¬í•¨). ì™¼ìª½ sidebarì— CoA(ê³„ì •ì²´ê³„)ê°€ ì—…ë¡œë“œ ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.",
        type="xlsx",
        key="initial_adj_uploader",
    )

    # --- Step 3: Generate & Download Intermediate File ---
    st.subheader("Step 3: ë²•ì¸ì„¸/NCI ìë™ê³„ì‚° ë° ê²€í† ")
    if st.button(
        "âš™ï¸ ë²•ì¸ì„¸/NCI ì¡°ì • ìë™ê³„ì‚° ì‹¤í–‰",
        disabled=not (
            st.session_state.adj_workflow.get("initial_file")
            and st.session_state.files.get("coa")
        ),
    ):
        st.session_state.results["validation_log"] = []  # ë¡œê·¸ ì´ˆê¸°í™”

        subs_files = st.session_state.files.get("subsidiaries", [])
        if not subs_files:
            log_validation(
                "âš ï¸ **[ìíšŒì‚¬ íŒŒì¼ ì—†ìŒ]** ìíšŒì‚¬ ì¬ë¬´ì œí‘œ íŒŒì¼ì´ ì—…ë¡œë“œë˜ì§€ ì•Šìœ¼ë©´ ìë³¸ë³€ë™ì— ë”°ë¥¸ ë¹„ì§€ë°°ì§€ë¶„ ì¡°ì •ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            )

        with st.spinner("ìë™ ì¡°ì • ë¶„ê°œë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                coa_df = pd.read_excel(
                    st.session_state.files["coa"], sheet_name="CoA", dtype=str
                )
                subs_names = [f.name.split("_")[0] for f in subs_files]
                aje_code = pd.read_excel(
                    st.session_state.files["coa"], sheet_name="AJE", dtype=str
                )
                intermediate_excel_data = generate_intermediate_adjustments(
                    st.session_state.adj_workflow["initial_file"],
                    coa_df,
                    subs_files,
                    subs_names,
                    aje_code,
                )
                if intermediate_excel_data:
                    st.session_state.adj_workflow["intermediate_data"] = (
                        intermediate_excel_data
                    )
                    st.success(
                        "ìë™ê³„ì‚°ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì•„ë˜ ë²„íŠ¼ìœ¼ë¡œ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ê²€í† í•˜ì„¸ìš”."
                    )
            except Exception as e:
                st.error(f"ìë™ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                st.exception(e)

    if st.session_state.results["validation_log"]:
        with st.expander("ğŸ” ì¡°ì • ìë™ê³„ì‚° ê²€ì¦ ë¡œê·¸", expanded=True):
            for log in st.session_state.results["validation_log"]:
                st.markdown(log, unsafe_allow_html=True)

    if st.session_state.adj_workflow.get("intermediate_data"):
        st.download_button(
            label="ğŸ“¥ ê²€í† ìš© íŒŒì¼ ë‹¤ìš´ë¡œë“œ (ìë™ê³„ì‚° í¬í•¨)",
            data=st.session_state.adj_workflow["intermediate_data"],
            file_name="ì¡°ì •ëª…ì„¸_ì…ë ¥í…œí”Œë¦¿_TaxNci.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        )

    # --- Step 4: Upload Final File ---
    st.subheader("Step 4: ìµœì¢… ì¡°ì • íŒŒì¼ ì—…ë¡œë“œ")
    st.write("ê²€í†  ë° ìˆ˜ì •ì„ ì™„ë£Œí•œ ìµœì¢… ì¡°ì • íŒŒì¼ì„ ì—…ë¡œë“œí•©ë‹ˆë‹¤.")
    st.session_state.adj_workflow["final_file"] = st.file_uploader(
        "ìµœì¢… ì¡°ì •ëª…ì„¸ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", type="xlsx", key="final_adj_uploader"
    )

    # --- Step 5 & 6: Generate Final CAJE and Display ---
    st.subheader("Step 5: ìµœì¢… ë¶„ê°œ ìƒì„± ë° ê²°ê³¼ í™•ì¸")

    def build_caje_from_template(adjustment_file, coa_df_internal):
        fs_map = dict(zip(coa_df_internal["ê³„ì •ì½”ë“œ"], coa_df_internal["FS_Element"]))

        def get_bspl_sign(fs_element):
            return -1 if fs_element in ["A", "X", "CA"] else 1

        ni_code = None
        try:
            r_rows = coa_df_internal[coa_df_internal["FS_Element"] == "R"]
            if not r_rows.empty:
                ni_code = r_rows.iloc[0].get("L1_code")
        except (IndexError, KeyError):
            ni_code = None

        xls = pd.ExcelFile(adjustment_file)
        all_bspl_entries, all_cf_entries = [], []

        for sheet_name in xls.sheet_names:
            if not sheet_name.upper().startswith("CAJE"):
                continue
            caje_type = sheet_name.split("_")[0].upper()
            df = pd.read_excel(xls, sheet_name, dtype={"ê³„ì •ì½”ë“œ": str}).fillna("")

            # --- A. BS/PL Adjustment Logic ---
            df_for_bspl = df.copy()
            if caje_type in ["CAJE01", "CAJE04"]:
                df_for_bspl = df[df["ë‹¹ê¸°ì „ê¸°"] == "ë‹¹ê¸°"]

            for _, row in df_for_bspl.iterrows():
                acc_code = str(row.get("ê³„ì •ì½”ë“œ", "")).strip()
                if not acc_code:
                    continue
                fs_element = fs_map.get(acc_code, "")
                amount = pd.to_numeric(row.get("ê¸ˆì•¡"), errors="coerce")
                if pd.isna(amount) or amount == 0:
                    continue

                final_amount = amount * get_bspl_sign(fs_element)
                all_bspl_entries.append(
                    {
                        "ì¡°ì •ìœ í˜•": caje_type,
                        "íšŒì‚¬ëª…": row.get("íšŒì‚¬ëª…"),
                        "ê³„ì •ì½”ë“œ": acc_code,
                        "ê¸ˆì•¡": final_amount,
                        "ì„¤ëª…": row.get("ì„¤ëª…"),
                        "ë‹¹ê¸°ì „ê¸°": row.get("ë‹¹ê¸°ì „ê¸°"),
                        "FS_Element": fs_element,
                    }
                )

            # --- B. CF Adjustment Logic ---
            if caje_type == "CAJE02":
                if ni_code is None:
                    st.warning(
                        f"[{sheet_name}] CFì¡°ì • ê±´ë„ˆëœ€: ë‹¹ê¸°ìˆœì´ìµ ê³„ì • ì½”ë“œë¥¼ CoAì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                    )
                    continue
                df_with_fs = df.merge(
                    coa_df_internal[["ê³„ì •ì½”ë“œ", "FS_Element"]],
                    on="ê³„ì •ì½”ë“œ",
                    how="left",
                )
                pl_rows = df_with_fs[df_with_fs["FS_Element"].isin(["R", "X"])].copy()
                bs_rows = df_with_fs[
                    df_with_fs["FS_Element"].isin(["A", "L", "E"])
                ].copy()
                if pl_rows.empty or bs_rows.empty:
                    st.warning(
                        f"[{sheet_name}] CFì¡°ì • ê±´ë„ˆëœ€: ì‹œíŠ¸ì—ì„œ ì†ìµ(R/X) ë˜ëŠ” ì¬ë¬´ìƒíƒœ(A/L/E) ê³„ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                    )
                    continue

                pl_pivot = pl_rows.pivot_table(
                    index=["ê³„ì •ì½”ë“œ", "FS_Element"],
                    columns="ë‹¹ê¸°ì „ê¸°",
                    values="ê¸ˆì•¡",
                    aggfunc="sum",
                ).fillna(0)
                if "ë‹¹ê¸°" not in pl_pivot.columns:
                    pl_pivot["ë‹¹ê¸°"] = 0
                if "ì „ê¸°" not in pl_pivot.columns:
                    pl_pivot["ì „ê¸°"] = 0
                pl_pivot["change"] = pl_pivot["ë‹¹ê¸°"] + pl_pivot["ì „ê¸°"]
                pl_pivot["impact"] = pl_pivot.apply(
                    lambda r: r["change"] if r.name[1] == "X" else -r["change"], axis=1
                )
                total_pl_impact = pl_pivot["impact"].sum()

                inventory_acc_code = bs_rows.iloc[0]["ê³„ì •ì½”ë“œ"]
                corp_name = df.iloc[0]["íšŒì‚¬ëª…"]

                # Line 1: NI Entry (+)
                all_cf_entries.append(
                    {
                        "ì¡°ì •ìœ í˜•": caje_type,
                        "íšŒì‚¬ëª…": corp_name,
                        "ê³„ì •ì½”ë“œ": ni_code,
                        "ì¡°ì •ê¸ˆì•¡": total_pl_impact,
                        "ì„¤ëª…": "[ë¹„í˜„ê¸ˆì†ìµ] ë¯¸ì‹¤í˜„ì´ìµ(NI)",
                    }
                )
                # Line 2: Inventory Entry (-)
                all_cf_entries.append(
                    {
                        "ì¡°ì •ìœ í˜•": caje_type,
                        "íšŒì‚¬ëª…": corp_name,
                        "ê³„ì •ì½”ë“œ": inventory_acc_code,
                        "ì¡°ì •ê¸ˆì•¡": -total_pl_impact,
                        "ì„¤ëª…": "[ë¹„í˜„ê¸ˆì†ìµ] ë¯¸ì‹¤í˜„ì´ìµ(ì¬ê³ )",
                    }
                )
            elif caje_type == "CAJE03":
                if ni_code is None:
                    st.warning(
                        f"[{sheet_name}] CFì¡°ì • ê±´ë„ˆëœ€: ë‹¹ê¸°ìˆœì´ìµ ê³„ì • ì½”ë“œë¥¼ CoAì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                    )
                    continue
                df_with_fs = df.merge(
                    coa_df_internal[["ê³„ì •ì½”ë“œ", "FS_Element"]],
                    on="ê³„ì •ì½”ë“œ",
                    how="left",
                )
                pl_rows = df_with_fs[df_with_fs["FS_Element"].isin(["X", "R"])].copy()
                bs_rows = df_with_fs[
                    df_with_fs["FS_Element"].isin(["A", "L", "E"])
                ].copy()
                if pl_rows.empty or bs_rows.empty:
                    st.warning(
                        f"[{sheet_name}] CFì¡°ì • ê±´ë„ˆëœ€: ì‹œíŠ¸ì—ì„œ ì†ìµ(R/X) ë˜ëŠ” ì¬ë¬´ìƒíƒœ(A/L/E) ê³„ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                    )
                    continue

                pl_pivot = pl_rows.pivot_table(
                    index=["ê³„ì •ì½”ë“œ", "FS_Element"],
                    columns="ë‹¹ê¸°ì „ê¸°",
                    values="ê¸ˆì•¡",
                    aggfunc="sum",
                ).fillna(0)
                if "ë‹¹ê¸°" not in pl_pivot.columns:
                    pl_pivot["ë‹¹ê¸°"] = 0
                if "ì „ê¸°" not in pl_pivot.columns:
                    pl_pivot["ì „ê¸°"] = 0
                pl_pivot["change"] = pl_pivot["ë‹¹ê¸°"] + pl_pivot["ì „ê¸°"]
                pl_pivot["impact"] = pl_pivot.apply(
                    lambda r: r["change"] if r.name[1] == "X" else -r["change"], axis=1
                )
                total_pl_impact = pl_pivot["impact"].sum()

                pl_acc_code = pl_rows.iloc[0]["ê³„ì •ì½”ë“œ"]
                corp_name = df.iloc[0]["íšŒì‚¬ëª…"]

                # Line 1: NI Entry (+)
                all_cf_entries.append(
                    {
                        "ì¡°ì •ìœ í˜•": caje_type,
                        "íšŒì‚¬ëª…": corp_name,
                        "ê³„ì •ì½”ë“œ": ni_code,
                        "ì¡°ì •ê¸ˆì•¡": total_pl_impact,
                        "ì„¤ëª…": "[ë¹„í˜„ê¸ˆì†ìµ] ë¯¸ì‹¤í˜„ì´ìµ(NI)",
                    }
                )
                # Line 2: PL Entry (-)
                all_cf_entries.append(
                    {
                        "ì¡°ì •ìœ í˜•": caje_type,
                        "íšŒì‚¬ëª…": corp_name,
                        "ê³„ì •ì½”ë“œ": pl_acc_code,
                        "ì¡°ì •ê¸ˆì•¡": -total_pl_impact,
                        "ì„¤ëª…": "[ë¹„í˜„ê¸ˆì†ìµ] ë¯¸ì‹¤í˜„ì´ìµ(ì†ìµ)",
                    }
                )
            elif caje_type == "CAJE04":
                if ni_code is None:
                    st.warning(
                        f"[{sheet_name}] CFì¡°ì • ê±´ë„ˆëœ€: ë‹¹ê¸°ìˆœì´ìµ ê³„ì • ì½”ë“œë¥¼ CoAì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                    )
                    continue
                df_with_fs = df.merge(
                    coa_df_internal[["ê³„ì •ì½”ë“œ", "FS_Element"]],
                    on="ê³„ì •ì½”ë“œ",
                    how="left",
                )
                pl_rows = df_with_fs[df_with_fs["FS_Element"].isin(["X", "R"])].copy()
                bs_rows = df_with_fs[
                    df_with_fs["FS_Element"].isin(["A", "L", "E"])
                ].copy()
                if pl_rows.empty or bs_rows.empty:
                    st.warning(
                        f"[{sheet_name}] CFì¡°ì • ê±´ë„ˆëœ€: ì‹œíŠ¸ì—ì„œ ì†ìµ(R/X) ë˜ëŠ” ì¬ë¬´ìƒíƒœ(A/L/E) ê³„ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                    )
                    continue

                pl_pivot = pl_rows.pivot_table(
                    index=["ê³„ì •ì½”ë“œ", "FS_Element"],
                    columns="ë‹¹ê¸°ì „ê¸°",
                    values="ê¸ˆì•¡",
                    aggfunc="sum",
                ).fillna(0)
                if "ë‹¹ê¸°" not in pl_pivot.columns:
                    pl_pivot["ë‹¹ê¸°"] = 0
                if "ì „ê¸°" not in pl_pivot.columns:
                    pl_pivot["ì „ê¸°"] = 0
                pl_pivot["change"] = pl_pivot["ë‹¹ê¸°"] + pl_pivot["ì „ê¸°"]
                pl_pivot["impact"] = pl_pivot.apply(
                    lambda r: r["change"] if r.name[1] == "X" else -r["change"], axis=1
                )
                total_pl_impact = pl_pivot["impact"].sum()

                pl_acc_code = pl_rows.iloc[0]["ê³„ì •ì½”ë“œ"]
                corp_name = df.iloc[0]["íšŒì‚¬ëª…"]

                # Line 1: NI Entry (+)
                all_cf_entries.append(
                    {
                        "ì¡°ì •ìœ í˜•": caje_type,
                        "íšŒì‚¬ëª…": corp_name,
                        "ê³„ì •ì½”ë“œ": ni_code,
                        "ì¡°ì •ê¸ˆì•¡": total_pl_impact,
                        "ì„¤ëª…": "[ì†ìµ/ì¬ë¬´í™œë™] ë¯¸ì‹¤í˜„ì´ìµ(NI)",
                    }
                )
                # Line 2: RE/PL Entry (-)
                all_cf_entries.append(
                    {
                        "ì¡°ì •ìœ í˜•": caje_type,
                        "íšŒì‚¬ëª…": corp_name,
                        "ê³„ì •ì½”ë“œ": pl_acc_code,
                        "ì¡°ì •ê¸ˆì•¡": total_pl_impact,
                        "ì„¤ëª…": "[ì†ìµ/ì¬ë¬´í™œë™] ë¯¸ì‹¤í˜„ì´ìµ(ì†ìµ)",
                    }
                )
            elif caje_type == "CAJE05":
                if ni_code is None:
                    st.warning(
                        f"[{sheet_name}] CFì¡°ì • ê±´ë„ˆëœ€: ë‹¹ê¸°ìˆœì´ìµ ê³„ì • ì½”ë“œë¥¼ CoAì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                    )
                    continue
                df_with_fs = df.merge(
                    coa_df_internal[["ê³„ì •ì½”ë“œ", "FS_Element"]],
                    on="ê³„ì •ì½”ë“œ",
                    how="left",
                )
                pl_rows = df_with_fs[df_with_fs["FS_Element"].isin(["X", "R"])].copy()
                bs_rows = df_with_fs[
                    df_with_fs["FS_Element"].isin(["A", "L", "E"])
                ].copy()
                if pl_rows.empty or bs_rows.empty:
                    st.warning(
                        f"[{sheet_name}] CFì¡°ì • ê±´ë„ˆëœ€: ì‹œíŠ¸ì—ì„œ ì†ìµ(R/X) ë˜ëŠ” ì¬ë¬´ìƒíƒœ(A/L/E) ê³„ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                    )
                    continue

                pl_pivot = pl_rows.pivot_table(
                    index=["ê³„ì •ì½”ë“œ", "FS_Element"],
                    columns="ë‹¹ê¸°ì „ê¸°",
                    values="ê¸ˆì•¡",
                    aggfunc="sum",
                ).fillna(0)
                if "ë‹¹ê¸°" not in pl_pivot.columns:
                    pl_pivot["ë‹¹ê¸°"] = 0
                if "ì „ê¸°" not in pl_pivot.columns:
                    pl_pivot["ì „ê¸°"] = 0
                pl_pivot["change"] = pl_pivot["ë‹¹ê¸°"] + pl_pivot["ì „ê¸°"]
                pl_pivot["impact"] = pl_pivot.apply(
                    lambda r: r["change"] if r.name[1] == "X" else -r["change"], axis=1
                )
                total_pl_impact = pl_pivot["impact"].sum()

                pl_acc_code = pl_rows.iloc[0]["ê³„ì •ì½”ë“œ"]
                corp_name = df.iloc[0]["íšŒì‚¬ëª…"]

                # Line 1: NI Entry (+)
                all_cf_entries.append(
                    {
                        "ì¡°ì •ìœ í˜•": caje_type,
                        "íšŒì‚¬ëª…": corp_name,
                        "ê³„ì •ì½”ë“œ": ni_code,
                        "ì¡°ì •ê¸ˆì•¡": total_pl_impact,
                        "ì„¤ëª…": "[ì†ìµ] ê¸°íƒ€ì†ìµì¡°ì •(NI)",
                    }
                )
                # Line 2: RE/PL Entry (-)
                all_cf_entries.append(
                    {
                        "ì¡°ì •ìœ í˜•": caje_type,
                        "íšŒì‚¬ëª…": corp_name,
                        "ê³„ì •ì½”ë“œ": pl_acc_code,
                        "ì¡°ì •ê¸ˆì•¡": total_pl_impact,
                        "ì„¤ëª…": "[ì†ìµ] ê¸°íƒ€ì†ìµì¡°ì •(ì†ìµ)",
                    }
                )
            elif caje_type == "CAJE97":
                if ni_code is None:
                    st.warning(
                        f"[{sheet_name}] CFì¡°ì • ê±´ë„ˆëœ€: ë‹¹ê¸°ìˆœì´ìµ ê³„ì • ì½”ë“œë¥¼ CoAì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                    )
                    continue
                df_with_fs = df.merge(
                    coa_df_internal[["ê³„ì •ì½”ë“œ", "FS_Element"]],
                    on="ê³„ì •ì½”ë“œ",
                    how="left",
                )
                pl_rows = df_with_fs[df_with_fs["FS_Element"].isin(["X", "R"])].copy()
                bs_rows = df_with_fs[
                    df_with_fs["FS_Element"].isin(["A", "L", "E"])
                ].copy()
                if pl_rows.empty or bs_rows.empty:
                    st.warning(
                        f"[{sheet_name}] CFì¡°ì • ê±´ë„ˆëœ€: ì‹œíŠ¸ì—ì„œ ì†ìµ(R/X) ë˜ëŠ” ì¬ë¬´ìƒíƒœ(A/L/E) ê³„ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                    )
                    continue

                pl_pivot = pl_rows.pivot_table(
                    index=["ê³„ì •ì½”ë“œ", "FS_Element"],
                    columns="ë‹¹ê¸°ì „ê¸°",
                    values="ê¸ˆì•¡",
                    aggfunc="sum",
                ).fillna(0)
                if "ë‹¹ê¸°" not in pl_pivot.columns:
                    pl_pivot["ë‹¹ê¸°"] = 0
                if "ì „ê¸°" not in pl_pivot.columns:
                    pl_pivot["ì „ê¸°"] = 0
                pl_pivot["change"] = pl_pivot["ë‹¹ê¸°"] + pl_pivot["ì „ê¸°"]
                pl_pivot["impact"] = pl_pivot.apply(
                    lambda r: r["change"] if r.name[1] == "X" else -r["change"], axis=1
                )
                total_pl_impact = pl_pivot["impact"].sum()

                pl_acc_code = pl_rows.iloc[0]["ê³„ì •ì½”ë“œ"]
                corp_name = df.iloc[0]["íšŒì‚¬ëª…"]

                # Line 1: NI Entry (+)
                all_cf_entries.append(
                    {
                        "ì¡°ì •ìœ í˜•": caje_type,
                        "íšŒì‚¬ëª…": corp_name,
                        "ê³„ì •ì½”ë“œ": ni_code,
                        "ì¡°ì •ê¸ˆì•¡": total_pl_impact,
                        "ì„¤ëª…": "[ë¹„í˜„ê¸ˆì†ìµ] ë²•ì¸ì„¸ ë‹¹ê¸°ì†ìµ íš¨ê³¼(NI)",
                    }
                )
                # Line 2: PL Entry (-)
                all_cf_entries.append(
                    {
                        "ì¡°ì •ìœ í˜•": caje_type,
                        "íšŒì‚¬ëª…": corp_name,
                        "ê³„ì •ì½”ë“œ": pl_acc_code,
                        "ì¡°ì •ê¸ˆì•¡": -total_pl_impact,
                        "ì„¤ëª…": "[ë¹„í˜„ê¸ˆì†ìµ] ë²•ì¸ì„¸ë°”ìš©",
                    }
                )
            else:
                grouped = df.groupby(["íšŒì‚¬ëª…", "ê³„ì •ì½”ë“œ", "ì„¤ëª…"])
                for (corp, acc_code, desc), group in grouped:
                    pivot_df = group.pivot_table(
                        columns="ë‹¹ê¸°ì „ê¸°", values="ê¸ˆì•¡", aggfunc="sum"
                    )
                    current_amt = (
                        pivot_df["ë‹¹ê¸°"].item() if "ë‹¹ê¸°" in pivot_df.columns else 0
                    )
                    prior_amt = (
                        pivot_df["ì „ê¸°"].item() if "ì „ê¸°" in pivot_df.columns else 0
                    )
                    fs_element = fs_map.get(acc_code, "")

                    cf_adj_amt, cf_desc = 0, desc
                    if caje_type == "CAJE01":
                        change_amt = current_amt - prior_amt
                        if fs_element == "L":
                            cf_adj_amt = change_amt
                        else:  # For 'A' and others
                            cf_adj_amt = -change_amt
                        cf_desc = f"[ìš´ì „ìë³¸] {desc}"

                    if abs(cf_adj_amt) > 1e-6:
                        all_cf_entries.append(
                            {
                                "ì¡°ì •ìœ í˜•": caje_type,
                                "íšŒì‚¬ëª…": corp,
                                "ê³„ì •ì½”ë“œ": acc_code,
                                "ì¡°ì •ê¸ˆì•¡": cf_adj_amt,
                                "ì„¤ëª…": cf_desc,
                            }
                        )

        bspl_cols = ["ì¡°ì •ìœ í˜•", "íšŒì‚¬ëª…", "ê³„ì •ì½”ë“œ", "ê¸ˆì•¡", "ì„¤ëª…", "ë‹¹ê¸°ì „ê¸°", "FS_Element"]
        cf_cols = ["ì¡°ì •ìœ í˜•", "íšŒì‚¬ëª…", "ê³„ì •ì½”ë“œ", "ì¡°ì •ê¸ˆì•¡", "ì„¤ëª…"]

        caje_bspl_df = (
            pd.DataFrame(all_bspl_entries, columns=bspl_cols)
            if all_bspl_entries
            else pd.DataFrame(columns=bspl_cols)
        )
        caje_cf_df = (
            pd.DataFrame(all_cf_entries, columns=cf_cols)
            if all_cf_entries
            else pd.DataFrame(columns=cf_cols)
        )

        return caje_bspl_df, caje_cf_df

    if st.button(
        "ğŸš€ ìµœì¢… ì—°ê²°ì¡°ì •ë¶„ê°œ ìƒì„± ì‹¤í–‰",
        disabled=not (
            st.session_state.adj_workflow["final_file"]
            and st.session_state.files["coa"]
        ),
    ):
        with st.spinner("ìµœì¢… ì¡°ì • ë¶„ê°œë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            try:
                coa_df = pd.read_excel(
                    st.session_state.files["coa"], sheet_name="CoA", dtype=str
                )
                caje_bspl_df, caje_cf_df = build_caje_from_template(
                    st.session_state.adj_workflow["final_file"], coa_df
                )
                st.session_state.results["caje_bspl_df"] = caje_bspl_df
                st.session_state.results["caje_cf_df"] = caje_cf_df
                st.session_state.caje_generated = True
                st.success("âœ… ìµœì¢… ì¡°ì • ë¶„ê°œ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

                if not caje_bspl_df.empty and "ê¸ˆì•¡" in caje_bspl_df.columns:
                    total_adj_sum = caje_bspl_df["ê¸ˆì•¡"].sum()
                    if abs(total_adj_sum) > 1:
                        st.error(
                            f"âŒ **[BS/PL CAJE ê²€ì¦]** ì¡°ì •ë¶„ê°œ í•©ê³„ê°€ 0ì´ ì•„ë‹™ë‹ˆë‹¤ (ì°¨ëŒ€ ë¶ˆì¼ì¹˜): {total_adj_sum:,.0f}"
                        )
                    else:
                        st.success(
                            f"âœ… **[BS/PL CAJE ê²€ì¦]** ì¡°ì •ë¶„ê°œ í•©ê³„ê°€ 0ìœ¼ë¡œ ì¼ì¹˜í•©ë‹ˆë‹¤."
                        )

            except Exception as e:
                st.error(f"ìµœì¢… ì¡°ì • ë¶„ê°œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                st.exception(e)

    if not st.session_state.files["coa"]:
        st.warning("ë¨¼ì € ì‚¬ì´ë“œë°”ì—ì„œ CoA íŒŒì¼ì„ ì—…ë¡œë“œí•´ì•¼ í•©ë‹ˆë‹¤.")

    if st.session_state.caje_generated:
        st.markdown("#### ğŸ“„ ì¬ë¬´ìƒíƒœí‘œ/ì†ìµê³„ì‚°ì„œ ì¡°ì • ë¶„ê°œ (BS/PL CAJE)")
        st.dataframe(st.session_state.results.get("caje_bspl_df"))
        st.markdown("#### ğŸŒŠ í˜„ê¸ˆíë¦„í‘œ ì¡°ì • ë¶„ê°œ (CF CAJE)")
        st.dataframe(st.session_state.results.get("caje_cf_df"))
        caje_excel_data = to_excel(
            {
                "CAJE_BSPL": st.session_state.results.get(
                    "caje_bspl_df", pd.DataFrame()
                ),
                "CAJE_CF": st.session_state.results.get("caje_cf_df", pd.DataFrame()),
            }
        )
        st.download_button(
            label="ğŸ“¥ ìƒì„±ëœ ì¡°ì • ë¶„ê°œ(CAJE) ë‹¤ìš´ë¡œë“œ (.xlsx)",
            data=caje_excel_data,
            file_name="CAJE_generated.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        )
        st.info(
            "ìƒì„±ëœ BS/PL CAJE ë°ì´í„°ëŠ” 'ì—°ê²° ì¬ë¬´ì œí‘œ' íƒ­ì˜ 'ì—°ê²° ì¡°ì •' ë°ì´í„°ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        )


with tab4:
    st.header("4. ì™¸í™” ì¬ë¬´ì œí‘œ í™˜ì‚°")
    st.write(
        "ì™¸í™”ë¡œ ì‘ì„±ëœ ì¬ë¬´ì œí‘œ(FS) íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´, ì§€ì •ëœ í™˜ìœ¨ì— ë”°ë¼ ì›í™”ë¡œ í™˜ì‚°í•˜ê³  ê²°ê³¼ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤."
    )
    st.subheader("Step 1: íŒŒì¼ ì—…ë¡œë“œ")
    st.info(
        "í™˜ì‚°í•  FSíŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”. íŒŒì¼ì˜ ì²« ë‘ ë°ì´í„° í–‰ì—ëŠ” ê¸°ë§í™˜ìœ¨ê³¼ í‰ê· í™˜ìœ¨ì´ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤."
    )
    fcfs_file = st.file_uploader("ì™¸í™” FS íŒŒì¼", type="xlsx", key="fcfs_uploader")
    st.subheader("Step 2: í™˜ì‚° ì‹¤í–‰")
    if st.button("âš™ï¸ ì™¸í™”FS í™˜ì‚° ì‹¤í–‰", disabled=not fcfs_file):
        with st.spinner("ì™¸í™” ì¬ë¬´ì œí‘œë¥¼ í™˜ì‚°í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                log_stream = io.StringIO()
                with redirect_stdout(log_stream):
                    closing_rate, average_rate, df = read_rates_and_table(fcfs_file)
                    pre_summary = precheck_foreign_currency(df)
                    translated_df, totals_summary = translate_fcfs(
                        df, closing_rate, average_rate
                    )
                log_contents = log_stream.getvalue()
                st.session_state.fcfs_results["log"] = log_contents.strip().split("\n")
                rates_summary_df = pd.DataFrame(
                    {
                        "í•­ëª©": ["ê¸°ë§í™˜ìœ¨", "í‰ê· í™˜ìœ¨"],
                        "ê°’": [closing_rate, average_rate],
                    }
                )
                pre_summary_df = pd.DataFrame(
                    {"í•­ëª©": list(pre_summary.keys()), "ê°’": list(pre_summary.values())}
                )
                totals_summary_df = pd.DataFrame(
                    {
                        "í•­ëª©": list(totals_summary.keys()),
                        "ê°’": list(totals_summary.values()),
                    }
                )
                summary_df = pd.concat(
                    [rates_summary_df, pre_summary_df, totals_summary_df],
                    ignore_index=True,
                )
                summary_df["ê°’"] = summary_df["ê°’"].astype(str)
                st.session_state.fcfs_results["translated_df"] = translated_df
                st.session_state.fcfs_results["summary_df"] = summary_df
                st.success("ğŸ‰ ì™¸í™” ì¬ë¬´ì œí‘œ í™˜ì‚°ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            except Exception as e:
                st.error(f"í™˜ì‚° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                st.exception(e)
    st.subheader("Step 3: ê²°ê³¼ í™•ì¸ ë° ë‹¤ìš´ë¡œë“œ")
    if st.session_state.fcfs_results.get("log"):
        with st.expander("ğŸ” ì²˜ë¦¬ ë¡œê·¸ ë³´ê¸°"):
            st.code("\n".join(st.session_state.fcfs_results["log"]))
    if st.session_state.fcfs_results.get("translated_df") is not None:
        st.markdown("#### ğŸ“„ í™˜ì‚°ëœ ì¬ë¬´ì œí‘œ")
        st.dataframe(st.session_state.fcfs_results["translated_df"])
        st.markdown("#### ğŸ“Š í™˜ì‚° ìš”ì•½")
        st.dataframe(st.session_state.fcfs_results["summary_df"])
        excel_data = to_excel(
            {
                "translated": st.session_state.fcfs_results["translated_df"],
                "summary": st.session_state.fcfs_results["summary_df"],
            }
        )
        st.download_button(
            label="ğŸ“¥ í™˜ì‚° ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (Excel)",
            data=excel_data,
            file_name="FCFS_translated.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        )

# =================================================================================================
# --- ì¡°ì •ëª…ì„¸ ì°¨ê¸°ì´ì›” ê¸°ëŠ¥ ---
# =================================================================================================

def generate_carryover_adjustments(adj_file, coa_df, aje_code):
    """
    ë‹¹ê¸° ì¡°ì •ëª…ì„¸ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì°¨ê¸° ì´ì›” ì¡°ì •ëª…ì„¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    adj_file.seek(0)
    xls = pd.ExcelFile(adj_file)
    input_sheets = {sheet_name: pd.read_excel(xls, sheet_name, dtype={"ê³„ì •ì½”ë“œ": str}) for sheet_name in xls.sheet_names}
    output_sheets = {}
    caje97_new_entries = []

    # --- ë°ì´í„° ì¤€ë¹„ ---
    if "Info" not in input_sheets:
        raise ValueError("'Info' ì‹œíŠ¸ê°€ ì¡°ì •ëª…ì„¸ íŒŒì¼ì— ì—†ìŠµë‹ˆë‹¤.")
    info_df = input_sheets["Info"].copy()
    if 'íšŒì‚¬ëª…' in info_df.columns:
        info_df = info_df.set_index('íšŒì‚¬ëª…')
    else: # ì²«ë²ˆì§¸ ì—´ì„ ì¸ë±ìŠ¤ë¡œ ì‚¬ìš©
        info_df = info_df.set_index(info_df.columns[0])

    # 'ë‹¹ê¸°ì„¸ìœ¨' ì‚¬ìš©
    info_df["ì„¸ìœ¨_num"] = info_df["ë‹¹ê¸°ì„¸ìœ¨"].apply(parse_percent)
    tax_rates = info_df["ì„¸ìœ¨_num"].to_dict()

    fs_map = dict(zip(coa_df["ê³„ì •ì½”ë“œ"].astype(str), coa_df["FS_Element"]))
    name_map = dict(zip(coa_df["ê³„ì •ì½”ë“œ"].astype(str), coa_df["ê³„ì •ëª…"]))

    # AJE ì‹œíŠ¸ì—ì„œ ê³„ì •ì½”ë“œ/ëª…ì¹­ ê°€ì ¸ì˜¤ê¸°
    RE_CODE = aje_code.loc[aje_code["FS_Element"] == "E", "ê³„ì •ì½”ë“œ"].iloc[0]
    RE_NAME = aje_code.loc[aje_code["FS_Element"] == "E", "ê³„ì •ëª…"].iloc[0]
    DTL_CODE = aje_code.loc[aje_code["FS_Element"] == "L", "ê³„ì •ì½”ë“œ"].iloc[0]
    DTL_NAME = aje_code.loc[aje_code["FS_Element"] == "L", "ê³„ì •ëª…"].iloc[0]
    
    # CoAì—ì„œ ë¹„ì§€ë°°ì§€ë¶„ ê´€ë ¨ ê³„ì •ì½”ë“œ/ëª…ì¹­ ê°€ì ¸ì˜¤ê¸°
    nci_pl_row = coa_df[coa_df["FS_Element"] == "CR"]
    NCI_PL_CODE = nci_pl_row.iloc[0]["ê³„ì •ì½”ë“œ"] if not nci_pl_row.empty else "302000" # Fallback
    
    nci_equity_row = coa_df[coa_df["FS_Element"] == "CE"]
    NCI_EQUITY_CODE = nci_equity_row.iloc[0]["ê³„ì •ì½”ë“œ"] if not nci_equity_row.empty else "201100" # Fallback
    NCI_EQUITY_NAME = nci_equity_row.iloc[0]["ê³„ì •ëª…"] if not nci_equity_row.empty else "ë¹„ì§€ë°°ì§€ë¶„"

    original_sheet_names = list(input_sheets.keys())

    # --- ì‹œíŠ¸ë³„ ì°¨ê¸° ì´ì›” ë¡œì§ ì ìš© ---
    for sheet_name in original_sheet_names:
        if not sheet_name.upper().startswith("CAJE"):
            if sheet_name not in output_sheets:
                 output_sheets[sheet_name] = input_sheets[sheet_name]
            continue

        caje_type = sheet_name.split("_")[0].upper()
        df = input_sheets[sheet_name].copy().dropna(how='all')
        if df.empty:
            output_sheets[sheet_name] = df
            continue
        
        df['ê¸ˆì•¡'] = pd.to_numeric(df['ê¸ˆì•¡'], errors='coerce').fillna(0)
        df['ê³„ì •ì½”ë“œ'] = df['ê³„ì •ì½”ë“œ'].astype(str).str.strip()
        df["FS_Element"] = df["ê³„ì •ì½”ë“œ"].map(fs_map)
        df_columns = df.columns.drop("FS_Element") if "FS_Element" in df.columns else df.columns

        # 1. CAJE00: ê·¸ëŒ€ë¡œ ìœ ì§€
        if caje_type == "CAJE00":
            output_sheets[sheet_name] = df.reindex(columns=df_columns)

        # 2. CAJE01: ì „ê¸° í–‰ ì‚­ì œ, ë‹¹ê¸° -> ì „ê¸°
        elif caje_type == "CAJE01":
            new_df = df[df["ë‹¹ê¸°ì „ê¸°"] == "ë‹¹ê¸°"].copy()
            new_df["ë‹¹ê¸°ì „ê¸°"] = "ì „ê¸°"
            output_sheets[sheet_name] = new_df.reindex(columns=df_columns)

        # 3. CAJE02: ê¸°ì¡´ ë°ì´í„° ì‚­ì œ í›„ ì¬ì‘ì„±
        elif caje_type == "CAJE02":
            new_entries = []
            df_columns = df.columns.drop("FS_Element") if "FS_Element" in df.columns else df.columns
            current_year_df = df[df["ë‹¹ê¸°ì „ê¸°"] == "ë‹¹ê¸°"].copy()

            if not current_year_df.empty:
                a_rows = current_year_df[current_year_df["FS_Element"] == "A"]
                x_rows = current_year_df[current_year_df["FS_Element"] == "X"]

                # Aí•­ëª©ê³¼ Xí•­ëª©ì´ ëª¨ë‘ ì¡´ì¬í•´ì•¼ ë¡œì§ ìˆ˜í–‰
                if not a_rows.empty and not x_rows.empty:
                    total_a_amount = a_rows["ê¸ˆì•¡"].sum()

                    # Aí•­ëª©ì˜ ì²«ë²ˆì§¸ íšŒì‚¬ëª…ì„ ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš©
                    corp = a_rows.iloc[0]["íšŒì‚¬ëª…"]
                    
                    # Xí•­ëª©ì˜ ì²«ë²ˆì§¸ ê³„ì •ì½”ë“œë¥¼ ì‚¬ìš©
                    x_code = x_rows.iloc[0]["ê³„ì •ì½”ë“œ"]
                    x_name = x_rows.iloc[0]["ê³„ì •ëª…"]
                    
                    # ì„¤ëª…ì€ Aí•­ëª©ì˜ ì²«ë²ˆì§¸ ì„¤ëª…ì„ ê¸°ë°˜ìœ¼ë¡œ ìƒì„±
                    desc = a_rows.iloc[0].get("ì„¤ëª…", "ë¯¸ì‹¤í˜„ì´ìµ")

                    # Main Adjustment
                    new_entries.append({'íšŒì‚¬ëª…': corp, 'ê³„ì •ì½”ë“œ': x_code, 'ê³„ì •ëª…': x_name, 'ë‹¹ê¸°ì „ê¸°': 'ì „ê¸°', 'ê¸ˆì•¡': total_a_amount, 'ì„¤ëª…': f'{desc}'})
                    new_entries.append({'íšŒì‚¬ëª…': corp, 'ê³„ì •ì½”ë“œ': RE_CODE, 'ê³„ì •ëª…': RE_NAME, 'ë‹¹ê¸°ì „ê¸°': 'ì „ê¸°', 'ê¸ˆì•¡': total_a_amount, 'ì„¤ëª…': f'{desc}'})
                    
                    # Tax Adjustment
                    tax_rate = tax_rates.get(corp, 0.0)
                    tax_effect = total_a_amount * tax_rate
                    if abs(tax_effect) > 1:
                        caje97_new_entries.append({'íšŒì‚¬ëª…': corp, 'ê³„ì •ì½”ë“œ': RE_CODE, 'ê³„ì •ëª…': RE_NAME, 'ë‹¹ê¸°ì „ê¸°': 'ì „ê¸°', 'ê¸ˆì•¡': -tax_effect, 'ì„¤ëª…': f'ì „ê¸° ë¯¸ì‹¤í˜„ì´ìµ ë²•ì¸ì„¸íš¨ê³¼ ({desc})'})
                        caje97_new_entries.append({'íšŒì‚¬ëª…': corp, 'ê³„ì •ì½”ë“œ': DTL_CODE, 'ê³„ì •ëª…': DTL_NAME, 'ë‹¹ê¸°ì „ê¸°': 'ì „ê¸°', 'ê¸ˆì•¡': -tax_effect, 'ì„¤ëª…': f'ì „ê¸° ë¯¸ì‹¤í˜„ì´ìµ ë²•ì¸ì„¸íš¨ê³¼ ({desc})'})

            output_sheets[sheet_name] = pd.DataFrame(new_entries).reindex(columns=df_columns)

        # 4. CAJE03: ëª¨ë“  í–‰ ìœ ì§€, Xê³„ì • -> ì´ìµì‰ì—¬ê¸ˆ ëŒ€ì²´
        elif caje_type == "CAJE03":
            new_df = df.copy()
            # Main Adjustment
            is_x = new_df["FS_Element"] == "X"
            new_df.loc[is_x, "ê¸ˆì•¡"] = -new_df.loc[is_x, "ê¸ˆì•¡"]
            new_df.loc[is_x, "ê³„ì •ì½”ë“œ"] = RE_CODE
            new_df.loc[is_x, "ê³„ì •ëª…"] = RE_NAME
            new_df.loc[is_x, "FS_Element"] = "E"
            new_df["ë‹¹ê¸°ì „ê¸°"] = "ì „ê¸°"
            output_sheets[sheet_name] = new_df.reindex(columns=df_columns)
            # Tax Adjustment
            tax_effect_rows = new_df[new_df["FS_Element"].isin(["E"])].copy()
            asset_rows = new_df[new_df["FS_Element"].isin(["A"])].copy()
            if asset_rows.empty:
                continue
            asset_corp = asset_rows.iloc[0]["íšŒì‚¬ëª…"]
            for _, row in tax_effect_rows.iterrows():
                amount, desc = row["ê¸ˆì•¡"], row.get('ì„¤ëª…', '')
                tax_rate = tax_rates.get(asset_corp, 0.0)
                tax_effect = amount * tax_rate
                if abs(tax_effect) > 1:
                    caje97_new_entries.append({'íšŒì‚¬ëª…': asset_corp, 'ê³„ì •ì½”ë“œ': RE_CODE, 'ê³„ì •ëª…': RE_NAME, 'ë‹¹ê¸°ì „ê¸°': 'ì „ê¸°', 'ê¸ˆì•¡': tax_effect, 'ì„¤ëª…': f'ë²•ì¸ì„¸íš¨ê³¼ ({desc})'})
                    caje97_new_entries.append({'íšŒì‚¬ëª…': asset_corp, 'ê³„ì •ì½”ë“œ': DTL_CODE, 'ê³„ì •ëª…': DTL_NAME, 'ë‹¹ê¸°ì „ê¸°': 'ì „ê¸°', 'ê¸ˆì•¡': -tax_effect, 'ì„¤ëª…': f'ë²•ì¸ì„¸íš¨ê³¼ ({desc})'})

        # 5. CAJE04: ë¹„ì§€ë°°ì§€ë¶„ ì´ì›”
        elif caje_type == "CAJE04":
            new_entries = []
            new_df = df.copy()
            ce_rows = new_df[new_df["FS_Element"] == "CE"]
            total_ce_amount = ce_rows["ê¸ˆì•¡"].sum()
            for desc, group in ce_rows.groupby('ê³„ì •ì½”ë“œ'):
                corp = group['íšŒì‚¬ëª…'].iloc[0]
                ce_row = ce_rows[ce_rows['ì„¤ëª…'] == desc]
                ce_code = ce_rows.iloc[0]["ê³„ì •ì½”ë“œ"]
                ce_name = ce_rows.iloc[0]["ê³„ì •ëª…"]
                # Main Adjustment
                new_entries.append({'íšŒì‚¬ëª…': corp, 'ê³„ì •ì½”ë“œ': ce_code, 'ê³„ì •ëª…': ce_name, 'ë‹¹ê¸°ì „ê¸°': 'ì „ê¸°', 'ê¸ˆì•¡': total_ce_amount, 'ì„¤ëª…': f'ë°°ë‹¹ê¸ˆ ì¡°ì • ({desc})'})
                new_entries.append({'íšŒì‚¬ëª…': corp, 'ê³„ì •ì½”ë“œ': RE_CODE, 'ê³„ì •ëª…': RE_NAME, 'ë‹¹ê¸°ì „ê¸°': 'ì „ê¸°', 'ê¸ˆì•¡': -total_ce_amount, 'ì„¤ëª…': f'ë°°ë‹¹ê¸ˆ ì¡°ì • ({desc})'})
            output_sheets[sheet_name] = pd.DataFrame(new_entries).reindex(columns=df_columns)

        # 6. CAJE96: Xê³„ì • -> ì´ìµì‰ì—¬ê¸ˆ ëŒ€ì²´
        elif caje_type == "CAJE96":
            new_df = df.copy()
            is_x = new_df["FS_Element"] == "X"
            new_df.loc[is_x, "ê¸ˆì•¡"] = -new_df.loc[is_x, "ê¸ˆì•¡"]
            new_df.loc[is_x, "ê³„ì •ì½”ë“œ"] = RE_CODE
            new_df.loc[is_x, "ê³„ì •ëª…"] = RE_NAME
            new_df.loc[is_x, "FS_Element"] = "E"
            new_df["ë‹¹ê¸°ì „ê¸°"] = "ì „ê¸°"
            output_sheets[sheet_name] = new_df.reindex(columns=df_columns)
            # Tax Adjustment
            tax_effect_rows = new_df[new_df["FS_Element"].isin(["E"])].copy()
            for _, row in tax_effect_rows.iterrows():
                corp, amount, desc = row["íšŒì‚¬ëª…"], row["ê¸ˆì•¡"], row.get('ì„¤ëª…', '')
                tax_rate = tax_rates.get(corp, 0.0)
                tax_effect = amount * tax_rate
                if abs(tax_effect) > 1:
                    caje97_new_entries.append({'íšŒì‚¬ëª…': corp, 'ê³„ì •ì½”ë“œ': RE_CODE, 'ê³„ì •ëª…': RE_NAME, 'ë‹¹ê¸°ì „ê¸°': 'ì „ê¸°', 'ê¸ˆì•¡': tax_effect, 'ì„¤ëª…': f'ë²•ì¸ì„¸íš¨ê³¼ ({desc})'})
                    caje97_new_entries.append({'íšŒì‚¬ëª…': corp, 'ê³„ì •ì½”ë“œ': DTL_CODE, 'ê³„ì •ëª…': DTL_NAME, 'ë‹¹ê¸°ì „ê¸°': 'ì „ê¸°', 'ê¸ˆì•¡': -tax_effect, 'ì„¤ëª…': f'ë²•ì¸ì„¸íš¨ê³¼ ({desc})'})

        # 8. CAJE98: ë‹¹ê¸°->ì „ê¸°, ë¹„ì§€ë°°ìˆœì´ìµ->ë¹„ì§€ë°°ì§€ë¶„
        elif caje_type == "CAJE98":
            new_df = df.copy()
            is_nci_pl = new_df["ê³„ì •ì½”ë“œ"] == NCI_PL_CODE
            new_df.loc[is_nci_pl, "ê³„ì •ì½”ë“œ"] = NCI_EQUITY_CODE
            new_df.loc[is_nci_pl, "ê³„ì •ëª…"] = NCI_EQUITY_NAME
            new_df["ë‹¹ê¸°ì „ê¸°"] = "ì „ê¸°"
            output_sheets[sheet_name] = new_df.reindex(columns=df_columns)
            
        # 7. CAJE97: 'ì·¨ë“ì¼' ë“± ìœ ì§€, ì‹ ê·œ ë²•ì¸ì„¸ íš¨ê³¼ ì¶”ê°€
        elif caje_type == "CAJE97":
            preserved_rows = df[~df["ë‹¹ê¸°ì „ê¸°"].isin(["ë‹¹ê¸°", "ì „ê¸°"])].copy()
            output_sheets[sheet_name] = preserved_rows # ì„ì‹œ ì €ì¥, ë‚˜ì¤‘ì— ì‹ ê·œ ë¶„ê°œì™€ í•©ì¹¨

        # ê¸°íƒ€ ì¡°ì • (CAJE05, CAJE99 ë“±)
        else:
            output_sheets[sheet_name] = df.reindex(columns=df_columns)


    # --- CAJE97 ìµœì¢… ì²˜ë¦¬ ---
    def find_sheet_name_by_prefix(prefix):
        for name in original_sheet_names:
            if name.upper().startswith(prefix):
                return name
        return None # ì°¾ì§€ ëª»í•œ ê²½ìš°

    caje97_sheet_name = find_sheet_name_by_prefix("CAJE97")
    if caje97_sheet_name:
        caje97_df = output_sheets.get(caje97_sheet_name, pd.DataFrame())
        caje97_cols = input_sheets.get(caje97_sheet_name, pd.DataFrame()).columns
        if caje97_cols.empty:
            caje97_cols = ['íšŒì‚¬ëª…', 'ê³„ì •ì½”ë“œ', 'ê³„ì •ëª…', 'ë‹¹ê¸°ì „ê¸°', 'ê¸ˆì•¡', 'ì„¤ëª…']

        new_tax_df = pd.DataFrame(caje97_new_entries)
        final_caje97_df = pd.concat([caje97_df, new_tax_df], ignore_index=True).reindex(columns=caje97_cols)
        output_sheets[caje97_sheet_name] = final_caje97_df
    elif caje97_new_entries: # ì‹œíŠ¸ëŠ” ì—†ì§€ë§Œ ìƒˆë¡œ ì¶”ê°€í•  í•­ëª©ì´ ìˆëŠ” ê²½ìš°
        caje97_sheet_name = "CAJE97_ë²•ì¸ì„¸ì¡°ì •"
        caje97_cols = ['íšŒì‚¬ëª…', 'ê³„ì •ì½”ë“œ', 'ê³„ì •ëª…', 'ë‹¹ê¸°ì „ê¸°', 'ê¸ˆì•¡', 'ì„¤ëª…']
        output_sheets[caje97_sheet_name] = pd.DataFrame(caje97_new_entries).reindex(columns=caje97_cols)


    # ëˆ„ë½ëœ ì‹œíŠ¸ê°€ ì—†ë„ë¡ ì›ë³¸ ì‹œíŠ¸ëª… ìˆœì„œëŒ€ë¡œ ì •ë ¬í•˜ì—¬ ë°˜í™˜
    final_ordered_sheets = {name: output_sheets.get(name, pd.DataFrame(columns=input_sheets.get(name, pd.DataFrame()).columns)) for name in original_sheet_names}

    return to_excel(final_ordered_sheets)

with tab3:
    st.markdown("---" )
    st.subheader("Step 6: ì¡°ì •ëª…ì„¸ ì°¨ê¸°ì´ì›” ìƒì„±")
    st.write(
        "ë‹¹ê¸° ì¡°ì •ëª…ì„¸ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´, ì°¨ê¸°ì— ë°˜ì˜ë  ì „ê¸°ëˆ„ì  ì¡°ì •ëª…ì„¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
    )

    if 'adj_workflow' not in st.session_state:
        st.session_state.adj_workflow = {}

    carryover_adj_file = st.file_uploader(
        "ì°¨ê¸°ì´ì›” í•  ì¡°ì •ëª…ì„¸ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.",
        type="xlsx",
        key="carryover_uploader"
    )

    if st.button("ğŸš€ ì°¨ê¸°ì´ì›” ì¡°ì •ëª…ì„¸ ìƒì„± ì‹¤í–‰", key="run_carryover"):
        if not carryover_adj_file:
            st.warning("ì°¨ê¸°ì´ì›” í•  ì¡°ì •ëª…ì„¸ íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        elif not st.session_state.files["coa"]:
            st.warning("ì‚¬ì´ë“œë°”ì—ì„œ CoA íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        else:
            with st.spinner("ì°¨ê¸°ì´ì›” ë°ì´í„°ë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                try:
                    coa_df = pd.read_excel(st.session_state.files["coa"], sheet_name="CoA", dtype=str)
                    aje_code = pd.read_excel(st.session_state.files["coa"], sheet_name="AJE", dtype=str)

                    carryover_excel_data = generate_carryover_adjustments(
                        carryover_adj_file, coa_df, aje_code
                    )

                    st.session_state.adj_workflow["carryover_file"] = carryover_excel_data
                    st.success("ğŸ‰ ì°¨ê¸°ì´ì›” ì¡°ì •ëª…ì„¸ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

                except Exception as e:
                    st.error(f"ì°¨ê¸°ì´ì›” ì¡°ì •ëª…ì„¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                    st.exception(e)

    if "carryover_file" in st.session_state.adj_workflow and st.session_state.adj_workflow.get("carryover_file"):
        st.download_button(
            label="ğŸ“¥ ì°¨ê¸°ì´ì›” ì¡°ì •ëª…ì„¸ ë‹¤ìš´ë¡œë“œ (.xlsx)",
            data=st.session_state.adj_workflow["carryover_file"],
            file_name="ì¡°ì •ëª…ì„¸_ì…ë ¥í…œí”Œë¦¿_carryover.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        )
