import streamlit as st
import pandas as pd
import io
from pathlib import Path
from openpyxl.styles import Font, PatternFill, Alignment
from openpyxl.utils import get_column_letter

st.set_page_config(page_title="ì—°ê²° ì¬ë¬´ì œí‘œ ë„ìš°ë¯¸", layout="wide")
st.title("ğŸ“Š ì—°ê²° ì¬ë¬´ì œí‘œ & ì£¼ì„ ëŒ€ì‚¬ ìë™í™”")

# --- Session State ì´ˆê¸°í™” ---
if 'files' not in st.session_state:
    st.session_state.files = {
        "coa": None,
        "parent": None,
        "subsidiaries": [],
        "adjustment": None,
        "footnotes": []
    }
if 'results' not in st.session_state:
    st.session_state.results = {
        "consolidation_wp": None,
        "financial_position": None,
        "income_statement": None,
        "combined_footnotes": None,
        "validation_log": [],
        "caje_df": None
    }
if 'caje_generated' not in st.session_state:
    st.session_state.caje_generated = False


# --- Helper Functions ---
@st.cache_data
def to_excel(df_dict):
    """
    ì—¬ëŸ¬ ë°ì´í„°í”„ë ˆì„ì„ í•˜ë‚˜ì˜ Excel íŒŒì¼ ë²„í¼ì— ì‹œíŠ¸ë¡œ ì €ì¥í•˜ê³ , ìŠ¤íƒ€ì¼ì„ ì ìš©í•©ë‹ˆë‹¤.
    df_dict: {'sheet_name': DataFrame} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
    """
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        for sheet_name, df in df_dict.items():
            if df.empty:
                continue
            df.to_excel(writer, sheet_name=sheet_name, index=False)
            
            ws = writer.sheets[sheet_name]

            # í—¤ë” ìŠ¤íƒ€ì¼ ì •ì˜
            header_font = Font(bold=True, color="FFFFFF")
            header_fill = PatternFill(start_color="4F81BD", end_color="4F81BD", fill_type="solid")
            header_alignment = Alignment(horizontal='center', vertical='center', wrap_text=True)
            
            # í—¤ë” ìŠ¤íƒ€ì¼ ì ìš©
            for cell in ws[1]:
                cell.font = header_font
                cell.fill = header_fill
                cell.alignment = header_alignment

            # ì—´ ë„ˆë¹„ ë° ìˆ«ì ì„œì‹ ì ìš©
            for i, column_name in enumerate(df.columns, 1): # openpyxlì€ 1-based index
                column_letter = get_column_letter(i)
                ws.column_dimensions[column_letter].width = 17
                
                # ì›ë³¸ DataFrameì—ì„œ ì—´ ì´ë¦„ìœ¼ë¡œ ë°ì´í„° íƒ€ì… í™•ì¸ (i-1 ì‚¬ìš©)
                if pd.api.types.is_numeric_dtype(df[df.columns[i-1]]):
                    # ì—´ ì „ì²´ì— ì„œì‹ ì ìš© (í—¤ë” ì œì™¸)
                    for cell in ws[column_letter][1:]:
                        if isinstance(cell.value, (int, float)):
                            cell.number_format = '#,##0'
                            cell.alignment = Alignment(horizontal='right', vertical='center')

    return output.getvalue()

def log_validation(message):
    """ê²€ì¦ ê²°ê³¼ë¥¼ ì„¸ì…˜ ìƒíƒœì— ê¸°ë¡í•©ë‹ˆë‹¤."""
    st.session_state.results["validation_log"].append(message)

# --- ì‚¬ì´ë“œë°” íŒŒì¼ ì—…ë¡œë“œ ---
with st.sidebar:
    st.header("ğŸ“ íŒŒì¼ ì—…ë¡œë“œ")
    st.info("íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ì„¸ì…˜ì— ì €ì¥ë©ë‹ˆë‹¤.")

    st.session_state.files["coa"] = st.file_uploader("1. CoA (ê³„ì • ì²´ê³„)", type="xlsx", key="coa_uploader")
    st.session_state.files["parent"] = st.file_uploader("2. ëª¨íšŒì‚¬ ì¬ë¬´ì œí‘œ", type="xlsx", key="parent_uploader")
    st.session_state.files["subsidiaries"] = st.file_uploader("3. ìíšŒì‚¬ ì¬ë¬´ì œí‘œ (ë‹¤ì¤‘ ì„ íƒ ê°€ëŠ¥)", type="xlsx", accept_multiple_files=True, key="subs_uploader")
    st.session_state.files["adjustment"] = st.file_uploader("4. ì—°ê²° ì¡°ì • ë¶„ê°œ (CAJE)", type="xlsx", key="adj_uploader")


# --- íƒ­ êµ¬ì„± ---
tab1, tab2, tab3 = st.tabs(["ğŸ“ˆ ì—°ê²° ì¬ë¬´ì œí‘œ", "ğŸ“ ì£¼ì„ ëŒ€ì‚¬", "ğŸ” ì—°ê²°ì¡°ì •"])

# =================================================================================================
# --- ì—°ê²° ì¬ë¬´ì œí‘œ íƒ­ ---
# =================================================================================================
with tab1:
    st.header("1. ì—°ê²° ì¬ë¬´ì œí‘œ ìƒì„±")
    st.write("CoA, ëª¨íšŒì‚¬, ìíšŒì‚¬ ì¬ë¬´ì œí‘œì™€ ì—°ê²° ì¡°ì • ë°ì´í„°ë¥¼ í†µí•©í•˜ì—¬ ì—°ê²° ì¬ë¬´ìƒíƒœí‘œì™€ ì†ìµê³„ì‚°ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")

    # --- ë°ì´í„° ë¡œë“œ ë° ì²˜ë¦¬ ë¡œì§ ---
    if st.button("ğŸš€ ì—°ê²° ì¬ë¬´ì œí‘œ ìƒì„± ì‹¤í–‰", disabled=not (st.session_state.files["coa"] and st.session_state.files["parent"])):
        with st.spinner("ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ê³  ìˆìŠµë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."):
            st.session_state.results["validation_log"] = [] # ë¡œê·¸ ì´ˆê¸°í™”

            # 1. íŒŒì¼ ë¡œë“œ ë° ë°ì´í„° ì •ì œ (ì´ì „ê³¼ ë™ì¼)
            try:
                def clean_df(df):
                    if "ê³„ì •ì½”ë“œ" in df.columns:
                        df = df.dropna(subset=["ê³„ì •ì½”ë“œ"])
                        df["ê³„ì •ì½”ë“œ"] = df["ê³„ì •ì½”ë“œ"].astype(str).str.strip().str.split('.').str[0]
                    return df
                coa_df = clean_df(pd.read_excel(st.session_state.files["coa"], dtype=str))
                parent_df = clean_df(pd.read_excel(st.session_state.files["parent"], dtype={"ê³„ì •ì½”ë“œ": str}))
                subs_dfs = [clean_df(pd.read_excel(f, dtype={"ê³„ì •ì½”ë“œ": str})) for f in st.session_state.files["subsidiaries"]]
                adj_df = clean_df(pd.read_excel(st.session_state.files["adjustment"], dtype={"ê³„ì •ì½”ë“œ": str})) if st.session_state.files["adjustment"] else pd.DataFrame(columns=['ê³„ì •ì½”ë“œ', 'ê¸ˆì•¡'])
            except Exception as e:
                st.error(f"íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                st.stop()

            # 2. ë°ì´í„° ê²€ì¦
            def check_duplicates(df, name):
                dups = df['ê³„ì •ì½”ë“œ'].value_counts().loc[lambda x: x > 1]
                if not dups.empty:
                    log_validation(f"âš ï¸ **[{name}]** ì¤‘ë³µ ê³„ì •ì½”ë“œ ë°œê²¬: {', '.join(dups.index)}")
            check_duplicates(parent_df, "ëª¨íšŒì‚¬")
            for i, df in enumerate(subs_dfs):
                check_duplicates(df, f"ìíšŒì‚¬{i+1}")

            def check_missing_in_coa(df, coa_codes, name):
                missing = set(df['ê³„ì •ì½”ë“œ']) - coa_codes
                if missing:
                    log_validation(f"ğŸš¨ **[{name}]** CoAì— ì—†ëŠ” ê³„ì •ì½”ë“œ ë°œê²¬: {', '.join(sorted(list(missing)))}")
            coa_codes = set(coa_df['ê³„ì •ì½”ë“œ'])
            check_missing_in_coa(parent_df, coa_codes, "ëª¨íšŒì‚¬")
            for i, df in enumerate(subs_dfs):
                check_missing_in_coa(df, coa_codes, f"ìíšŒì‚¬{i+1}")

            def check_balance_sheet_equation(df, column_name):
                """ì¬ë¬´ìƒíƒœí‘œ ì°¨ëŒ€ ê²€ì¦ (ìì‚° = ë¶€ì±„ + ìë³¸)"""
                total_assets = df[df['FS_Element'] == 'A'][column_name].sum()
                total_liabilities = df[df['FS_Element'] == 'L'][column_name].sum()
                total_equity = df[df['FS_Element'] == 'E'][column_name].sum()
                difference = total_assets - (total_liabilities + total_equity)
                
                if abs(difference) > 1: # ì‚¬ì†Œí•œ ë°˜ì˜¬ë¦¼ ì˜¤ë¥˜ëŠ” ë¬´ì‹œ
                    log_validation(f"âŒ **[{column_name}]** ì¬ë¬´ìƒíƒœí‘œ ì°¨ëŒ€ ë¶ˆì¼ì¹˜: {difference:,.0f}")
                else:
                    log_validation(f"âœ… **[{column_name}]** ì¬ë¬´ìƒíƒœí‘œ ì°¨ëŒ€ ì¼ì¹˜")

            # 3. ë°ì´í„° ë³‘í•© ë° ê¸°ë³¸ ê³„ì‚° (ì´ì „ê³¼ ë™ì¼)
            merged_df = coa_df.merge(parent_df[['ê³„ì •ì½”ë“œ', 'ê¸ˆì•¡']], on='ê³„ì •ì½”ë“œ', how='left').rename(columns={'ê¸ˆì•¡': 'ëª¨íšŒì‚¬'})
            for i, df in enumerate(subs_dfs):
                merged_df = merged_df.merge(df[['ê³„ì •ì½”ë“œ', 'ê¸ˆì•¡']], on='ê³„ì •ì½”ë“œ', how='left').rename(columns={'ê¸ˆì•¡': f'ìíšŒì‚¬{i+1}'})
            num_cols = merged_df.select_dtypes(include='number').columns
            merged_df[num_cols] = merged_df[num_cols].fillna(0)
            merged_df['ë‹¨ìˆœí•©ê³„'] = merged_df[num_cols].sum(axis=1)

            # --- ì¶”ê°€ëœ ì°¨ëŒ€ ê²€ì¦ ì‹¤í–‰ ---
            check_balance_sheet_equation(merged_df, 'ëª¨íšŒì‚¬')
            for i in range(len(subs_dfs)):
                check_balance_sheet_equation(merged_df, f'ìíšŒì‚¬{i+1}')
            check_balance_sheet_equation(merged_df, 'ë‹¨ìˆœí•©ê³„')
            # ------------------------------

            # 4. ì—°ê²° ì¡°ì • ì²˜ë¦¬
            adj_grouped = adj_df.groupby('ê³„ì •ì½”ë“œ', as_index=False)['ê¸ˆì•¡'].sum()

            # ì¡°ì •ë¶„ê°œë¥¼ ë³‘í•©í•˜ê³  ê²°ì¸¡ê°’ì„ 0ìœ¼ë¡œ ì±„ì›ë‹ˆë‹¤.
            merged_df = merged_df.merge(adj_grouped.rename(columns={'ê¸ˆì•¡': 'ì—°ê²°ì¡°ì •'}), on='ê³„ì •ì½”ë“œ', how='left')
            merged_df['ì—°ê²°ì¡°ì •'] = merged_df['ì—°ê²°ì¡°ì •'].fillna(0)

            # FS_Elementì— ë”°ë¼ ì¡°ì • ê¸ˆì•¡ì˜ ë¶€í˜¸ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.
            # L(ë¶€ì±„), E(ìë³¸), R(ìˆ˜ìµ)ì€ ëŒ€ë³€ ê³„ì •ì´ë¯€ë¡œ ì¡°ì •ì•¡ì˜ ë¶€í˜¸ë¥¼ ë°˜ì „ì‹œí‚µë‹ˆë‹¤.
            sign_map = {"L": -1, "E": -1, "R": -1}
            merged_df['sign'] = merged_df['FS_Element'].map(sign_map).fillna(1)
            
            # 'ì—°ê²°ì¡°ì •' ì—´ì— ì§ì ‘ ë¶€í˜¸ë¥¼ ì ìš©í•˜ì—¬ í‘œì‹œë˜ëŠ” ê°’ì„ ìˆ˜ì •í•©ë‹ˆë‹¤.
            merged_df['ì—°ê²°ì¡°ì •'] = merged_df['ì—°ê²°ì¡°ì •'] * merged_df['sign']

            # ìµœì¢… ê¸ˆì•¡ì„ ê³„ì‚°í•©ë‹ˆë‹¤. (ë‹¨ìˆœí•©ê³„ + ë¶€í˜¸ê°€ ì ìš©ëœ ì¡°ì •ì•¡)
            merged_df['ì—°ê²°ê¸ˆì•¡'] = merged_df['ë‹¨ìˆœí•©ê³„'] + merged_df['ì—°ê²°ì¡°ì •']
            
            # ê³„ì‚°ì— ì‚¬ìš©ëœ ì„ì‹œ sign ì—´ì„ ì œê±°í•©ë‹ˆë‹¤.
            merged_df = merged_df.drop(columns=['sign'])

            # 4. ì¬ë¬´ìƒíƒœí‘œ / ì†ìµê³„ì‚°ì„œ ë¶„ë¦¬
            df_bs = merged_df[merged_df["FS_Element"].isin(["A", "L", "E"])].copy()
            df_pl = merged_df[merged_df["FS_Element"].isin(["R", "X"])].copy()
            con_amtcols = ['ëª¨íšŒì‚¬'] + [f'ìíšŒì‚¬{i+1}' for i in range(len(subs_dfs))] + ['ë‹¨ìˆœí•©ê³„', 'ì—°ê²°ì¡°ì •', 'ì—°ê²°ê¸ˆì•¡']
            code_cols = [c for c in coa_df.columns if c.startswith('L') and c.endswith('code')]
            name_cols = [c for c in coa_df.columns if c.startswith('L') and not c.endswith('code')]
            name_code_map = {row[name]: row[code] for code, name in zip(code_cols, name_cols) for _, row in coa_df.iterrows() if pd.notna(row[code]) and pd.notna(row[name])}

            # 5. â˜…â˜…â˜… ì‚¬ìš©ì ë¡œì§ ê¸°ë°˜ ì¬ê·€í•¨ìˆ˜ ì¬êµ¬í˜„ â˜…â˜…â˜…
            def generate_fs_with_subtotals(df, name_cols, amount_cols, is_pl=False):
                df = df.copy()
                if is_pl:
                    df["sign"] = df["FS_Element"].map({"R": 1, "X": -1}).fillna(1)
                    for col in amount_cols:
                        df[col] = df[col] * df["sign"]

                def recursive_subtotal(data, current_name_cols):
                    if not current_name_cols or data.empty:
                        return data

                    current_col = current_name_cols[0]
                    remaining_cols = current_name_cols[1:]
                    
                    all_sub_dfs = []
                    for key, group in data.groupby(current_col, sort=False, dropna=False):
                        if pd.isna(key) or key == '':
                            all_sub_dfs.append(group)
                            continue

                        # í•˜ìœ„ ë ˆë²¨ ë¨¼ì € ì¬ê·€ í˜¸ì¶œ
                        sub_df = recursive_subtotal(group, remaining_cols)
                        
                        # í˜„ì¬ ë ˆë²¨ì˜ í•©ê³„ í–‰ ìƒì„±
                        sum_row = group.iloc[0:1].copy() # Get structure from the original group data
                        row_index = sum_row.index[0]
                        # Sum the original group data to prevent double counting subtotals from sub_df
                        sum_row.loc[row_index, amount_cols] = group[amount_cols].sum().values
                        sum_row.loc[row_index, 'ê³„ì •ëª…'] = key
                        sum_row.loc[row_index, 'ê³„ì •ì½”ë“œ'] = name_code_map.get(key, '')
                        # í•˜ìœ„ ë ˆë²¨ ê³„ì¸µ ì •ë³´ëŠ” ê³µë°±ìœ¼ë¡œ ì²˜ë¦¬
                        for col in remaining_cols:
                            if col in sum_row.columns:
                                sum_row.loc[row_index, col] = ''
                        
                        # ì„¸ë¶€ë‚´ì—­ + í•©ê³„ ìˆœì„œë¡œ í•©ì¹˜ê¸°
                        all_sub_dfs.append(pd.concat([sub_df, sum_row], ignore_index=True))

                    return pd.concat(all_sub_dfs, ignore_index=True)

                final_df = recursive_subtotal(df, name_cols)

                if is_pl and not final_df.empty:
                    final_df[amount_cols] = final_df[amount_cols].divide(final_df['sign'], axis=0)
                    final_df = final_df.drop(columns=['sign'])
                
                return final_df

            # 6. ìµœì¢… ê²°ê³¼ ìƒì„±
            bs_final = generate_fs_with_subtotals(df_bs, name_cols, con_amtcols, is_pl=False)
            pl_final = generate_fs_with_subtotals(df_pl, name_cols, con_amtcols, is_pl=True)
            
            # ê¸ˆì•¡ì´ ëª¨ë“  ì—´ì—ì„œ 0ì¸ í–‰ ì œê±°
            bs_final = bs_final.loc[(bs_final[con_amtcols] != 0).any(axis=1)]
            pl_final = pl_final.loc[(pl_final[con_amtcols] != 0).any(axis=1)]

            st.session_state.results['consolidation_wp'] = pd.concat([bs_final, pl_final]).reset_index(drop=True)
            st.session_state.results['con_amtcols'] = con_amtcols
            st.session_state.results['level_cols'] = code_cols + name_cols

            st.success("ğŸ‰ ì—°ê²° ì¬ë¬´ì œí‘œ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

    # --- ê²°ê³¼ í‘œì‹œ ---
    if st.session_state.results["validation_log"]:
        with st.expander("ğŸ” ë°ì´í„° ê²€ì¦ ë¡œê·¸ ë³´ê¸°"):
            for log in st.session_state.results["validation_log"]:
                st.markdown(log, unsafe_allow_html=True)

    if st.session_state.results["consolidation_wp"] is not None:
        st.subheader("ğŸ“„ ì—°ê²° ì‘ì—…åº•ç¨¿ (Working Paper)")
        
        con_amtcols = st.session_state.results.get('con_amtcols', [])
        display_cols = ['ê³„ì •ì½”ë“œ', 'ê³„ì •ëª…'] + con_amtcols
        display_cols = [col for col in display_cols if col in st.session_state.results["consolidation_wp"].columns]
        st.dataframe(st.session_state.results["consolidation_wp"][display_cols])

        # --- ë‹¤ìš´ë¡œë“œ ë¡œì§ ìˆ˜ì • ---
        level_cols_to_drop = st.session_state.results.get('level_cols', [])
        df_for_download = st.session_state.results["consolidation_wp"].drop(columns=level_cols_to_drop, errors='ignore')

        excel_data = to_excel({
            "Consolidation_WP": df_for_download
        })
        st.download_button(
            label="ğŸ“¥ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (Excel)",
            data=excel_data,
            file_name="consolidated_fs_results.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
    elif not (st.session_state.files["coa"] and st.session_state.files["parent"]):
        st.info("ì‚¬ì´ë“œë°”ì—ì„œ CoAì™€ ëª¨íšŒì‚¬ íŒŒì¼ì„ ì—…ë¡œë“œí•œ í›„ 'ìƒì„± ì‹¤í–‰' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")


# =================================================================================================
# --- ì£¼ì„ ëŒ€ì‚¬ íƒ­ ---
# =================================================================================================
with tab2:
    st.header("2. ì£¼ì„ ëŒ€ì‚¬ (Reconciliation)")
    st.write("ëª¨íšŒì‚¬ ì£¼ì„ì„ ê¸°ì¤€ìœ¼ë¡œ ìíšŒì‚¬ ì£¼ì„ë“¤ì˜ ìˆ«ì ë°ì´í„°ë¥¼ ìœ„ì¹˜ ê¸°ë°˜ìœ¼ë¡œ í•©ì‚°í•˜ê³ , ì—°ê²°ì •ì‚°í‘œì™€ ëŒ€ì‚¬í•©ë‹ˆë‹¤.")

    footnote_parent_file = st.file_uploader("1. ëª¨íšŒì‚¬ ì£¼ì„ íŒŒì¼", type="xlsx")
    footnote_subs_files = st.file_uploader("2. ìíšŒì‚¬ ì£¼ì„ íŒŒì¼ (ë‹¤ì¤‘ ì„ íƒ ê°€ëŠ¥)", type="xlsx", accept_multiple_files=True)

    if st.button("ğŸ”„ ì£¼ì„ ëŒ€ì‚¬ ì‹¤í–‰", disabled=not footnote_parent_file):
        if st.session_state.results.get("consolidation_wp") is None and footnote_subs_files:
            st.warning("ëŒ€ì‚¬ë¥¼ ìœ„í•´ì„œëŠ” ë¨¼ì € 'ì—°ê²° ì¬ë¬´ì œí‘œ' íƒ­ì—ì„œ 'ìƒì„± ì‹¤í–‰'ì„ ì™„ë£Œí•´ì•¼ í•©ë‹ˆë‹¤.")
            st.stop()

        with st.spinner("ì£¼ì„ íŒŒì¼ì„ ì·¨í•©í•˜ê³  ëŒ€ì‚¬í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            try:
                st.session_state.results['combined_footnotes'] = {}
                parent_sheets = pd.read_excel(footnote_parent_file, sheet_name=None, dtype=str)
                subs_files_data = [(Path(f.name).stem, pd.read_excel(f, sheet_name=None, dtype=str)) for f in footnote_subs_files]
                conso_map = st.session_state.results.get("consolidation_wp", pd.DataFrame()).set_index('ê³„ì •ì½”ë“œ')['ì—°ê²°ê¸ˆì•¡'].to_dict() if st.session_state.results.get("consolidation_wp") is not None else {}

                for sheet_name, parent_df in parent_sheets.items():
                    if "ì£¼ì„" not in sheet_name:
                        continue

                    # â˜…â˜…â˜… íŒŒì¼ ì´ë¦„ ê¸°ë¡ ë¡œì§ ì¶”ê°€ â˜…â˜…â˜…
                    all_dfs_for_sheet = []
                    parent_df_copy = parent_df.copy()
                    parent_df_copy["ì†ŒìŠ¤íŒŒì¼"] = Path(footnote_parent_file.name).stem
                    all_dfs_for_sheet.append(parent_df_copy)

                    for name, sheets in subs_files_data:
                        if sheet_name in sheets:
                            sub_df_copy = sheets[sheet_name].copy()
                            sub_df_copy["ì†ŒìŠ¤íŒŒì¼"] = name
                            all_dfs_for_sheet.append(sub_df_copy)
                    
                    should_concat = False
                    for df in all_dfs_for_sheet:
                        if len(df.columns) > 3:
                            for col_name in df.columns[2:-1]: # ë§ˆì§€ë§‰ ì†ŒìŠ¤íŒŒì¼ ì—´ ì œì™¸
                                if pd.to_numeric(df[col_name], errors='coerce').isna().any():
                                    should_concat = True
                                    break
                        if should_concat: break

                    if should_concat:
                        final_df = pd.concat(all_dfs_for_sheet, ignore_index=True)
                    else:
                        final_df = all_dfs_for_sheet[0].copy()
                        value_cols = final_df.columns[2:-1]
                        final_df[value_cols] = final_df[value_cols].apply(pd.to_numeric, errors='coerce').fillna(0)
                        
                        for next_df in all_dfs_for_sheet[1:]:
                            next_value_cols = next_df.columns[2:-1]
                            next_df[next_value_cols] = next_df[next_value_cols].apply(pd.to_numeric, errors='coerce').fillna(0)
                            final_df[value_cols] = final_df[value_cols].add(next_df[next_value_cols].values, fill_value=0)
                        
                        if footnote_subs_files:
                            final_df["ì†ŒìŠ¤íŒŒì¼"] = "combined"

                        # --- ì—°ê²°ì¡°ì • ê¸ˆì•¡ í•©ì‚° ë¡œì§ ---
                        if "ê³„ì •ì½”ë“œ" in final_df.columns and st.session_state.results.get("consolidation_wp") is not None:
                            numeric_cols = final_df.select_dtypes(include='number').columns
                            if not numeric_cols.empty:
                                last_numeric_col = numeric_cols[-1]
                                
                                # ì—°ê²°ì¡°ì • ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                                conso_wp_df = st.session_state.results["consolidation_wp"]
                                if 'ê³„ì •ì½”ë“œ' in conso_wp_df.columns and 'ì—°ê²°ì¡°ì •' in conso_wp_df.columns:
                                    adj_map = conso_wp_df.set_index('ê³„ì •ì½”ë“œ')['ì—°ê²°ì¡°ì •'].to_dict()
                                    
                                    # 'ê³„ì •ì½”ë“œ'ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ë§¤í•‘ ë³´ì¥
                                    final_df['ê³„ì •ì½”ë“œ_str'] = final_df['ê³„ì •ì½”ë“œ'].astype(str).str.strip()
                                    
                                    # ì¡°ì •ì•¡ ì ìš©
                                    adj_values = final_df['ê³„ì •ì½”ë“œ_str'].map(adj_map).fillna(0)
                                    final_df[last_numeric_col] += adj_values
                                    
                                    final_df = final_df.drop(columns=['ê³„ì •ì½”ë“œ_str'])

                        if "ê³„ì •ì½”ë“œ" in final_df.columns and conso_map:
                            last_numeric_col = final_df.select_dtypes(include='number').columns[-1]
                            def check_value_match(row):
                                code = str(row["ê³„ì •ì½”ë“œ"]).strip()
                                if not code: return ""
                                footnote_value = row[last_numeric_col]
                                conso_value = conso_map.get(code)
                                if conso_value is None: return "ë¶ˆì¼ì¹˜ (ì •ì‚°í‘œì— ì½”ë“œ ì—†ìŒ)"
                                if abs(footnote_value - conso_value) < 1: return "ì¼ì¹˜"
                                else: return f"ë¶ˆì¼ì¹˜ (ì°¨ì´: {footnote_value - conso_value:,.0f})"
                            final_df["ëŒ€ì‚¬ê²°ê³¼"] = final_df.apply(check_value_match, axis=1)

                    st.session_state.results['combined_footnotes'][sheet_name] = final_df

                st.success("ğŸ‰ ì£¼ì„ ì·¨í•© ë° ëŒ€ì‚¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

            except Exception as e:
                st.error(f"ì£¼ì„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

    # --- ê²°ê³¼ í‘œì‹œ ---
    if st.session_state.results.get('combined_footnotes'):
        st.subheader("ğŸ“’ ì·¨í•©ëœ ì£¼ì„ ë°ì´í„°")
        for sheet_name, df in st.session_state.results['combined_footnotes'].items():
            with st.expander(f"ì‹œíŠ¸: {sheet_name}", expanded=False):
                st.dataframe(df)
        footnote_excel_data = to_excel(st.session_state.results['combined_footnotes'])
        st.download_button(
            label="ğŸ“¥ ì·¨í•©ëœ ì£¼ì„ ë‹¤ìš´ë¡œë“œ (Excel)",
            data=footnote_excel_data,
            file_name="combined_footnotes.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )

# =================================================================================================
# --- ì—°ê²°ì¡°ì • íƒ­ ---
# =================================================================================================
with tab3:
    st.header("3. ì—°ê²° ì¡°ì • ë¶„ê°œ ìƒì„±")
    st.write("ì¡°ì •ë¶„ê°œ ì…ë ¥ í…œí”Œë¦¿ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ì‘ì„±í•œ í›„, ì—…ë¡œë“œí•˜ì—¬ ì—°ê²° ì¡°ì • ë¶„ê°œ(CAJE)ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")

    # --- ì¡°ì •ë¶„ê°œ í…œí”Œë¦¿ ë‹¤ìš´ë¡œë“œ ---
    st.subheader("Step 1: í…œí”Œë¦¿ ë‹¤ìš´ë¡œë“œ")
    
    @st.cache_data
    def create_adjustment_template():
        adjustment_types = [
            ("CAJE01_ì±„ê¶Œì±„ë¬´ì œê±°", "Intercompany Elimination"),
            ("CAJE02_ë¯¸ì‹¤í˜„ì´ìµì œê±°", "Unrealized Profit Elimination"),
            ("CAJE03_íˆ¬ììë³¸ìƒê³„", "Investment-Equity Elimination"),
            ("CAJE04_ë°°ë‹¹ì¡°ì •", "Dividend Adjustment"),
            ("CAJE05_ê°ê°€ìƒê°ì¡°ì •", "Depreciation Adjustment"),
            ("CAJE06_ìƒê°ë¹„ì¡°ì •", "Amortization Adjustment"),
            ("CAJE07_ì†ìµì¡°ì •", "Profit & Loss Adjustment"),
            ("CAJE08_íšŒê³„ì •ì±…ì¡°ì •", "Accounting Policy Adjustment"),
            ("CAJE09_ì§€ë¶„ë²•ì¡°ì •", "Equity Method Adjustment"),
            ("CAJE10_ê³µì •ê°€ì¹˜ì¡°ì •", "Fair Value Adjustment"),
            ("CAJE99_ê¸°íƒ€ì¡°ì •", "Other Adjustment"),
        ]
        columns = ["ë²•ì¸1", "ê³„ì •1", "ê¸ˆì•¡1", "ë²•ì¸2", "ê³„ì •2", "ê¸ˆì•¡2", "ì„¤ëª…"]
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine="openpyxl") as writer:
            for sheet_name, _ in adjustment_types:
                df = pd.DataFrame(columns=columns)
                df.to_excel(writer, sheet_name=sheet_name, index=False)
                ws = writer.sheets[sheet_name]

                # í—¤ë” ìŠ¤íƒ€ì¼ ì •ì˜
                header_font = Font(bold=True, color="FFFFFF")
                header_fill = PatternFill(start_color="4F81BD", end_color="4F81BD", fill_type="solid")
                header_alignment = Alignment(horizontal='center', vertical='center', wrap_text=True)

                # í—¤ë” ìŠ¤íƒ€ì¼ ì ìš©
                for cell in ws[1]:
                    cell.font = header_font
                    cell.fill = header_fill
                    cell.alignment = header_alignment

                # ì—´ ë„ˆë¹„ ì¡°ì ˆ
                for i, column_name in enumerate(df.columns, 1):
                    column_letter = get_column_letter(i)
                    ws.column_dimensions[column_letter].width = 20

        return output.getvalue()

    template_data = create_adjustment_template()
    st.download_button(
        label="ğŸ“¥ ì¡°ì •ë¶„ê°œ ì…ë ¥ í…œí”Œë¦¿ ë‹¤ìš´ë¡œë“œ (.xlsx)",
        data=template_data,
        file_name="ì¡°ì •ë¶„ê°œ_ì…ë ¥í…œí”Œë¦¿.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

    # --- ì¡°ì •ë¶„ê°œ íŒŒì¼ ì—…ë¡œë“œ ë° ì²˜ë¦¬ ---
    st.subheader("Step 2: í…œí”Œë¦¿ ì—…ë¡œë“œ ë° ë¶„ê°œ ìƒì„±")
    uploaded_adj_file = st.file_uploader("ì‘ì„±í•œ ì¡°ì •ë¶„ê°œ í…œí”Œë¦¿ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", type="xlsx", key="caje_uploader")

    if st.button("âš™ï¸ ì¡°ì • ë¶„ê°œ ìƒì„± ì‹¤í–‰", disabled=not (uploaded_adj_file and st.session_state.files["coa"])):
        with st.spinner("ì¡°ì • ë¶„ê°œë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            try:
                coa_df = pd.read_excel(st.session_state.files["coa"], dtype=str)
                
                def get_fs_sign(fs_element):
                    if fs_element in ["A", "X"]: return -1
                    elif fs_element in ["L", "E", "R"]: return 1
                    else: return 1

                def build_caje_from_excel(adjustment_file, coa_df_internal):
                    fs_map = dict(zip(coa_df_internal["ê³„ì •ì½”ë“œ"], coa_df_internal["FS_Element"]))
                    xls = pd.ExcelFile(adjustment_file)
                    all_entries = []

                    for sheet in xls.sheet_names:
                        df = pd.read_excel(xls, sheet, dtype={"ê³„ì •1": str,"ê³„ì •2": str }).fillna("")
                        try:
                            caje_type = sheet.split("_")[0]
                        except IndexError:
                            caje_type = sheet

                        for _, row in df.iterrows():
                            ì„¤ëª… = row.get("ì„¤ëª…", "")
                            # ë²•ì¸1
                            code1 = str(row["ê³„ì •1"]).strip()
                            if row["ë²•ì¸1"] and code1 and row["ê¸ˆì•¡1"]:
                                fs1 = fs_map.get(code1, "")
                                try:
                                    ê¸ˆì•¡1 = float(str(row["ê¸ˆì•¡1"]).replace(",", ""))
                                    sign1 = get_fs_sign(fs1)
                                    all_entries.append({
                                        "ì¡°ì •ìœ í˜•": caje_type, "ë²•ì¸": row["ë²•ì¸1"], "ê³„ì •ì½”ë“œ": code1,
                                        "ê¸ˆì•¡": ê¸ˆì•¡1 * sign1, "ì„¤ëª…": ì„¤ëª…, "FS_Element": fs1
                                    })
                                except ValueError: pass
                            # ë²•ì¸2
                            code2 = str(row["ê³„ì •2"]).strip()
                            if row["ë²•ì¸2"] and code2 and row["ê¸ˆì•¡2"]:
                                fs2 = fs_map.get(code2, "")
                                try:
                                    ê¸ˆì•¡2 = float(str(row["ê¸ˆì•¡2"]).replace(",", ""))
                                    sign2 = get_fs_sign(fs2)
                                    all_entries.append({
                                        "ì¡°ì •ìœ í˜•": caje_type, "ë²•ì¸": row["ë²•ì¸2"], "ê³„ì •ì½”ë“œ": code2,
                                        "ê¸ˆì•¡": ê¸ˆì•¡2 * sign2, "ì„¤ëª…": ì„¤ëª…, "FS_Element": fs2
                                    })
                                except ValueError: pass
                    return pd.DataFrame(all_entries)

                caje_df = build_caje_from_excel(uploaded_adj_file, coa_df)
                st.session_state.results['caje_df'] = caje_df
                st.session_state.caje_generated = True
                st.success("âœ… ì¡°ì • ë¶„ê°œ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

            except Exception as e:
                st.error(f"ì¡°ì • ë¶„ê°œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    
    if not st.session_state.files["coa"]:
        st.warning("ë¨¼ì € ì‚¬ì´ë“œë°”ì—ì„œ CoA íŒŒì¼ì„ ì—…ë¡œë“œí•´ì•¼ í•©ë‹ˆë‹¤.")

    # --- ê²°ê³¼ í‘œì‹œ ë° ë‹¤ìš´ë¡œë“œ ---
    if st.session_state.caje_generated:
        st.subheader("Step 3: ê²°ê³¼ í™•ì¸ ë° ë‹¤ìš´ë¡œë“œ")
        st.dataframe(st.session_state.results['caje_df'])
        
        caje_excel_data = to_excel({"CAJE": st.session_state.results['caje_df']})
        st.download_button(
            label="ğŸ“¥ ìƒì„±ëœ ì¡°ì • ë¶„ê°œ(CAJE) ë‹¤ìš´ë¡œë“œ (.xlsx)",
            data=caje_excel_data,
            file_name="CAJE.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
        st.info("ìƒì„±ëœ CAJE íŒŒì¼ì€ ì‚¬ì´ë“œë°”ì˜ '4. ì—°ê²° ì¡°ì • ë¶„ê°œ (CAJE)'ì— ì—…ë¡œë“œí•˜ì—¬ ì—°ê²° ì¬ë¬´ì œí‘œ ìƒì„±ì— ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
